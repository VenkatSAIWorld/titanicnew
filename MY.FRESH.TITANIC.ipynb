{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.covariance as covariance\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.mixture as mixture\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.impute as impute\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnull(df, features):\n",
    "    for feats in features:\n",
    "        if df[feats].isnull().sum()>0:\n",
    "            print(feats,'null values:', df[feats].isnull().sum())\n",
    "            print(feats,':',df[feats].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats=train.columns.to_list()\n",
    "test_feats=test.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age null values: 177\n",
      "Age : False    714\n",
      "True     177\n",
      "Name: Age, dtype: int64\n",
      "Cabin null values: 687\n",
      "Cabin : True     687\n",
      "False    204\n",
      "Name: Cabin, dtype: int64\n",
      "Embarked null values: 2\n",
      "Embarked : False    889\n",
      "True       2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "isnull(train, train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age null values: 86\n",
      "Age : False    332\n",
      "True      86\n",
      "Name: Age, dtype: int64\n",
      "Fare null values: 1\n",
      "Fare : False    417\n",
      "True       1\n",
      "Name: Fare, dtype: int64\n",
      "Cabin null values: 327\n",
      "Cabin : True     327\n",
      "False     91\n",
      "Name: Cabin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "isnull(test, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, features):\n",
    "    for feats in features:\n",
    "        if len(df[feats].value_counts())<10:\n",
    "            val_feats=df[feats].value_counts()\n",
    "            df[feats].value_counts().plot.bar()\n",
    "            plt.xlabel(feats)\n",
    "            plt.show()\n",
    "            print(feats, val_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived 0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass 3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SibSp 0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parch 0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "plot(train, train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass 3    218\n",
      "1    107\n",
      "2     93\n",
      "Name: Pclass, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEfCAYAAAC6Z4bJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPzUlEQVR4nO3dfWydZ32H8etLW14KaC2L22VpNhcW2FpeQmsVGGMqq0RfGAtMY2sREEGloKmoMNCkApuotFV0jJep09YpiI7CGFANGGVUdCXiZYgVcLooTZpVZDTQkKx1B5QiRFnCb3+cx+PUtWPH9vGT3r4+kuVz7vMc+xcpunJy+3mOU1VIktryqL4HkCQtP+MuSQ0y7pLUIOMuSQ0y7pLUIOMuSQ06vu8BANasWVPj4+N9jyFJjyjbt2+/r6rGZnvsmIj7+Pg4k5OTfY8hSY8oSb4112Nuy0hSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXomLiI6ZFi/IrP9D1CU/Zd/eK+R5Ca5St3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBs0b9yTrk3w+yZ4ku5O8oVu/Msl3kuzoPi4aes5bkuxNcmeS80f5B5AkPdxCrlA9BLy5qm5L8kRge5JbusfeW1XvGj44yRnAxcCZwC8Cn0vy1Ko6vJyDS5LmNu8r96o6WFW3dbcfAPYA647wlE3AR6vqwaq6C9gLnLMcw0qSFuao9tyTjAPPBr7aLb0+yc4k1yU5uVtbB9w99LT9HPkfA0nSMltw3JM8Afg48Maq+gFwLfAUYCNwEHj39KGzPL1m+XpbkkwmmZyamjrqwSVJc1tQ3JOcwCDsH66qTwBU1T1Vdbiqfgq8j59tvewH1g89/TTgwMyvWVVbq2qiqibGxsaW8meQJM2wkLNlArwf2FNV7xlaXzt02MuAXd3tG4GLkzwmyenABuBryzeyJGk+Czlb5vnAq4Dbk+zo1t4KXJJkI4Mtl33A6wCqaneSG4A7GJxpc5lnykjSypo37lX1ZWbfR7/pCM+5CrhqCXNJkpbAK1QlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaNG/ck6xP8vkke5LsTvKGbv1JSW5J8o3u88ndepJck2Rvkp1Jzhr1H0KS9FALeeV+CHhzVf0a8FzgsiRnAFcA26pqA7Ctuw9wIbCh+9gCXLvsU0uSjmjeuFfVwaq6rbv9ALAHWAdsAq7vDrseeGl3exPwwRq4FTgpydpln1ySNKej2nNPMg48G/gqcGpVHYTBPwDAKd1h64C7h562v1uTJK2QBcc9yROAjwNvrKofHOnQWdZqlq+3JclkksmpqamFjiFJWoAFxT3JCQzC/uGq+kS3fM/0dkv3+d5ufT+wfujppwEHZn7NqtpaVRNVNTE2NrbY+SVJs1jI2TIB3g/sqar3DD10I7C5u70Z+NTQ+qu7s2aeC9w/vX0jSVoZxy/gmOcDrwJuT7KjW3srcDVwQ5JLgW8DL+8euwm4CNgL/Ah4zbJOLEma17xxr6ovM/s+OsB5sxxfwGVLnEuStAReoSpJDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktSgeeOe5Lok9ybZNbR2ZZLvJNnRfVw09NhbkuxNcmeS80c1uCRpbgt55f4B4IJZ1t9bVRu7j5sAkpwBXAyc2T3nb5Mct1zDSpIW5vj5DqiqLyUZX+DX2wR8tKoeBO5Kshc4B/j3RU8oaV7jV3ym7xGasu/qF/c9wpItZc/99Ul2dts2J3dr64C7h47Z361JklbQYuN+LfAUYCNwEHh3t55Zjq3ZvkCSLUkmk0xOTU0tcgxJ0mwWFfequqeqDlfVT4H3Mdh6gcEr9fVDh54GHJjja2ytqomqmhgbG1vMGJKkOSwq7knWDt19GTB9Js2NwMVJHpPkdGAD8LWljShJOlrz/kA1yUeAc4E1SfYDbwfOTbKRwZbLPuB1AFW1O8kNwB3AIeCyqjo8mtElSXNZyNkyl8yy/P4jHH8VcNVShpIkLY1XqEpSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDVo3rgnuS7JvUl2Da09KcktSb7RfT65W0+Sa5LsTbIzyVmjHF6SNLuFvHL/AHDBjLUrgG1VtQHY1t0HuBDY0H1sAa5dnjElSUdj3rhX1ZeA785Y3gRc392+Hnjp0PoHa+BW4KQka5drWEnSwix2z/3UqjoI0H0+pVtfB9w9dNz+bu1hkmxJMplkcmpqapFjSJJms9w/UM0sazXbgVW1taomqmpibGxsmceQpNVtsXG/Z3q7pft8b7e+H1g/dNxpwIHFjydJWozFxv1GYHN3ezPwqaH1V3dnzTwXuH96+0aStHKOn++AJB8BzgXWJNkPvB24GrghyaXAt4GXd4ffBFwE7AV+BLxmBDNLkuYxb9yr6pI5HjpvlmMLuGypQ0mSlsYrVCWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhp0/FKenGQf8ABwGDhUVRNJngR8DBgH9gG/X1XfW9qYkqSjsRyv3F9YVRuraqK7fwWwrao2ANu6+5KkFTSKbZlNwPXd7euBl47ge0iSjmCpcS/gX5NsT7KlWzu1qg4CdJ9Pme2JSbYkmUwyOTU1tcQxJEnDlrTnDjy/qg4kOQW4Jcl/LvSJVbUV2AowMTFRS5xDkjRkSa/cq+pA9/le4JPAOcA9SdYCdJ/vXeqQkqSjs+i4J3l8kidO3wZeBOwCbgQ2d4dtBj611CElSUdnKdsypwKfTDL9df6xqj6b5OvADUkuBb4NvHzpY0qSjsai415V3wSeNcv6/wDnLWUoSdLSeIWqJDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg0YW9yQXJLkzyd4kV4zq+0iSHm4kcU9yHPA3wIXAGcAlSc4YxfeSJD3cqF65nwPsrapvVtVPgI8Cm0b0vSRJMxw/oq+7Drh76P5+4DnDByTZAmzp7v4wyZ0jmmU1WgPc1/cQ88lf9D2BeuDfzeX1y3M9MKq4Z5a1esidqq3A1hF9/1UtyWRVTfQ9hzSTfzdXzqi2ZfYD64funwYcGNH3kiTNMKq4fx3YkOT0JI8GLgZuHNH3kiTNMJJtmao6lOT1wM3AccB1VbV7FN9Ls3K7S8cq/26ukFTV/EdJkh5RvEJVkhpk3CWpQcZdkhpk3BuS5HFJntb3HJL6Z9wbkeQlwA7gs939jUk8/VS9S/LUJNuS7OruPzPJn/Q9V+uMezuuZPCePt8HqKodwHiP80jT3ge8BfhfgKrayeDaF42QcW/Hoaq6v+8hpFmcWFVfm7F2qJdJVpFRvbeMVt6uJK8AjkuyAbgc+ErPM0kA9yV5Ct37SyX5PeBgvyO1z4uYGpHkROBtwIsYvHHbzcCfVdWPex1Mq16SJzO4MvXXge8BdwGvrKp9fc7VOuMuaUUkeTzwqKp6oO9ZVgPj/giX5NPMeDvlYVX1Oys4jvT/krzpSI9X1XtWapbVyD33R7539T2ANIcn9j3AauYrd0lqkK/cG9GdIfMOBr+Q/LHT61X15N6GkoAkjwUuBc7koX83X9vbUKuA57m34++BaxmcP/xC4IPAh3qdSBr4EPALwPnAFxn8ZjZ/qDpibss0Isn2qjo7ye1V9Yxu7d+q6gV9z6bVLcl/VNWzk+ysqmcmOQG4uap+q+/ZWua2TDt+nORRwDe634L1HeCUnmeSoHvbAeD7SZ4O/De+NcbIuS3TjjcCJzK4MvVs4JXAq3udSBrYmuRk4E8Z/C7lO4B39jtS+9yWaUSSCQZXqP4ycEK3XFX1zP6mktQX496IJHcCfwzcDvx0er2qvtXbUBKQ5CQG/4scZ2gruKou72um1cA993ZMVZXv365j0U3Arcx44aHR8pV7I5KcB1wCbAMenF6vqk/0NpQEJLmtqs7qe47Vxrg3Isk/AL8K7OZnr47KC0XUtyR/BPwQ+Bce+sLju70NtQq4LdOOZ02f3y4dY34C/CWDH/hPv5oswKunR8i4t+PWJGdU1R19DyLN8CbgV6rqvr4HWU2Mezt+A9ic5C4G//UNngqpY8Nu4Ed9D7HaGPd2XND3ANIcDgM7knyeh+65eyrkCBn3Rng+u45h/9x9aAV5toykkUvyOOCXqurOvmdZLXxvGUkjleQlwA7gs939jUm84G7EjLukUbsSOAf4PkBV7QBO73Og1cC4Sxq1Q1V1/4w194NHzB+oShq1XUleARzX/TrIy4Gv9DxT83zlLmkkkkz/msf/YvD7Ux8EPgL8gMHvH9AIebaMpJFIcgdwIYNf0PHCmY/73jKj5baMpFH5OwZnyDwZmBxaD763zMj5yl3SSCW5tqr+sO85VhvjLkkN8geqktQg4y5JDTLuWvWSvC3J7iQ7k+xI8py+Z5KWyrNltKoleR7w28BZVfVgkjXAo3seS1oyX7lrtVsL3FdVDwJU1X1VdSDJ2Um+mGR7kpuTrE1yfJKvJzkXIMk7klzV5/DSXDxbRqtakicAXwZOBD4HfIzBpfFfBDZV1VSSPwDOr6rXJjkT+CcGl9C/E3hOVf2kn+mlubkto1Wtqn6Y5GzgBQyuovwY8OfA04FbkgAcBxzsjt/dXVb/aeB5hl3HKuOuVa+qDgNfAL6Q5HbgMmB3VT1vjqc8g8Hb1566MhNKR889d61qSZ7WvVPhtI3AHmCs+2ErSU7otmNI8rvAzwO/CVyT5KSVnllaCPfctap1WzJ/DZwEHAL2AluA04BrgJ9j8D/cvwI+yWA//ryqujvJ5cDZVbW5j9mlIzHuktQgt2UkqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIa9H8wM7/1bMqDuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex male      266\n",
      "female    152\n",
      "Name: Sex, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SibSp 0    283\n",
      "1    110\n",
      "2     14\n",
      "4      4\n",
      "3      4\n",
      "8      2\n",
      "5      1\n",
      "Name: SibSp, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parch 0    324\n",
      "1     52\n",
      "2     33\n",
      "3      3\n",
      "9      2\n",
      "4      2\n",
      "6      1\n",
      "5      1\n",
      "Name: Parch, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked S    270\n",
      "C    102\n",
      "Q     46\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "plot(test, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df, features):\n",
    "    for feats in features:\n",
    "        if len(df[feats].unique())>20 and df[feats].dtypes!='O' and feats not in ['PassengerId']:\n",
    "            df[feats+'_median']=df[feats].fillna(df[feats].median())\n",
    "            plt.subplot(221)\n",
    "            df[feats+'_median'].plot.hist()\n",
    "            plt.xlabel(feats+'_median')\n",
    "            df[feats+'_rs']=df[feats]\n",
    "            rs=df[feats].dropna().sample(df[feats].isnull().sum())\n",
    "            rs.index=df[df[feats].isnull()].index\n",
    "            df.loc[df[feats].isnull(), feats+'_rs']=rs\n",
    "            \n",
    "            plt.subplots(222)\n",
    "            df[feats+'_rs'].plot.hist()\n",
    "\n",
    "            plt.xlabel(feats+'_rs')\n",
    "            \n",
    "            plt.subplot(223)\n",
    "            df[feats+'_median'].plot.kde()\n",
    "            plt.xlabel(feats+'_median')\n",
    "            \n",
    "            plt.subplot(224)\n",
    "            df[feats+'_rs'].plot.kde()\n",
    "            plt.xlabel(feats+'_rs')\n",
    "\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 123 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAACRCAYAAACLx4fmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANcklEQVR4nO3dfbBdVXnH8e8vLxJCDREDNDXqDTUKTAcEA6XFWjS1I0GDOtHSoWCZaJyWUuzLSKCM1Zl2Jpm+BBgqorElUKlKKK0CFUN4sXaGhBuSEkm0xBgxQwqxhgQCJCR5+sd+TnK4nty7z849Ofue+/vMnDl7r732vmsn98l+yVrPUkRgZu0Z0+0GmI1EDhyzChw4ZhU4cMwqcOCYVeDAMatgXLcbcDimTJkSfX193W6G9ajVq1f/NCKOb7VtRAdOX18f/f393W6G9ShJPz7UNt+qmVXgwDGrwIFjVsGIfsYZTN+Ceyrtt3nhBcPcEutFvuKYVeDAMavAgWNWgQPHrAIHjlkFDhyzChw4ZhU4cMwqcOCYVeDAMavAgWNWgQPHrIKOBo6kyZKWSfq+pA2Sfk3ScZKWS3oyv1+XdSXpBkkbJT0u6cxOts3scHT6inM98K2IOBk4HdgALABWRMQMYEWuA5wPzMjPfOCmDrfNrLKOBY6kScC7gC8DRMSeiHgOuBBYmtWWAh/M5QuBW6PwCDBZ0tROtc/scHTyinMSsA34J0lrJC2RdAxwYkRsBcjvE7L+G4CfNO2/JcvMaqeTgTMOOBO4KSLOAHZx8LasFbUo+7mM8JLmS+qX1L9t27bhaalZmzoZOFuALRGxMteXUQTSM41bsPx+tqn+G5v2nwY8PfCgEfHFiJgZETOPP75l5h6zjutY4ETE/wI/kfS2LJoFrAe+AXwsyz4G/HsufwO4NN+unQPsaNzSmdVNqZwDkn4lIr5X4fhXAF+R9BpgE3AZRbB+XdI84CngI1n3XmA2sBF4Meua1VLZZB1fyF/+W4Db8+3YkCJiLTCzxaZZLeoGcHnJ9ph1ValbtYh4J3AxxTNIv6TbJb23oy0zq7HSzzgR8SRwLXAV8JvADdkj4MOdapxZXZUKHEmnSVpM8T//7wE+EBGn5PLiDrbPrJbKPuPcCHwJuCYiXmoURsTTkq7tSMvMaqxs4MwGXoqIfQCSxgATIuLFiLitY60zq6myzzj3A0c3rU/MMrNRqWzgTIiIFxoruTyxM00yq7+ygbOreXyMpHcALw1S36ynlX3G+RRwh6RG37GpwO90pklm9VcqcCLiUUknA2+j6MX8/Yh4paMtM6uxdubHOQvoy33OkERE3NqRVpnVXNlOnrcBvwysBfZlcQAOHBuVyl5xZgKnZkdMs1Gv7Fu17wG/2MmGmI0kZa84U4D1klYBuxuFETGnI60yq7mygfPZTjbCbKQp+zr6YUlvBmZExP2SJgJjO9s0s/oqO6zgExTJNm7OojcA/1Zy37GZHuruXJ8uaWVm8vxajixF0lG5vjG397V7MmZHStmXA5cD5wI74cCgthMG3eOgKynG8TQsAhZnJs/twLwsnwdsj4i3UIzxWVTy+GZHXNnA2R0RexorksbRIufZQJKmARcAS3JdFIPflmWVgZk8Gxk+lwGzsr5Z7ZQNnIclXQMcnbkG7gC+WWK/64BPA/tz/fXAcxGxN9ebs3UeyOSZ23dk/VdxQkKrg7KBs4Aine064JMUqZwGHfkp6f3AsxGxurm4RdUose1ggRMSWg2Ufau2n2Lo9JfaOPa5wBxJs4EJwCSKK9BkSePyqtKcrbORyXNL3goeC/ysjZ9ndsSUfav2I0mbBn4G2yciro6IaRHRB1wEPBARFwMPAnOz2sBMno0Mn3Ozvrv4WC2101etYQJF9s3jKv7Mq4CvSvorYA05DUh+3yZpI8WV5qKKxzfruLK3av83oOg6Sd8FPlNy/4eAh3J5E3B2izovczAdrlmtlR1W0Dyt4BiKK9BrO9IisxGg7K3a3zUt7wU2Ax8d9taYjRBlb9Xe3emGmI0kZW/V/nSw7RHx98PTHLORoZ23amdRvDIG+ADwHV49Z6fZqNHOQLYzI+J5AEmfBe6IiI93qmFmdVa2y82bgD1N63soMt6YjUplrzi3Aask3UXRf+xDOMONjWJl36r9taT/AH4jiy6LiDWda5ZZvbUz6/REYGdEXE/REXN6h9pkVntlO3n+JUUfs6uzaDzwz51qlFndlb3ifAiYA+yCYiY23OXGRrGygbMnu/gHgKRjOtcks/orGzhfl3QzxSC0T1DMxtbOoDaznlL2rdrfZq6BnRRTfXwmIpZ3tGVmNTZk4EgaC9wXEb8FOFjMKHGrljNNvyjp2HYOLOmNkh6UtEHSE5KuzPLjJC3PhITLJb0uyyXphkxI+PiAMUBmtVK258DLwDpJy8k3awAR8ceD7LMX+LOIeEzSa4HVuf/vAysiYqGkBRQZdK4Czgdm5OdXgZvy26x2ygbOPfkpLSK2Altz+XlJGyhyp10InJfVllIMqb4qy2/Nt3ePSJosaWoex6xWBg0cSW+KiKciYulg9YaSeaDPAFYCJzaCISK2Smqk0j2QkDA1khU6cKx2hnrGOZBYXdKdVX6ApF8A7gQ+FRE7B6vaouzn0kM5k6fVwVCB0/zLfFK7B5c0niJovhIR/5rFz0iamtunAs9meSMhYUNzssIDnMnT6mCowIlDLA8pE6Z/GdgwYGh1c+LBgQkJL823a+cAO/x8Y3U11MuB0yXtpLjyHJ3L5HpExKRB9j0XuITibdzaLLsGWEjRE2Ee8BQHc6ndC8wGNgIvApe1ezJmR8qggRMRlWddi4jv0vq5BWBWi/pBMQ+PWe21Mx7HzJIDx6wCB45ZBQ4cswocOGYVOHDMKnDgmFVQtnf0qNG3oK1O4AdsXnjBMLfE6sxXHLMKHDhmFThwzCpw4JhV4MAxq8CBY1aBA8esAgeOWQUOHLMKatVzQNL7gOuBscCSiFjY5SaVVqXHgXsbjFy1ueJkjup/oMjoeSrwu5JO7W6rzFqr0xXnbGBjRGwCkPRViuye67vaqhpyf7ruq1PgtMrk6dzRw8gBN3zqFDilM3kC83P1BUk/OMTxpgA/Haa2dYQWVdrtiJ9XxXa2q45/X28+1IY6BU7pTJ7AF4c6mKT+iJg5fM2rB59XPdTm5QDwKDBD0nRJrwEuosjuaVY7tbniRMReSX8E3EfxOvofI+KJLjfLrKXaBA5ARNxLkQp3OAx5OzdC+bxqQEXmWTNrR52eccxGjJ4LHEnvk/SDnIR3Qbfb045en3BY0lhJayTdnevTJa3M8/pavhRC0lG5vjG393Wz3a30VOD0QLedxoTDpwDnAJdn+xdQTDg8A1iR6/DqCYfnU0w4XGdXAhua1hcBi/O8tgPzsnwesD0i3gIsznq10lOBQ1O3nYjYAzS67YwIEbE1Ih7L5ecpfskaEw435mFdCnwwlw9MOBwRjwCTG7Pd1Y2kacAFwJJcF/AeYFlWGXhejfNdBszK+rXRa4FzqAl4R5zBJhwGhppwuI6uAz4N7M/11wPPRcTeXG9u+4Hzyu07sn5t9FrglOq2U3fDPeFwt0l6P/BsRKxuLm5RNUpsq4Va/T/OMCjVbafOBptwOKe3b3vC4Ro4F5gjaTYwAZhEcQWaLGlcXlWa2944ry2SxgHHAj878s0+tF674ozobju9OuFwRFwdEdMioo/i7+SBiLgYeBCYm9UGnlfjfOdm/VpdcYiInvpQTMD7P8APgb/odnvabPs7KW5JHgfW5mc2xf39CuDJ/D4u64viLeIPgXXAzG6fQ4lzPA+4O5dPAlZRTJh8B3BUlk/I9Y25/aRut3vgxz0HzCrotVs1syPCgWNWgQPHrAIHjlkFDhyzChw4ZhU4cI4wSfskrW369HW7TWVIukXS3FxeMsJ6nQ+7XutyMxK8FBFvb3cnSWMjYl8nGtSuiPh4t9vQbb7i1ICkPkn/Kemx/Px6lp+XA9tup+gZgKTfk7Qqr1Y35xikQx33BUmLJK2WdL+ksyU9JGmTpDlZZ6ykv5H0aA6G+2SWS9KNktZLuoeDPbLJY8zM5Zsk9efAu8811dks6XN5PuskndyJP7uu6XbXhdH2AfZxsDvNXVk2EZiQyzOA/lw+D9gFTM/1U4BvAuNz/fPApYP8rADOz+W7gG8D44HTgbVZPh+4NpePAvqB6cCHgeUUGYd+CXgOmJv1HiK793Cw+8/YLD8t1zcDV+TyH1Ik0e/6n/9wfXyrduS1ulUbD9wo6e0UgfXWpm2rIuJHuTwLeAfwaI7rOpqDPaVb2QN8K5fXAbsj4hVJ64C+LP9t4LTG8wtFT+QZwLuAf4ni9vBpSQ8c4md8VEV21XHAVIqRt4/ntkbv7tUUgdgzHDj18CfAMxRXgjHAy03bdjUtC1gaEVeXPO4rkf/kUwwg2w0QEfuzu37jmFdExH3NO+YQgEE7MkqaDvw5cFZEbJd0C0UHzYbd+b2PHvtd8zNOPRwLbI2I/cAlFLc9rawA5ko6AQ4k8ThkfuOS7gP+IMcBIemtko4BvgNclM9AU4F3t9h3EkVg75B0IkUOhFGhp/4VGME+D9wp6SMUY1R2taoUEeslXQt8W9IY4BXgcuDHh/Gzl1Dctj2W44G2UYz9v4siJ8A6imEaD7doz39LWgM8AWwC/usw2jGieFiBWQW+VTOrwLdqPUDSSopXyc0uiYh13WjPaOBbNbMKfKtmVoEDx6wCB45ZBQ4cswocOGYV/D84gBGtOC+jZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 123 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fillna(train, train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 123 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 123 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fillna(test, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_median</th>\n",
       "      <th>Age_rs</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Fare_rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>34.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>7.8292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>9.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>8.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>12.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>108.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>22.3583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q   \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S   \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q   \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S   \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S   \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...   \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S   \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C   \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S   \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C   \n",
       "\n",
       "     Age_median  Age_rs  Fare_median   Fare_rs  \n",
       "0          34.5    34.5       7.8292    7.8292  \n",
       "1          47.0    47.0       7.0000    7.0000  \n",
       "2          62.0    62.0       9.6875    9.6875  \n",
       "3          27.0    27.0       8.6625    8.6625  \n",
       "4          22.0    22.0      12.2875   12.2875  \n",
       "..          ...     ...          ...       ...  \n",
       "413        27.0    26.0       8.0500    8.0500  \n",
       "414        39.0    39.0     108.9000  108.9000  \n",
       "415        38.5    38.5       7.2500    7.2500  \n",
       "416        27.0    29.0       8.0500    8.0500  \n",
       "417        27.0    21.0      22.3583   22.3583  \n",
       "\n",
       "[418 rows x 15 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_catcol(df, features):\n",
    "    for features in features:\n",
    "        if df[features].dtypes=='O' and features not in ['Name', 'Ticket', 'Cabin']:\n",
    "            df[features]=df[features].fillna(df[features].mode()[0])\n",
    "            print(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        male\n",
      "1      female\n",
      "2      female\n",
      "3      female\n",
      "4        male\n",
      "        ...  \n",
      "886      male\n",
      "887    female\n",
      "888    female\n",
      "889      male\n",
      "890      male\n",
      "Name: Sex, Length: 891, dtype: object\n",
      "0      S\n",
      "1      C\n",
      "2      S\n",
      "3      S\n",
      "4      S\n",
      "      ..\n",
      "886    S\n",
      "887    S\n",
      "888    S\n",
      "889    C\n",
      "890    Q\n",
      "Name: Embarked, Length: 891, dtype: object\n"
     ]
    }
   ],
   "source": [
    "fill_catcol(train, train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        male\n",
      "1      female\n",
      "2        male\n",
      "3        male\n",
      "4      female\n",
      "        ...  \n",
      "413      male\n",
      "414    female\n",
      "415      male\n",
      "416      male\n",
      "417      male\n",
      "Name: Sex, Length: 418, dtype: object\n",
      "0      Q\n",
      "1      S\n",
      "2      Q\n",
      "3      S\n",
      "4      S\n",
      "      ..\n",
      "413    S\n",
      "414    C\n",
      "415    S\n",
      "416    S\n",
      "417    C\n",
      "Name: Embarked, Length: 418, dtype: object\n"
     ]
    }
   ],
   "source": [
    "fill_catcol(test, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df, features):\n",
    "    for feats in features:\n",
    "        if df[feats].dtype=='O' and len(df[feats].unique())<10:\n",
    "            df[feats+'_le']=preprocessing.LabelEncoder().fit_transform(df[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding(train, train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding(test, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(df, features):\n",
    "    df[features+'_sc']= preprocessing.StandardScaler().fit_transform(df[features].values.reshape(-1,1))\n",
    "    df[features+'_mm']= preprocessing.MinMaxScaler().fit_transform(df[features].values.reshape(-1,1))\n",
    "    df[features+'_mab']= preprocessing.MaxAbsScaler().fit_transform(df[features].values.reshape(-1,1))\n",
    "    df[features+'_rs']= preprocessing.RobustScaler().fit_transform(df[features].values.reshape(-1,1))\n",
    "    #df[features+'ohe']= preprocessing.OneHotEncoder().fit_transform(df[features].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation(train,  'Fare_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>381.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>5081.308859</td>\n",
       "      <td>362212.463781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>62.805625</td>\n",
       "      <td>497.734578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2819.610000</td>\n",
       "      <td>149721.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>521.660125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>2197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>27000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>549.902500</td>\n",
       "      <td>12895.213625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>27000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>60.062500</td>\n",
       "      <td>465.484375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1            2              3\n",
       "0    1.0   7.2500    52.562500     381.078125\n",
       "1    1.0  71.2833  5081.308859  362212.463781\n",
       "2    1.0   7.9250    62.805625     497.734578\n",
       "3    1.0  53.1000  2819.610000  149721.291000\n",
       "4    1.0   8.0500    64.802500     521.660125\n",
       "..   ...      ...          ...            ...\n",
       "886  1.0  13.0000   169.000000    2197.000000\n",
       "887  1.0  30.0000   900.000000   27000.000000\n",
       "888  1.0  23.4500   549.902500   12895.213625\n",
       "889  1.0  30.0000   900.000000   27000.000000\n",
       "890  1.0   7.7500    60.062500     465.484375\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(preprocessing.PolynomialFeatures(degree=3).fit_transform(train['Fare'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_median</th>\n",
       "      <th>Age_rs</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Fare_rs</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>34.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q   \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S   \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q   \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S   \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S   \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...   \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S   \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C   \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S   \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C   \n",
       "\n",
       "     Age_median  Age_rs  Fare_median   Fare_rs  Sex_le  Embarked_le  \n",
       "0          34.5    34.5       7.8292    7.8292       1            1  \n",
       "1          47.0    47.0       7.0000    7.0000       0            2  \n",
       "2          62.0    62.0       9.6875    9.6875       1            1  \n",
       "3          27.0    27.0       8.6625    8.6625       1            2  \n",
       "4          22.0    22.0      12.2875   12.2875       0            2  \n",
       "..          ...     ...          ...       ...     ...          ...  \n",
       "413        27.0    26.0       8.0500    8.0500       1            2  \n",
       "414        39.0    39.0     108.9000  108.9000       0            0  \n",
       "415        38.5    38.5       7.2500    7.2500       1            2  \n",
       "416        27.0    29.0       8.0500    8.0500       1            2  \n",
       "417        27.0    21.0      22.3583   22.3583       1            0  \n",
       "\n",
       "[418 rows x 17 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_trans(df, features):\n",
    "    df[features+'_Poly']=preprocessing.PolynomialFeatures(degree=3).fit_transform(df[features].values.reshape(-1,1))[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_trans(train, 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_trans(test, 'Fare_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_Fare']=np.log(train['Fare']+1)\n",
    "test['log_Fare']=np.log(test['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Fare_rs</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>Fare_median_sc</th>\n",
       "      <th>Fare_median_mm</th>\n",
       "      <th>Fare_median_mab</th>\n",
       "      <th>Fare_median_rs</th>\n",
       "      <th>Fare_Poly</th>\n",
       "      <th>log_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.312011</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>2.110213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>2.461242</td>\n",
       "      <td>5081.308859</td>\n",
       "      <td>4.280593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>-0.282777</td>\n",
       "      <td>62.805625</td>\n",
       "      <td>2.188856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.673732</td>\n",
       "      <td>2819.610000</td>\n",
       "      <td>3.990834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>-0.277363</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>2.202765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>-0.062981</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>2.639057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>...</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.389604</td>\n",
       "      <td>549.902500</td>\n",
       "      <td>3.196630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>-0.290356</td>\n",
       "      <td>60.062500</td>\n",
       "      <td>2.169054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare  ... Fare_median  Fare_rs  Sex_le  \\\n",
       "0        0         A/5 21171   7.2500  ...      7.2500   7.2500       1   \n",
       "1        0          PC 17599  71.2833  ...     71.2833  71.2833       0   \n",
       "2        0  STON/O2. 3101282   7.9250  ...      7.9250   7.9250       0   \n",
       "3        0            113803  53.1000  ...     53.1000  53.1000       0   \n",
       "4        0            373450   8.0500  ...      8.0500   8.0500       1   \n",
       "..     ...               ...      ...  ...         ...      ...     ...   \n",
       "886      0            211536  13.0000  ...     13.0000  13.0000       1   \n",
       "887      0            112053  30.0000  ...     30.0000  30.0000       0   \n",
       "888      2        W./C. 6607  23.4500  ...     23.4500  23.4500       0   \n",
       "889      0            111369  30.0000  ...     30.0000  30.0000       1   \n",
       "890      0            370376   7.7500  ...      7.7500   7.7500       1   \n",
       "\n",
       "     Embarked_le  Fare_median_sc  Fare_median_mm  Fare_median_mab  \\\n",
       "0              2       -0.502445        0.014151         0.014151   \n",
       "1              0        0.786845        0.139136         0.139136   \n",
       "2              2       -0.488854        0.015469         0.015469   \n",
       "3              2        0.420730        0.103644         0.103644   \n",
       "4              2       -0.486337        0.015713         0.015713   \n",
       "..           ...             ...             ...              ...   \n",
       "886            2       -0.386671        0.025374         0.025374   \n",
       "887            2       -0.044381        0.058556         0.058556   \n",
       "888            2       -0.176263        0.045771         0.045771   \n",
       "889            0       -0.044381        0.058556         0.058556   \n",
       "890            1       -0.492378        0.015127         0.015127   \n",
       "\n",
       "     Fare_median_rs    Fare_Poly  log_Fare  \n",
       "0         -0.312011    52.562500  2.110213  \n",
       "1          2.461242  5081.308859  4.280593  \n",
       "2         -0.282777    62.805625  2.188856  \n",
       "3          1.673732  2819.610000  3.990834  \n",
       "4         -0.277363    64.802500  2.202765  \n",
       "..              ...          ...       ...  \n",
       "886       -0.062981   169.000000  2.639057  \n",
       "887        0.673281   900.000000  3.433987  \n",
       "888        0.389604   549.902500  3.196630  \n",
       "889        0.673281   900.000000  3.433987  \n",
       "890       -0.290356    60.062500  2.169054  \n",
       "\n",
       "[891 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age null values: 177\n",
      "Age : False    714\n",
      "True     177\n",
      "Name: Age, dtype: int64\n",
      "Cabin null values: 687\n",
      "Cabin : True     687\n",
      "False    204\n",
      "Name: Cabin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "isnull(train, train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_sc',\n",
       "       'Fare_median_mm', 'Fare_median_mab', 'Fare_median_rs', 'Fare_Poly',\n",
       "       'log_Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age null values: 86\n",
      "Age : False    332\n",
      "True      86\n",
      "Name: Age, dtype: int64\n",
      "Fare null values: 1\n",
      "Fare : False    417\n",
      "True       1\n",
      "Name: Fare, dtype: int64\n",
      "Cabin null values: 327\n",
      "Cabin : True     327\n",
      "False     91\n",
      "Name: Cabin, dtype: int64\n",
      "log_Fare null values: 1\n",
      "log_Fare : False    417\n",
      "True       1\n",
      "Name: log_Fare, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "isnull(test, test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_Poly',\n",
       "       'log_Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_sc',\n",
       "       'Fare_median_mm', 'Fare_median_mab', 'Fare_median_rs', 'Fare_Poly',\n",
       "       'log_Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>4.460000e+02</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.838384e-01</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642e+00</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>2.969912e+01</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>5.230079e-01</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.815937e-01</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.220421e+01</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.936158e+01</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_rs</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.966200e+01</td>\n",
       "      <td>14.611243</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.220421e+01</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_rs</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.220421e+01</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_le</th>\n",
       "      <td>891.0</td>\n",
       "      <td>6.475870e-01</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_le</th>\n",
       "      <td>891.0</td>\n",
       "      <td>1.536476e+00</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_sc</th>\n",
       "      <td>891.0</td>\n",
       "      <td>-4.373606e-17</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>-0.648422</td>\n",
       "      <td>-0.489148</td>\n",
       "      <td>-0.357391</td>\n",
       "      <td>-0.024246</td>\n",
       "      <td>9.667167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_mm</th>\n",
       "      <td>891.0</td>\n",
       "      <td>6.285843e-02</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_mab</th>\n",
       "      <td>891.0</td>\n",
       "      <td>6.285843e-02</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_rs</th>\n",
       "      <td>891.0</td>\n",
       "      <td>7.687447e-01</td>\n",
       "      <td>2.152200</td>\n",
       "      <td>-0.626005</td>\n",
       "      <td>-0.283409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716591</td>\n",
       "      <td>21.562738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_Poly</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.503776e+03</td>\n",
       "      <td>17325.993074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.574641</td>\n",
       "      <td>208.923898</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>262481.209173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.962246e+00</td>\n",
       "      <td>0.969048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.187218</td>\n",
       "      <td>2.737881</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean           std       min         25%  \\\n",
       "PassengerId      891.0  4.460000e+02    257.353842  1.000000  223.500000   \n",
       "Survived         891.0  3.838384e-01      0.486592  0.000000    0.000000   \n",
       "Pclass           891.0  2.308642e+00      0.836071  1.000000    2.000000   \n",
       "Age              714.0  2.969912e+01     14.526497  0.420000   20.125000   \n",
       "SibSp            891.0  5.230079e-01      1.102743  0.000000    0.000000   \n",
       "Parch            891.0  3.815937e-01      0.806057  0.000000    0.000000   \n",
       "Fare             891.0  3.220421e+01     49.693429  0.000000    7.910400   \n",
       "Age_median       891.0  2.936158e+01     13.019697  0.420000   22.000000   \n",
       "Age_rs           891.0  2.966200e+01     14.611243  0.420000   20.000000   \n",
       "Fare_median      891.0  3.220421e+01     49.693429  0.000000    7.910400   \n",
       "Fare_rs          891.0  3.220421e+01     49.693429  0.000000    7.910400   \n",
       "Sex_le           891.0  6.475870e-01      0.477990  0.000000    0.000000   \n",
       "Embarked_le      891.0  1.536476e+00      0.791503  0.000000    1.000000   \n",
       "Fare_median_sc   891.0 -4.373606e-17      1.000562 -0.648422   -0.489148   \n",
       "Fare_median_mm   891.0  6.285843e-02      0.096995  0.000000    0.015440   \n",
       "Fare_median_mab  891.0  6.285843e-02      0.096995  0.000000    0.015440   \n",
       "Fare_median_rs   891.0  7.687447e-01      2.152200 -0.626005   -0.283409   \n",
       "Fare_Poly        891.0  3.503776e+03  17325.993074  0.000000   62.574641   \n",
       "log_Fare         891.0  2.962246e+00      0.969048  0.000000    2.187218   \n",
       "\n",
       "                        50%         75%            max  \n",
       "PassengerId      446.000000  668.500000     891.000000  \n",
       "Survived           0.000000    1.000000       1.000000  \n",
       "Pclass             3.000000    3.000000       3.000000  \n",
       "Age               28.000000   38.000000      80.000000  \n",
       "SibSp              0.000000    1.000000       8.000000  \n",
       "Parch              0.000000    0.000000       6.000000  \n",
       "Fare              14.454200   31.000000     512.329200  \n",
       "Age_median        28.000000   35.000000      80.000000  \n",
       "Age_rs            28.000000   38.000000      80.000000  \n",
       "Fare_median       14.454200   31.000000     512.329200  \n",
       "Fare_rs           14.454200   31.000000     512.329200  \n",
       "Sex_le             1.000000    1.000000       1.000000  \n",
       "Embarked_le        2.000000    2.000000       2.000000  \n",
       "Fare_median_sc    -0.357391   -0.024246       9.667167  \n",
       "Fare_median_mm     0.028213    0.060508       1.000000  \n",
       "Fare_median_mab    0.028213    0.060508       1.000000  \n",
       "Fare_median_rs     0.000000    0.716591      21.562738  \n",
       "Fare_Poly        208.923898  961.000000  262481.209173  \n",
       "log_Fare           2.737881    3.465736       6.240917  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_median</th>\n",
       "      <th>Age_rs</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Fare_rs</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>Fare_median_Poly</th>\n",
       "      <th>log_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "      <td>29.599282</td>\n",
       "      <td>30.179426</td>\n",
       "      <td>35.576535</td>\n",
       "      <td>35.708344</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.401914</td>\n",
       "      <td>4377.461560</td>\n",
       "      <td>3.016087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "      <td>12.703770</td>\n",
       "      <td>13.969243</td>\n",
       "      <td>55.850103</td>\n",
       "      <td>55.865146</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.854496</td>\n",
       "      <td>17277.476288</td>\n",
       "      <td>0.967998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.343658</td>\n",
       "      <td>2.185579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>208.923898</td>\n",
       "      <td>2.737881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>31.471875</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>990.481289</td>\n",
       "      <td>3.481240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>262481.209173</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch  \\\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000   \n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   \n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   \n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000   \n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000   \n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   \n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   \n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000   \n",
       "\n",
       "             Fare  Age_median      Age_rs  Fare_median     Fare_rs  \\\n",
       "count  417.000000  418.000000  418.000000   418.000000  418.000000   \n",
       "mean    35.627188   29.599282   30.179426    35.576535   35.708344   \n",
       "std     55.907576   12.703770   13.969243    55.850103   55.865146   \n",
       "min      0.000000    0.170000    0.170000     0.000000    0.000000   \n",
       "25%      7.895800   23.000000   21.000000     7.895800    7.895800   \n",
       "50%     14.454200   27.000000   27.000000    14.454200   14.454200   \n",
       "75%     31.500000   35.750000   39.000000    31.471875   31.500000   \n",
       "max    512.329200   76.000000   76.000000   512.329200  512.329200   \n",
       "\n",
       "           Sex_le  Embarked_le  Fare_median_Poly    log_Fare  \n",
       "count  418.000000   418.000000        418.000000  417.000000  \n",
       "mean     0.636364     1.401914       4377.461560    3.016087  \n",
       "std      0.481622     0.854496      17277.476288    0.967998  \n",
       "min      0.000000     0.000000          0.000000    0.000000  \n",
       "25%      0.000000     1.000000         62.343658    2.185579  \n",
       "50%      1.000000     2.000000        208.923898    2.737881  \n",
       "75%      1.000000     2.000000        990.481289    3.481240  \n",
       "max      1.000000     2.000000     262481.209173    6.240917  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Fare_rs</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>Fare_median_sc</th>\n",
       "      <th>Fare_median_mm</th>\n",
       "      <th>Fare_median_mab</th>\n",
       "      <th>Fare_median_rs</th>\n",
       "      <th>Fare_Poly</th>\n",
       "      <th>log_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.312011</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>2.110213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>2.461242</td>\n",
       "      <td>5081.308859</td>\n",
       "      <td>4.280593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>-0.282777</td>\n",
       "      <td>62.805625</td>\n",
       "      <td>2.188856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.673732</td>\n",
       "      <td>2819.610000</td>\n",
       "      <td>3.990834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>-0.277363</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>2.202765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>-0.062981</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>2.639057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>...</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.389604</td>\n",
       "      <td>549.902500</td>\n",
       "      <td>3.196630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>-0.290356</td>\n",
       "      <td>60.062500</td>\n",
       "      <td>2.169054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare  ... Fare_median  Fare_rs  Sex_le  \\\n",
       "0        0         A/5 21171   7.2500  ...      7.2500   7.2500       1   \n",
       "1        0          PC 17599  71.2833  ...     71.2833  71.2833       0   \n",
       "2        0  STON/O2. 3101282   7.9250  ...      7.9250   7.9250       0   \n",
       "3        0            113803  53.1000  ...     53.1000  53.1000       0   \n",
       "4        0            373450   8.0500  ...      8.0500   8.0500       1   \n",
       "..     ...               ...      ...  ...         ...      ...     ...   \n",
       "886      0            211536  13.0000  ...     13.0000  13.0000       1   \n",
       "887      0            112053  30.0000  ...     30.0000  30.0000       0   \n",
       "888      2        W./C. 6607  23.4500  ...     23.4500  23.4500       0   \n",
       "889      0            111369  30.0000  ...     30.0000  30.0000       1   \n",
       "890      0            370376   7.7500  ...      7.7500   7.7500       1   \n",
       "\n",
       "     Embarked_le  Fare_median_sc  Fare_median_mm  Fare_median_mab  \\\n",
       "0              2       -0.502445        0.014151         0.014151   \n",
       "1              0        0.786845        0.139136         0.139136   \n",
       "2              2       -0.488854        0.015469         0.015469   \n",
       "3              2        0.420730        0.103644         0.103644   \n",
       "4              2       -0.486337        0.015713         0.015713   \n",
       "..           ...             ...             ...              ...   \n",
       "886            2       -0.386671        0.025374         0.025374   \n",
       "887            2       -0.044381        0.058556         0.058556   \n",
       "888            2       -0.176263        0.045771         0.045771   \n",
       "889            0       -0.044381        0.058556         0.058556   \n",
       "890            1       -0.492378        0.015127         0.015127   \n",
       "\n",
       "     Fare_median_rs    Fare_Poly  log_Fare  \n",
       "0         -0.312011    52.562500  2.110213  \n",
       "1          2.461242  5081.308859  4.280593  \n",
       "2         -0.282777    62.805625  2.188856  \n",
       "3          1.673732  2819.610000  3.990834  \n",
       "4         -0.277363    64.802500  2.202765  \n",
       "..              ...          ...       ...  \n",
       "886       -0.062981   169.000000  2.639057  \n",
       "887        0.673281   900.000000  3.433987  \n",
       "888        0.389604   549.902500  3.196630  \n",
       "889        0.673281   900.000000  3.433987  \n",
       "890       -0.290356    60.062500  2.169054  \n",
       "\n",
       "[891 rows x 24 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillna(train, train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_median</th>\n",
       "      <th>Fare_rs</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>Fare_median_sc</th>\n",
       "      <th>Fare_median_mm</th>\n",
       "      <th>Fare_median_mab</th>\n",
       "      <th>Fare_median_rs</th>\n",
       "      <th>Fare_Poly</th>\n",
       "      <th>log_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.312011</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>2.110213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>2.461242</td>\n",
       "      <td>5081.308859</td>\n",
       "      <td>4.280593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>-0.282777</td>\n",
       "      <td>62.805625</td>\n",
       "      <td>2.188856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.673732</td>\n",
       "      <td>2819.610000</td>\n",
       "      <td>3.990834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>-0.277363</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>2.202765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>-0.062981</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>2.639057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>...</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0.389604</td>\n",
       "      <td>549.902500</td>\n",
       "      <td>3.196630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>-0.290356</td>\n",
       "      <td>60.062500</td>\n",
       "      <td>2.169054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare  ... Fare_median  Fare_rs  Sex_le  \\\n",
       "0        0         A/5 21171   7.2500  ...      7.2500   7.2500       1   \n",
       "1        0          PC 17599  71.2833  ...     71.2833  71.2833       0   \n",
       "2        0  STON/O2. 3101282   7.9250  ...      7.9250   7.9250       0   \n",
       "3        0            113803  53.1000  ...     53.1000  53.1000       0   \n",
       "4        0            373450   8.0500  ...      8.0500   8.0500       1   \n",
       "..     ...               ...      ...  ...         ...      ...     ...   \n",
       "886      0            211536  13.0000  ...     13.0000  13.0000       1   \n",
       "887      0            112053  30.0000  ...     30.0000  30.0000       0   \n",
       "888      2        W./C. 6607  23.4500  ...     23.4500  23.4500       0   \n",
       "889      0            111369  30.0000  ...     30.0000  30.0000       1   \n",
       "890      0            370376   7.7500  ...      7.7500   7.7500       1   \n",
       "\n",
       "     Embarked_le  Fare_median_sc  Fare_median_mm  Fare_median_mab  \\\n",
       "0              2       -0.502445        0.014151         0.014151   \n",
       "1              0        0.786845        0.139136         0.139136   \n",
       "2              2       -0.488854        0.015469         0.015469   \n",
       "3              2        0.420730        0.103644         0.103644   \n",
       "4              2       -0.486337        0.015713         0.015713   \n",
       "..           ...             ...             ...              ...   \n",
       "886            2       -0.386671        0.025374         0.025374   \n",
       "887            2       -0.044381        0.058556         0.058556   \n",
       "888            2       -0.176263        0.045771         0.045771   \n",
       "889            0       -0.044381        0.058556         0.058556   \n",
       "890            1       -0.492378        0.015127         0.015127   \n",
       "\n",
       "     Fare_median_rs    Fare_Poly  log_Fare  \n",
       "0         -0.312011    52.562500  2.110213  \n",
       "1          2.461242  5081.308859  4.280593  \n",
       "2         -0.282777    62.805625  2.188856  \n",
       "3          1.673732  2819.610000  3.990834  \n",
       "4         -0.277363    64.802500  2.202765  \n",
       "..              ...          ...       ...  \n",
       "886       -0.062981   169.000000  2.639057  \n",
       "887        0.673281   900.000000  3.433987  \n",
       "888        0.389604   549.902500  3.196630  \n",
       "889        0.673281   900.000000  3.433987  \n",
       "890       -0.290356    60.062500  2.169054  \n",
       "\n",
       "[891 rows x 24 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>4.460000e+02</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.838384e-01</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642e+00</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>2.969912e+01</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>5.230079e-01</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.815937e-01</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.220421e+01</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.936158e+01</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_rs</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.966200e+01</td>\n",
       "      <td>14.611243</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.220421e+01</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_rs</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.220421e+01</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_le</th>\n",
       "      <td>891.0</td>\n",
       "      <td>6.475870e-01</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_le</th>\n",
       "      <td>891.0</td>\n",
       "      <td>1.536476e+00</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_sc</th>\n",
       "      <td>891.0</td>\n",
       "      <td>-4.373606e-17</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>-0.648422</td>\n",
       "      <td>-0.489148</td>\n",
       "      <td>-0.357391</td>\n",
       "      <td>-0.024246</td>\n",
       "      <td>9.667167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_mm</th>\n",
       "      <td>891.0</td>\n",
       "      <td>6.285843e-02</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_mab</th>\n",
       "      <td>891.0</td>\n",
       "      <td>6.285843e-02</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_rs</th>\n",
       "      <td>891.0</td>\n",
       "      <td>7.687447e-01</td>\n",
       "      <td>2.152200</td>\n",
       "      <td>-0.626005</td>\n",
       "      <td>-0.283409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716591</td>\n",
       "      <td>21.562738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_Poly</th>\n",
       "      <td>891.0</td>\n",
       "      <td>3.503776e+03</td>\n",
       "      <td>17325.993074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.574641</td>\n",
       "      <td>208.923898</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>262481.209173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.962246e+00</td>\n",
       "      <td>0.969048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.187218</td>\n",
       "      <td>2.737881</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean           std       min         25%  \\\n",
       "PassengerId      891.0  4.460000e+02    257.353842  1.000000  223.500000   \n",
       "Survived         891.0  3.838384e-01      0.486592  0.000000    0.000000   \n",
       "Pclass           891.0  2.308642e+00      0.836071  1.000000    2.000000   \n",
       "Age              714.0  2.969912e+01     14.526497  0.420000   20.125000   \n",
       "SibSp            891.0  5.230079e-01      1.102743  0.000000    0.000000   \n",
       "Parch            891.0  3.815937e-01      0.806057  0.000000    0.000000   \n",
       "Fare             891.0  3.220421e+01     49.693429  0.000000    7.910400   \n",
       "Age_median       891.0  2.936158e+01     13.019697  0.420000   22.000000   \n",
       "Age_rs           891.0  2.966200e+01     14.611243  0.420000   20.000000   \n",
       "Fare_median      891.0  3.220421e+01     49.693429  0.000000    7.910400   \n",
       "Fare_rs          891.0  3.220421e+01     49.693429  0.000000    7.910400   \n",
       "Sex_le           891.0  6.475870e-01      0.477990  0.000000    0.000000   \n",
       "Embarked_le      891.0  1.536476e+00      0.791503  0.000000    1.000000   \n",
       "Fare_median_sc   891.0 -4.373606e-17      1.000562 -0.648422   -0.489148   \n",
       "Fare_median_mm   891.0  6.285843e-02      0.096995  0.000000    0.015440   \n",
       "Fare_median_mab  891.0  6.285843e-02      0.096995  0.000000    0.015440   \n",
       "Fare_median_rs   891.0  7.687447e-01      2.152200 -0.626005   -0.283409   \n",
       "Fare_Poly        891.0  3.503776e+03  17325.993074  0.000000   62.574641   \n",
       "log_Fare         891.0  2.962246e+00      0.969048  0.000000    2.187218   \n",
       "\n",
       "                        50%         75%            max  \n",
       "PassengerId      446.000000  668.500000     891.000000  \n",
       "Survived           0.000000    1.000000       1.000000  \n",
       "Pclass             3.000000    3.000000       3.000000  \n",
       "Age               28.000000   38.000000      80.000000  \n",
       "SibSp              0.000000    1.000000       8.000000  \n",
       "Parch              0.000000    0.000000       6.000000  \n",
       "Fare              14.454200   31.000000     512.329200  \n",
       "Age_median        28.000000   35.000000      80.000000  \n",
       "Age_rs            28.000000   38.000000      80.000000  \n",
       "Fare_median       14.454200   31.000000     512.329200  \n",
       "Fare_rs           14.454200   31.000000     512.329200  \n",
       "Sex_le             1.000000    1.000000       1.000000  \n",
       "Embarked_le        2.000000    2.000000       2.000000  \n",
       "Fare_median_sc    -0.357391   -0.024246       9.667167  \n",
       "Fare_median_mm     0.028213    0.060508       1.000000  \n",
       "Fare_median_mab    0.028213    0.060508       1.000000  \n",
       "Fare_median_rs     0.000000    0.716591      21.562738  \n",
       "Fare_Poly        208.923898  961.000000  262481.209173  \n",
       "log_Fare           2.737881    3.465736       6.240917  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation(train, 'log_Fare')\n",
    "transformation(train, 'Age_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation(test, 'log_Fare')\n",
    "transformation(test, 'Age_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_sc',\n",
       "       'Fare_median_mm', 'Fare_median_mab', 'Fare_median_rs', 'Fare_Poly',\n",
       "       'log_Fare', 'log_Fare_sc', 'log_Fare_mm', 'log_Fare_mab', 'log_Fare_rs',\n",
       "       'Age_median_sc', 'Age_median_mm', 'Age_median_mab', 'Age_median_rs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_median_Poly</th>\n",
       "      <th>log_Fare</th>\n",
       "      <th>log_Fare_sc</th>\n",
       "      <th>log_Fare_mm</th>\n",
       "      <th>log_Fare_mab</th>\n",
       "      <th>log_Fare_rs</th>\n",
       "      <th>Age_median_sc</th>\n",
       "      <th>Age_median_mm</th>\n",
       "      <th>Age_median_mab</th>\n",
       "      <th>Age_median_rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>61.296373</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>-0.866767</td>\n",
       "      <td>0.348997</td>\n",
       "      <td>0.348997</td>\n",
       "      <td>-0.432070</td>\n",
       "      <td>0.386231</td>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>-0.968773</td>\n",
       "      <td>0.333195</td>\n",
       "      <td>0.333195</td>\n",
       "      <td>-0.508188</td>\n",
       "      <td>1.371370</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>1.568627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>93.847656</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>-0.669205</td>\n",
       "      <td>0.379604</td>\n",
       "      <td>0.379604</td>\n",
       "      <td>-0.284647</td>\n",
       "      <td>2.553537</td>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>2.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75.038906</td>\n",
       "      <td>2.268252</td>\n",
       "      <td>-0.773486</td>\n",
       "      <td>0.363449</td>\n",
       "      <td>0.363449</td>\n",
       "      <td>-0.362462</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>150.982656</td>\n",
       "      <td>2.586824</td>\n",
       "      <td>-0.443987</td>\n",
       "      <td>0.414494</td>\n",
       "      <td>0.414494</td>\n",
       "      <td>-0.116587</td>\n",
       "      <td>-0.598908</td>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>-0.392157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>-0.841220</td>\n",
       "      <td>0.352955</td>\n",
       "      <td>0.352955</td>\n",
       "      <td>-0.413006</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>...</td>\n",
       "      <td>11859.210000</td>\n",
       "      <td>4.699571</td>\n",
       "      <td>1.741229</td>\n",
       "      <td>0.753026</td>\n",
       "      <td>0.753026</td>\n",
       "      <td>1.514046</td>\n",
       "      <td>0.740881</td>\n",
       "      <td>0.512066</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>52.562500</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>-0.936946</td>\n",
       "      <td>0.338125</td>\n",
       "      <td>0.338125</td>\n",
       "      <td>-0.484438</td>\n",
       "      <td>0.701476</td>\n",
       "      <td>0.505473</td>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>-0.841220</td>\n",
       "      <td>0.352955</td>\n",
       "      <td>0.352955</td>\n",
       "      <td>-0.413006</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>499.893579</td>\n",
       "      <td>3.150952</td>\n",
       "      <td>0.139492</td>\n",
       "      <td>0.504886</td>\n",
       "      <td>0.504886</td>\n",
       "      <td>0.318811</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin  ...  \\\n",
       "0      male  34.5      0      0              330911    7.8292   NaN  ...   \n",
       "1    female  47.0      1      0              363272    7.0000   NaN  ...   \n",
       "2      male  62.0      0      0              240276    9.6875   NaN  ...   \n",
       "3      male  27.0      0      0              315154    8.6625   NaN  ...   \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN  ...   \n",
       "..      ...   ...    ...    ...                 ...       ...   ...  ...   \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN  ...   \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105  ...   \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN  ...   \n",
       "416    male   NaN      0      0              359309    8.0500   NaN  ...   \n",
       "417    male   NaN      1      1                2668   22.3583   NaN  ...   \n",
       "\n",
       "    Fare_median_Poly  log_Fare  log_Fare_sc  log_Fare_mm  log_Fare_mab  \\\n",
       "0          61.296373  2.178064    -0.866767     0.348997      0.348997   \n",
       "1          49.000000  2.079442    -0.968773     0.333195      0.333195   \n",
       "2          93.847656  2.369075    -0.669205     0.379604      0.379604   \n",
       "3          75.038906  2.268252    -0.773486     0.363449      0.363449   \n",
       "4         150.982656  2.586824    -0.443987     0.414494      0.414494   \n",
       "..               ...       ...          ...          ...           ...   \n",
       "413        64.802500  2.202765    -0.841220     0.352955      0.352955   \n",
       "414     11859.210000  4.699571     1.741229     0.753026      0.753026   \n",
       "415        52.562500  2.110213    -0.936946     0.338125      0.338125   \n",
       "416        64.802500  2.202765    -0.841220     0.352955      0.352955   \n",
       "417       499.893579  3.150952     0.139492     0.504886      0.504886   \n",
       "\n",
       "     log_Fare_rs  Age_median_sc  Age_median_mm  Age_median_mab  Age_median_rs  \n",
       "0      -0.432070       0.386231       0.452723        0.453947       0.588235  \n",
       "1      -0.508188       1.371370       0.617566        0.618421       1.568627  \n",
       "2      -0.284647       2.553537       0.815377        0.815789       2.745098  \n",
       "3      -0.362462      -0.204852       0.353818        0.355263       0.000000  \n",
       "4      -0.116587      -0.598908       0.287881        0.289474      -0.392157  \n",
       "..           ...            ...            ...             ...            ...  \n",
       "413    -0.413006      -0.204852       0.353818        0.355263       0.000000  \n",
       "414     1.514046       0.740881       0.512066        0.513158       0.941176  \n",
       "415    -0.484438       0.701476       0.505473        0.506579       0.901961  \n",
       "416    -0.413006      -0.204852       0.353818        0.355263       0.000000  \n",
       "417     0.318811      -0.204852       0.353818        0.355263       0.000000  \n",
       "\n",
       "[418 rows x 27 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>418.0</td>\n",
       "      <td>1.100500e+03</td>\n",
       "      <td>120.810458</td>\n",
       "      <td>892.000000</td>\n",
       "      <td>996.250000</td>\n",
       "      <td>1100.500000</td>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>418.0</td>\n",
       "      <td>2.265550e+00</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>332.0</td>\n",
       "      <td>3.027259e+01</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>418.0</td>\n",
       "      <td>4.473684e-01</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.923445e-01</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>417.0</td>\n",
       "      <td>3.562719e+01</td>\n",
       "      <td>55.907576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median</th>\n",
       "      <td>418.0</td>\n",
       "      <td>2.959928e+01</td>\n",
       "      <td>12.703770</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_rs</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.017943e+01</td>\n",
       "      <td>13.969243</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.557654e+01</td>\n",
       "      <td>55.850103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.471875</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_rs</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.570834e+01</td>\n",
       "      <td>55.865146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_le</th>\n",
       "      <td>418.0</td>\n",
       "      <td>6.363636e-01</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_le</th>\n",
       "      <td>418.0</td>\n",
       "      <td>1.401914e+00</td>\n",
       "      <td>0.854496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_median_Poly</th>\n",
       "      <td>418.0</td>\n",
       "      <td>4.377462e+03</td>\n",
       "      <td>17277.476288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.343658</td>\n",
       "      <td>208.923898</td>\n",
       "      <td>990.481289</td>\n",
       "      <td>262481.209173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare</th>\n",
       "      <td>417.0</td>\n",
       "      <td>3.016087e+00</td>\n",
       "      <td>0.967998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.185579</td>\n",
       "      <td>2.737881</td>\n",
       "      <td>3.481240</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare_sc</th>\n",
       "      <td>417.0</td>\n",
       "      <td>3.599572e-16</td>\n",
       "      <td>1.001201</td>\n",
       "      <td>-3.119542</td>\n",
       "      <td>-0.858995</td>\n",
       "      <td>-0.287749</td>\n",
       "      <td>0.481109</td>\n",
       "      <td>3.335445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare_mm</th>\n",
       "      <td>417.0</td>\n",
       "      <td>4.832762e-01</td>\n",
       "      <td>0.155105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>0.438698</td>\n",
       "      <td>0.557809</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare_mab</th>\n",
       "      <td>417.0</td>\n",
       "      <td>4.832762e-01</td>\n",
       "      <td>0.155105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350202</td>\n",
       "      <td>0.438698</td>\n",
       "      <td>0.557809</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_Fare_rs</th>\n",
       "      <td>417.0</td>\n",
       "      <td>2.147213e-01</td>\n",
       "      <td>0.747107</td>\n",
       "      <td>-2.113115</td>\n",
       "      <td>-0.426270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573730</td>\n",
       "      <td>2.703668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median_sc</th>\n",
       "      <td>418.0</td>\n",
       "      <td>8.698518e-17</td>\n",
       "      <td>1.001198</td>\n",
       "      <td>-2.319355</td>\n",
       "      <td>-0.520097</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>0.484745</td>\n",
       "      <td>3.656893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median_mm</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.880955e-01</td>\n",
       "      <td>0.167530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301068</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.469207</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median_mab</th>\n",
       "      <td>418.0</td>\n",
       "      <td>3.894642e-01</td>\n",
       "      <td>0.167155</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.470395</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_median_rs</th>\n",
       "      <td>418.0</td>\n",
       "      <td>2.038653e-01</td>\n",
       "      <td>0.996374</td>\n",
       "      <td>-2.104314</td>\n",
       "      <td>-0.313725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>3.843137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean           std         min         25%  \\\n",
       "PassengerId       418.0  1.100500e+03    120.810458  892.000000  996.250000   \n",
       "Pclass            418.0  2.265550e+00      0.841838    1.000000    1.000000   \n",
       "Age               332.0  3.027259e+01     14.181209    0.170000   21.000000   \n",
       "SibSp             418.0  4.473684e-01      0.896760    0.000000    0.000000   \n",
       "Parch             418.0  3.923445e-01      0.981429    0.000000    0.000000   \n",
       "Fare              417.0  3.562719e+01     55.907576    0.000000    7.895800   \n",
       "Age_median        418.0  2.959928e+01     12.703770    0.170000   23.000000   \n",
       "Age_rs            418.0  3.017943e+01     13.969243    0.170000   21.000000   \n",
       "Fare_median       418.0  3.557654e+01     55.850103    0.000000    7.895800   \n",
       "Fare_rs           418.0  3.570834e+01     55.865146    0.000000    7.895800   \n",
       "Sex_le            418.0  6.363636e-01      0.481622    0.000000    0.000000   \n",
       "Embarked_le       418.0  1.401914e+00      0.854496    0.000000    1.000000   \n",
       "Fare_median_Poly  418.0  4.377462e+03  17277.476288    0.000000   62.343658   \n",
       "log_Fare          417.0  3.016087e+00      0.967998    0.000000    2.185579   \n",
       "log_Fare_sc       417.0  3.599572e-16      1.001201   -3.119542   -0.858995   \n",
       "log_Fare_mm       417.0  4.832762e-01      0.155105    0.000000    0.350202   \n",
       "log_Fare_mab      417.0  4.832762e-01      0.155105    0.000000    0.350202   \n",
       "log_Fare_rs       417.0  2.147213e-01      0.747107   -2.113115   -0.426270   \n",
       "Age_median_sc     418.0  8.698518e-17      1.001198   -2.319355   -0.520097   \n",
       "Age_median_mm     418.0  3.880955e-01      0.167530    0.000000    0.301068   \n",
       "Age_median_mab    418.0  3.894642e-01      0.167155    0.002237    0.302632   \n",
       "Age_median_rs     418.0  2.038653e-01      0.996374   -2.104314   -0.313725   \n",
       "\n",
       "                          50%          75%            max  \n",
       "PassengerId       1100.500000  1204.750000    1309.000000  \n",
       "Pclass               3.000000     3.000000       3.000000  \n",
       "Age                 27.000000    39.000000      76.000000  \n",
       "SibSp                0.000000     1.000000       8.000000  \n",
       "Parch                0.000000     0.000000       9.000000  \n",
       "Fare                14.454200    31.500000     512.329200  \n",
       "Age_median          27.000000    35.750000      76.000000  \n",
       "Age_rs              27.000000    39.000000      76.000000  \n",
       "Fare_median         14.454200    31.471875     512.329200  \n",
       "Fare_rs             14.454200    31.500000     512.329200  \n",
       "Sex_le               1.000000     1.000000       1.000000  \n",
       "Embarked_le          2.000000     2.000000       2.000000  \n",
       "Fare_median_Poly   208.923898   990.481289  262481.209173  \n",
       "log_Fare             2.737881     3.481240       6.240917  \n",
       "log_Fare_sc         -0.287749     0.481109       3.335445  \n",
       "log_Fare_mm          0.438698     0.557809       1.000000  \n",
       "log_Fare_mab         0.438698     0.557809       1.000000  \n",
       "log_Fare_rs          0.000000     0.573730       2.703668  \n",
       "Age_median_sc       -0.204852     0.484745       3.656893  \n",
       "Age_median_mm        0.353818     0.469207       1.000000  \n",
       "Age_median_mab       0.355263     0.470395       1.000000  \n",
       "Age_median_rs        0.000000     0.686275       3.843137  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation(train, 'SibSp')\n",
    "transformation(train, 'Parch')\n",
    "transformation(test, 'SibSp')\n",
    "transformation(test, 'Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_sc',\n",
       "       'Fare_median_mm', 'Fare_median_mab', 'Fare_median_rs', 'Fare_Poly',\n",
       "       'log_Fare', 'log_Fare_sc', 'log_Fare_mm', 'log_Fare_mab', 'log_Fare_rs',\n",
       "       'Age_median_sc', 'Age_median_mm', 'Age_median_mab', 'Age_median_rs',\n",
       "       'SibSp_sc', 'SibSp_mm', 'SibSp_mab', 'SibSp_rs', 'Parch_sc', 'Parch_mm',\n",
       "       'Parch_mab', 'Parch_rs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train[['Pclass', 'Age_median_sc', 'SibSp_mm', 'Parch_mm', 'Sex_le', 'Embarked_le', 'log_Fare_sc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train1.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age_median_sc</th>\n",
       "      <th>SibSp_mm</th>\n",
       "      <th>Parch_mm</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>log_Fare_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.879741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.361220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.798540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.062038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.784179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.181487</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.333698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.796286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.487082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.242007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0.202762</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.818987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Age_median_sc  SibSp_mm  Parch_mm  Sex_le  Embarked_le  \\\n",
       "0         3      -0.565736     0.125  0.000000       1            2   \n",
       "1         1       0.663861     0.125  0.000000       0            0   \n",
       "2         3      -0.258337     0.000  0.000000       0            2   \n",
       "3         1       0.433312     0.125  0.000000       0            2   \n",
       "4         3       0.433312     0.000  0.000000       1            2   \n",
       "..      ...            ...       ...       ...     ...          ...   \n",
       "886       2      -0.181487     0.000  0.000000       1            2   \n",
       "887       1      -0.796286     0.000  0.000000       0            2   \n",
       "888       3      -0.104637     0.125  0.333333       0            2   \n",
       "889       1      -0.258337     0.000  0.000000       1            0   \n",
       "890       3       0.202762     0.000  0.000000       1            1   \n",
       "\n",
       "     log_Fare_sc  \n",
       "0      -0.879741  \n",
       "1       1.361220  \n",
       "2      -0.798540  \n",
       "3       1.062038  \n",
       "4      -0.784179  \n",
       "..           ...  \n",
       "886    -0.333698  \n",
       "887     0.487082  \n",
       "888     0.242007  \n",
       "889     0.487082  \n",
       "890    -0.818987  \n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train):\n",
    "    global log\n",
    "    log=linear_model.LogisticRegression()\n",
    "    log.fit(X_train, y_train)\n",
    "    print(log.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963483146067416\n"
     ]
    }
   ],
   "source": [
    "model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "model(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age_median_sc</th>\n",
       "      <th>SibSp_mm</th>\n",
       "      <th>Parch_mm</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>log_Fare_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.317416</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.653090</td>\n",
       "      <td>1.547753</td>\n",
       "      <td>-0.003978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.833767</td>\n",
       "      <td>1.007344</td>\n",
       "      <td>0.142605</td>\n",
       "      <td>0.136895</td>\n",
       "      <td>0.476321</td>\n",
       "      <td>0.781625</td>\n",
       "      <td>0.992865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.204944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.058578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.799386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.231524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.528699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.891554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.385294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass  Age_median_sc    SibSp_mm    Parch_mm      Sex_le  \\\n",
       "count  712.000000     712.000000  712.000000  712.000000  712.000000   \n",
       "mean     2.317416       0.002920    0.066187    0.065309    0.653090   \n",
       "std      0.833767       1.007344    0.142605    0.136895    0.476321   \n",
       "min      1.000000      -2.204944    0.000000    0.000000    0.000000   \n",
       "25%      2.000000      -0.565736    0.000000    0.000000    0.000000   \n",
       "50%      3.000000      -0.104637    0.000000    0.000000    1.000000   \n",
       "75%      3.000000       0.433312    0.125000    0.000000    1.000000   \n",
       "max      3.000000       3.891554    1.000000    1.000000    1.000000   \n",
       "\n",
       "       Embarked_le  log_Fare_sc  \n",
       "count   712.000000   712.000000  \n",
       "mean      1.547753    -0.003978  \n",
       "std       0.781625     0.992865  \n",
       "min       0.000000    -3.058578  \n",
       "25%       1.000000    -0.799386  \n",
       "50%       2.000000    -0.231524  \n",
       "75%       2.000000     0.528699  \n",
       "max       2.000000     3.385294  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817415730337079"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_sc',\n",
       "       'Fare_median_mm', 'Fare_median_mab', 'Fare_median_rs', 'Fare_Poly',\n",
       "       'log_Fare', 'log_Fare_sc', 'log_Fare_mm', 'log_Fare_mab', 'log_Fare_rs',\n",
       "       'Age_median_sc', 'Age_median_mm', 'Age_median_mab', 'Age_median_rs',\n",
       "       'SibSp_sc', 'SibSp_mm', 'SibSp_mab', 'SibSp_rs', 'Parch_sc', 'Parch_mm',\n",
       "       'Parch_mab', 'Parch_rs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=train[['Pclass', 'Age_median_sc', 'SibSp', 'Parch', 'Sex_le', 'Embarked_le', 'log_Fare_sc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=model_selection.train_test_split(X1, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7935393258426966\n"
     ]
    }
   ],
   "source": [
    "model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8268156424581006\n"
     ]
    }
   ],
   "source": [
    "model(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfmodel(X_train, y_train):\n",
    "    rf=ensemble.RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('train score', rf.score(X_train, y_train))\n",
    "    print('val score', rf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9817415730337079\n",
      "val score 0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "rfmodel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=train[['Pclass', 'Age_median_rs', 'SibSp', 'Parch', 'Sex_le', 'Embarked_le', 'log_Fare_rs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=model_selection.train_test_split(X2, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9817415730337079\n",
      "val score 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "rfmodel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_test['log_Fare_rs']=x_test['log_Fare_rs'].fillna(x_test['log_Fare_rs'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass           0\n",
       "Age_median_rs    0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Sex_le           0\n",
       "Embarked_le      0\n",
       "log_Fare_rs      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomisedSearch(X_train, y_train):\n",
    "    param_dist=dict(n_estimators=np.arange(100, 1500, 100), max_depth=np.arange(1,15,1), criterion=['entropy', 'gini'])\n",
    "    global rs\n",
    "    rs=model_selection.RandomizedSearchCV(estimator=rf, \n",
    "                                          param_distributions=param_dist, cv=5, verbose=5)\n",
    "    rs.fit(X_train, y_train)\n",
    "    print(rs.score(X_train, y_train))\n",
    "    print(rs.score(X_val, y_val))\n",
    "    global test_predictions\n",
    "    test_predictions=pd.DataFrame(dict(Survived=rs.predict(x_test)), index=test['PassengerId'])\n",
    "    test_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=500, max_depth=4, criterion=gini ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_depth=4, criterion=gini, score=0.783, total=   1.2s\n",
      "[CV] n_estimators=500, max_depth=4, criterion=gini ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_depth=4, criterion=gini, score=0.860, total=   1.1s\n",
      "[CV] n_estimators=500, max_depth=4, criterion=gini ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_depth=4, criterion=gini, score=0.803, total=   1.1s\n",
      "[CV] n_estimators=500, max_depth=4, criterion=gini ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_depth=4, criterion=gini, score=0.803, total=   1.2s\n",
      "[CV] n_estimators=500, max_depth=4, criterion=gini ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, max_depth=4, criterion=gini, score=0.845, total=   1.2s\n",
      "[CV] n_estimators=1300, max_depth=11, criterion=entropy ..............\n",
      "[CV]  n_estimators=1300, max_depth=11, criterion=entropy, score=0.783, total=   3.7s\n",
      "[CV] n_estimators=1300, max_depth=11, criterion=entropy ..............\n",
      "[CV]  n_estimators=1300, max_depth=11, criterion=entropy, score=0.846, total=   4.2s\n",
      "[CV] n_estimators=1300, max_depth=11, criterion=entropy ..............\n",
      "[CV]  n_estimators=1300, max_depth=11, criterion=entropy, score=0.824, total=   4.0s\n",
      "[CV] n_estimators=1300, max_depth=11, criterion=entropy ..............\n",
      "[CV]  n_estimators=1300, max_depth=11, criterion=entropy, score=0.803, total=   4.1s\n",
      "[CV] n_estimators=1300, max_depth=11, criterion=entropy ..............\n",
      "[CV]  n_estimators=1300, max_depth=11, criterion=entropy, score=0.845, total=   3.7s\n",
      "[CV] n_estimators=1100, max_depth=12, criterion=gini .................\n",
      "[CV]  n_estimators=1100, max_depth=12, criterion=gini, score=0.762, total=   3.3s\n",
      "[CV] n_estimators=1100, max_depth=12, criterion=gini .................\n",
      "[CV]  n_estimators=1100, max_depth=12, criterion=gini, score=0.839, total=   3.6s\n",
      "[CV] n_estimators=1100, max_depth=12, criterion=gini .................\n",
      "[CV]  n_estimators=1100, max_depth=12, criterion=gini, score=0.810, total=   3.2s\n",
      "[CV] n_estimators=1100, max_depth=12, criterion=gini .................\n",
      "[CV]  n_estimators=1100, max_depth=12, criterion=gini, score=0.810, total=   3.1s\n",
      "[CV] n_estimators=1100, max_depth=12, criterion=gini .................\n",
      "[CV]  n_estimators=1100, max_depth=12, criterion=gini, score=0.831, total=   2.8s\n",
      "[CV] n_estimators=700, max_depth=1, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=1, criterion=gini, score=0.727, total=   1.4s\n",
      "[CV] n_estimators=700, max_depth=1, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=1, criterion=gini, score=0.762, total=   1.5s\n",
      "[CV] n_estimators=700, max_depth=1, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=1, criterion=gini, score=0.803, total=   1.4s\n",
      "[CV] n_estimators=700, max_depth=1, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=1, criterion=gini, score=0.754, total=   1.5s\n",
      "[CV] n_estimators=700, max_depth=1, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=1, criterion=gini, score=0.739, total=   2.1s\n",
      "[CV] n_estimators=200, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=200, max_depth=4, criterion=entropy, score=0.811, total=   0.4s\n",
      "[CV] n_estimators=200, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=200, max_depth=4, criterion=entropy, score=0.867, total=   0.4s\n",
      "[CV] n_estimators=200, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=200, max_depth=4, criterion=entropy, score=0.803, total=   0.4s\n",
      "[CV] n_estimators=200, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=200, max_depth=4, criterion=entropy, score=0.803, total=   0.5s\n",
      "[CV] n_estimators=200, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=200, max_depth=4, criterion=entropy, score=0.852, total=   0.4s\n",
      "[CV] n_estimators=100, max_depth=2, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=2, criterion=entropy, score=0.727, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=2, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=2, criterion=entropy, score=0.832, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=2, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=2, criterion=entropy, score=0.782, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=2, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=2, criterion=entropy, score=0.782, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=2, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=2, criterion=entropy, score=0.775, total=   0.2s\n",
      "[CV] n_estimators=1300, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1300, max_depth=14, criterion=gini, score=0.762, total=   3.4s\n",
      "[CV] n_estimators=1300, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1300, max_depth=14, criterion=gini, score=0.797, total=   3.9s\n",
      "[CV] n_estimators=1300, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1300, max_depth=14, criterion=gini, score=0.810, total=   3.9s\n",
      "[CV] n_estimators=1300, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1300, max_depth=14, criterion=gini, score=0.768, total=   3.7s\n",
      "[CV] n_estimators=1300, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1300, max_depth=14, criterion=gini, score=0.831, total=   3.4s\n",
      "[CV] n_estimators=1300, max_depth=7, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=7, criterion=gini, score=0.790, total=   3.1s\n",
      "[CV] n_estimators=1300, max_depth=7, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=7, criterion=gini, score=0.874, total=   3.2s\n",
      "[CV] n_estimators=1300, max_depth=7, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=7, criterion=gini, score=0.810, total=   3.8s\n",
      "[CV] n_estimators=1300, max_depth=7, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=7, criterion=gini, score=0.803, total=   3.1s\n",
      "[CV] n_estimators=1300, max_depth=7, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=7, criterion=gini, score=0.824, total=   3.2s\n",
      "[CV] n_estimators=1000, max_depth=12, criterion=entropy ..............\n",
      "[CV]  n_estimators=1000, max_depth=12, criterion=entropy, score=0.783, total=   3.0s\n",
      "[CV] n_estimators=1000, max_depth=12, criterion=entropy ..............\n",
      "[CV]  n_estimators=1000, max_depth=12, criterion=entropy, score=0.832, total=   2.7s\n",
      "[CV] n_estimators=1000, max_depth=12, criterion=entropy ..............\n",
      "[CV]  n_estimators=1000, max_depth=12, criterion=entropy, score=0.824, total=   3.2s\n",
      "[CV] n_estimators=1000, max_depth=12, criterion=entropy ..............\n",
      "[CV]  n_estimators=1000, max_depth=12, criterion=entropy, score=0.803, total=   2.8s\n",
      "[CV] n_estimators=1000, max_depth=12, criterion=entropy ..............\n",
      "[CV]  n_estimators=1000, max_depth=12, criterion=entropy, score=0.831, total=   2.8s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=gini, score=0.790, total=   1.7s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=gini, score=0.867, total=   1.6s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=gini, score=0.817, total=   1.6s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=gini, score=0.810, total=   1.6s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=gini ...................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=gini, score=0.838, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8441011235955056\n",
      "0.8435754189944135\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Survived  418 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 6.5 KB\n"
     ]
    }
   ],
   "source": [
    "randomisedSearch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0           294\n",
       "1           124\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelMetrics(model, X_train, y_train):\n",
    "    print(\"--- train---\")\n",
    "    print(metrics.accuracy_score(y_train,model.predict(X_train)))\n",
    "    print(metrics.confusion_matrix(y_train,model.predict(X_train)))\n",
    "    print(metrics.classification_report(y_train,model.predict(X_train)))\n",
    "    #print(metrics.auc(x=X_train, y=y_train))\n",
    "    print(\"--- Validation---\")\n",
    "\n",
    "    print(metrics.accuracy_score(y_val,model.predict(X_val)))\n",
    "    print(metrics.confusion_matrix(y_val,model.predict(X_val)))\n",
    "    print(metrics.classification_report(y_val,model.predict(X_val)))\n",
    "    #print(metrics.auc(x=X_val, y=y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train---\n",
      "0.8441011235955056\n",
      "[[415  24]\n",
      " [ 87 186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       439\n",
      "           1       0.89      0.68      0.77       273\n",
      "\n",
      "    accuracy                           0.84       712\n",
      "   macro avg       0.86      0.81      0.83       712\n",
      "weighted avg       0.85      0.84      0.84       712\n",
      "\n",
      "--- Validation---\n",
      "0.8435754189944135\n",
      "[[105   5]\n",
      " [ 23  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       110\n",
      "           1       0.90      0.67      0.77        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.86      0.81      0.82       179\n",
      "weighted avg       0.85      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMetrics(rs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train---\n",
      "0.7668539325842697\n",
      "[[377  62]\n",
      " [104 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       439\n",
      "           1       0.73      0.62      0.67       273\n",
      "\n",
      "    accuracy                           0.77       712\n",
      "   macro avg       0.76      0.74      0.75       712\n",
      "weighted avg       0.76      0.77      0.76       712\n",
      "\n",
      "--- Validation---\n",
      "0.7541899441340782\n",
      "[[91 19]\n",
      " [25 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81       110\n",
      "           1       0.70      0.64      0.67        69\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.74      0.73      0.74       179\n",
      "weighted avg       0.75      0.75      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMetrics(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train---\n",
      "0.797752808988764\n",
      "[[373  66]\n",
      " [ 78 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       439\n",
      "           1       0.75      0.71      0.73       273\n",
      "\n",
      "    accuracy                           0.80       712\n",
      "   macro avg       0.79      0.78      0.78       712\n",
      "weighted avg       0.80      0.80      0.80       712\n",
      "\n",
      "--- Validation---\n",
      "0.8212290502793296\n",
      "[[95 15]\n",
      " [17 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       110\n",
      "           1       0.78      0.75      0.76        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMetrics(log, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 0\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1\n",
       "...               ...\n",
       "1305                0\n",
       "1306                1\n",
       "1307                0\n",
       "1308                0\n",
       "1309                0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv('test_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age_median_rs</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_le</th>\n",
       "      <th>Embarked_le</th>\n",
       "      <th>log_Fare_rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.231153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>2</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.615385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.880665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.490934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>1</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.325612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.692308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.435652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.446405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.136463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>2</td>\n",
       "      <td>2.461538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.743829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Age_median_rs  SibSp  Parch  Sex_le  Embarked_le  log_Fare_rs\n",
       "140       3       0.000000      0      2       0            0     0.039071\n",
       "439       2       0.230769      0      0       1            2    -0.231153\n",
       "817       2       0.230769      1      1       1            0     0.703796\n",
       "378       3      -0.615385      0      0       1            0    -0.880665\n",
       "491       3      -0.538462      0      0       1            2    -0.490934\n",
       "..      ...            ...    ...    ...     ...          ...          ...\n",
       "835       1       0.846154      1      1       0            0     1.325612\n",
       "192       3      -0.692308      1      0       0            2    -0.435652\n",
       "629       3       0.000000      0      0       1            1    -0.446405\n",
       "559       3       0.615385      1      0       0            2     0.136463\n",
       "684       2       2.461538      1      1       1            2     0.743829\n",
       "\n",
       "[712 rows x 7 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=train[['Pclass', 'Age_median_rs', 'SibSp_mm', 'Parch_mm', 'Sex_le', 'Embarked_le', 'log_Fare_rs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=model_selection.train_test_split(X3, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=600, max_depth=12, criterion=gini ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=600, max_depth=12, criterion=gini, score=0.762, total=   1.5s\n",
      "[CV] n_estimators=600, max_depth=12, criterion=gini ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=600, max_depth=12, criterion=gini, score=0.811, total=   1.6s\n",
      "[CV] n_estimators=600, max_depth=12, criterion=gini ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=600, max_depth=12, criterion=gini, score=0.810, total=   1.7s\n",
      "[CV] n_estimators=600, max_depth=12, criterion=gini ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=600, max_depth=12, criterion=gini, score=0.796, total=   1.5s\n",
      "[CV] n_estimators=600, max_depth=12, criterion=gini ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=600, max_depth=12, criterion=gini, score=0.817, total=   1.5s\n",
      "[CV] n_estimators=1300, max_depth=6, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=6, criterion=gini, score=0.790, total=   3.2s\n",
      "[CV] n_estimators=1300, max_depth=6, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=6, criterion=gini, score=0.860, total=   3.7s\n",
      "[CV] n_estimators=1300, max_depth=6, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=6, criterion=gini, score=0.810, total=   3.3s\n",
      "[CV] n_estimators=1300, max_depth=6, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=6, criterion=gini, score=0.810, total=   3.1s\n",
      "[CV] n_estimators=1300, max_depth=6, criterion=gini ..................\n",
      "[CV]  n_estimators=1300, max_depth=6, criterion=gini, score=0.831, total=   3.2s\n",
      "[CV] n_estimators=800, max_depth=1, criterion=entropy ................\n",
      "[CV]  n_estimators=800, max_depth=1, criterion=entropy, score=0.734, total=   1.9s\n",
      "[CV] n_estimators=800, max_depth=1, criterion=entropy ................\n",
      "[CV]  n_estimators=800, max_depth=1, criterion=entropy, score=0.755, total=   1.8s\n",
      "[CV] n_estimators=800, max_depth=1, criterion=entropy ................\n",
      "[CV]  n_estimators=800, max_depth=1, criterion=entropy, score=0.803, total=   2.4s\n",
      "[CV] n_estimators=800, max_depth=1, criterion=entropy ................\n",
      "[CV]  n_estimators=800, max_depth=1, criterion=entropy, score=0.768, total=   1.6s\n",
      "[CV] n_estimators=800, max_depth=1, criterion=entropy ................\n",
      "[CV]  n_estimators=800, max_depth=1, criterion=entropy, score=0.739, total=   1.6s\n",
      "[CV] n_estimators=400, max_depth=9, criterion=entropy ................\n",
      "[CV]  n_estimators=400, max_depth=9, criterion=entropy, score=0.804, total=   1.0s\n",
      "[CV] n_estimators=400, max_depth=9, criterion=entropy ................\n",
      "[CV]  n_estimators=400, max_depth=9, criterion=entropy, score=0.860, total=   1.1s\n",
      "[CV] n_estimators=400, max_depth=9, criterion=entropy ................\n",
      "[CV]  n_estimators=400, max_depth=9, criterion=entropy, score=0.824, total=   1.1s\n",
      "[CV] n_estimators=400, max_depth=9, criterion=entropy ................\n",
      "[CV]  n_estimators=400, max_depth=9, criterion=entropy, score=0.796, total=   1.0s\n",
      "[CV] n_estimators=400, max_depth=9, criterion=entropy ................\n",
      "[CV]  n_estimators=400, max_depth=9, criterion=entropy, score=0.852, total=   1.0s\n",
      "[CV] n_estimators=500, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=500, max_depth=11, criterion=entropy, score=0.783, total=   1.4s\n",
      "[CV] n_estimators=500, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=500, max_depth=11, criterion=entropy, score=0.839, total=   1.3s\n",
      "[CV] n_estimators=500, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=500, max_depth=11, criterion=entropy, score=0.831, total=   1.4s\n",
      "[CV] n_estimators=500, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=500, max_depth=11, criterion=entropy, score=0.803, total=   1.4s\n",
      "[CV] n_estimators=500, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=500, max_depth=11, criterion=entropy, score=0.831, total=   2.0s\n",
      "[CV] n_estimators=1000, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1000, max_depth=14, criterion=gini, score=0.748, total=   2.6s\n",
      "[CV] n_estimators=1000, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1000, max_depth=14, criterion=gini, score=0.797, total=   2.7s\n",
      "[CV] n_estimators=1000, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1000, max_depth=14, criterion=gini, score=0.803, total=   2.6s\n",
      "[CV] n_estimators=1000, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1000, max_depth=14, criterion=gini, score=0.761, total=   2.8s\n",
      "[CV] n_estimators=1000, max_depth=14, criterion=gini .................\n",
      "[CV]  n_estimators=1000, max_depth=14, criterion=gini, score=0.831, total=   2.6s\n",
      "[CV] n_estimators=100, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=6, criterion=entropy, score=0.797, total=   0.3s\n",
      "[CV] n_estimators=100, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=6, criterion=entropy, score=0.860, total=   0.4s\n",
      "[CV] n_estimators=100, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=6, criterion=entropy, score=0.810, total=   0.4s\n",
      "[CV] n_estimators=100, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=6, criterion=entropy, score=0.824, total=   0.4s\n",
      "[CV] n_estimators=100, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=6, criterion=entropy, score=0.831, total=   0.4s\n",
      "[CV] n_estimators=1300, max_depth=2, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=2, criterion=entropy, score=0.748, total=   2.8s\n",
      "[CV] n_estimators=1300, max_depth=2, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=2, criterion=entropy, score=0.860, total=   2.9s\n",
      "[CV] n_estimators=1300, max_depth=2, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=2, criterion=entropy, score=0.789, total=   2.8s\n",
      "[CV] n_estimators=1300, max_depth=2, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=2, criterion=entropy, score=0.775, total=   2.7s\n",
      "[CV] n_estimators=1300, max_depth=2, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=2, criterion=entropy, score=0.782, total=   2.7s\n",
      "[CV] n_estimators=700, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=700, max_depth=11, criterion=entropy, score=0.783, total=   2.6s\n",
      "[CV] n_estimators=700, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=700, max_depth=11, criterion=entropy, score=0.839, total=   1.9s\n",
      "[CV] n_estimators=700, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=700, max_depth=11, criterion=entropy, score=0.817, total=   2.0s\n",
      "[CV] n_estimators=700, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=700, max_depth=11, criterion=entropy, score=0.796, total=   1.8s\n",
      "[CV] n_estimators=700, max_depth=11, criterion=entropy ...............\n",
      "[CV]  n_estimators=700, max_depth=11, criterion=entropy, score=0.845, total=   1.9s\n",
      "[CV] n_estimators=100, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=4, criterion=entropy, score=0.783, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=4, criterion=entropy, score=0.853, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=4, criterion=entropy, score=0.796, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=4, criterion=entropy, score=0.810, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=4, criterion=entropy ................\n",
      "[CV]  n_estimators=100, max_depth=4, criterion=entropy, score=0.831, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9213483146067416\n",
      "0.8435754189944135\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Survived  418 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 6.5 KB\n"
     ]
    }
   ],
   "source": [
    "randomisedSearch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train---\n",
      "0.9213483146067416\n",
      "[[430   9]\n",
      " [ 47 226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       439\n",
      "           1       0.96      0.83      0.89       273\n",
      "\n",
      "    accuracy                           0.92       712\n",
      "   macro avg       0.93      0.90      0.91       712\n",
      "weighted avg       0.92      0.92      0.92       712\n",
      "\n",
      "--- Validation---\n",
      "0.8435754189944135\n",
      "[[102   8]\n",
      " [ 20  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       110\n",
      "           1       0.86      0.71      0.78        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.85      0.82      0.83       179\n",
      "weighted avg       0.85      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelMetrics(rs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0           305\n",
       "1           113\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29      , 0.71      ],\n",
       "       [0.75316667, 0.24683333],\n",
       "       [0.93      , 0.07      ],\n",
       "       ...,\n",
       "       [0.64561905, 0.35438095],\n",
       "       [0.54      , 0.46      ],\n",
       "       [0.96      , 0.04      ]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr,_=metrics.roc_curve(y_train, rf.predict_proba(X_train)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprV, tprV,_=metrics.roc_curve(y_val, rf.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8821038490742362\n",
      "0.8665349143610013\n"
     ]
    }
   ],
   "source": [
    "print(metrics.auc(fpr, tpr))\n",
    "print(metrics.auc(fprV, tprV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1886cee1108>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(rf,X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x18875b39f88>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(rs,X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x18875983988>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(rf,X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x18875983d88>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(rs,X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS, qqplot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vif Factor</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.798583</td>\n",
       "      <td>Pclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.162305</td>\n",
       "      <td>Age_median_rs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.696415</td>\n",
       "      <td>SibSp_mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.725985</td>\n",
       "      <td>Parch_mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.037803</td>\n",
       "      <td>Sex_le</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.433758</td>\n",
       "      <td>Embarked_le</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.497612</td>\n",
       "      <td>log_Fare_rs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vif Factor       Features\n",
       "0    5.798583         Pclass\n",
       "1    1.162305  Age_median_rs\n",
       "2    1.696415       SibSp_mm\n",
       "3    1.725985       Parch_mm\n",
       "4    3.037803         Sex_le\n",
       "5    4.433758    Embarked_le\n",
       "6    1.497612    log_Fare_rs"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Vif Factor']=[variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['Features']=X_train.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=train[['Age_median_rs', 'SibSp_mm', 'Parch_mm', 'Sex_le', 'Embarked_le', 'log_Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=model_selection.train_test_split(X4, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 6)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1400, max_depth=12, criterion=entropy ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1400, max_depth=12, criterion=entropy, score=0.790, total=   4.2s\n",
      "[CV] n_estimators=1400, max_depth=12, criterion=entropy ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1400, max_depth=12, criterion=entropy, score=0.818, total=   3.9s\n",
      "[CV] n_estimators=1400, max_depth=12, criterion=entropy ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1400, max_depth=12, criterion=entropy, score=0.803, total=   5.0s\n",
      "[CV] n_estimators=1400, max_depth=12, criterion=entropy ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1400, max_depth=12, criterion=entropy, score=0.810, total=   4.2s\n",
      "[CV] n_estimators=1400, max_depth=12, criterion=entropy ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1400, max_depth=12, criterion=entropy, score=0.817, total=   4.0s\n",
      "[CV] n_estimators=1400, max_depth=4, criterion=gini ..................\n",
      "[CV]  n_estimators=1400, max_depth=4, criterion=gini, score=0.769, total=   3.3s\n",
      "[CV] n_estimators=1400, max_depth=4, criterion=gini ..................\n",
      "[CV]  n_estimators=1400, max_depth=4, criterion=gini, score=0.839, total=   3.9s\n",
      "[CV] n_estimators=1400, max_depth=4, criterion=gini ..................\n",
      "[CV]  n_estimators=1400, max_depth=4, criterion=gini, score=0.803, total=   3.2s\n",
      "[CV] n_estimators=1400, max_depth=4, criterion=gini ..................\n",
      "[CV]  n_estimators=1400, max_depth=4, criterion=gini, score=0.817, total=   3.1s\n",
      "[CV] n_estimators=1400, max_depth=4, criterion=gini ..................\n",
      "[CV]  n_estimators=1400, max_depth=4, criterion=gini, score=0.845, total=   3.1s\n",
      "[CV] n_estimators=100, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=100, max_depth=9, criterion=gini, score=0.783, total=   0.2s\n",
      "[CV] n_estimators=100, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=100, max_depth=9, criterion=gini, score=0.839, total=   0.3s\n",
      "[CV] n_estimators=100, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=100, max_depth=9, criterion=gini, score=0.796, total=   0.3s\n",
      "[CV] n_estimators=100, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=100, max_depth=9, criterion=gini, score=0.810, total=   0.3s\n",
      "[CV] n_estimators=100, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=100, max_depth=9, criterion=gini, score=0.824, total=   0.2s\n",
      "[CV] n_estimators=600, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=600, max_depth=6, criterion=entropy, score=0.783, total=   1.8s\n",
      "[CV] n_estimators=600, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=600, max_depth=6, criterion=entropy, score=0.839, total=   1.8s\n",
      "[CV] n_estimators=600, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=600, max_depth=6, criterion=entropy, score=0.803, total=   1.5s\n",
      "[CV] n_estimators=600, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=600, max_depth=6, criterion=entropy, score=0.817, total=   1.7s\n",
      "[CV] n_estimators=600, max_depth=6, criterion=entropy ................\n",
      "[CV]  n_estimators=600, max_depth=6, criterion=entropy, score=0.831, total=   1.6s\n",
      "[CV] n_estimators=200, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=200, max_depth=9, criterion=gini, score=0.790, total=   0.5s\n",
      "[CV] n_estimators=200, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=200, max_depth=9, criterion=gini, score=0.839, total=   0.8s\n",
      "[CV] n_estimators=200, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=200, max_depth=9, criterion=gini, score=0.803, total=   0.6s\n",
      "[CV] n_estimators=200, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=200, max_depth=9, criterion=gini, score=0.817, total=   0.5s\n",
      "[CV] n_estimators=200, max_depth=9, criterion=gini ...................\n",
      "[CV]  n_estimators=200, max_depth=9, criterion=gini, score=0.838, total=   0.5s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=entropy ................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=entropy, score=0.776, total=   1.7s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=entropy ................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=entropy, score=0.839, total=   1.7s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=entropy ................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=entropy, score=0.803, total=   1.9s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=entropy ................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=entropy, score=0.817, total=   2.3s\n",
      "[CV] n_estimators=700, max_depth=5, criterion=entropy ................\n",
      "[CV]  n_estimators=700, max_depth=5, criterion=entropy, score=0.852, total=   1.7s\n",
      "[CV] n_estimators=400, max_depth=6, criterion=gini ...................\n",
      "[CV]  n_estimators=400, max_depth=6, criterion=gini, score=0.776, total=   1.0s\n",
      "[CV] n_estimators=400, max_depth=6, criterion=gini ...................\n",
      "[CV]  n_estimators=400, max_depth=6, criterion=gini, score=0.839, total=   0.9s\n",
      "[CV] n_estimators=400, max_depth=6, criterion=gini ...................\n",
      "[CV]  n_estimators=400, max_depth=6, criterion=gini, score=0.803, total=   0.9s\n",
      "[CV] n_estimators=400, max_depth=6, criterion=gini ...................\n",
      "[CV]  n_estimators=400, max_depth=6, criterion=gini, score=0.817, total=   1.0s\n",
      "[CV] n_estimators=400, max_depth=6, criterion=gini ...................\n",
      "[CV]  n_estimators=400, max_depth=6, criterion=gini, score=0.831, total=   0.9s\n",
      "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
      "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.790, total=   2.6s\n",
      "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
      "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.811, total=   2.6s\n",
      "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
      "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.796, total=   2.8s\n",
      "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
      "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.789, total=   3.0s\n",
      "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
      "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.803, total=   2.6s\n",
      "[CV] n_estimators=1200, max_depth=3, criterion=entropy ...............\n",
      "[CV]  n_estimators=1200, max_depth=3, criterion=entropy, score=0.769, total=   2.6s\n",
      "[CV] n_estimators=1200, max_depth=3, criterion=entropy ...............\n",
      "[CV]  n_estimators=1200, max_depth=3, criterion=entropy, score=0.818, total=   2.6s\n",
      "[CV] n_estimators=1200, max_depth=3, criterion=entropy ...............\n",
      "[CV]  n_estimators=1200, max_depth=3, criterion=entropy, score=0.775, total=   2.8s\n",
      "[CV] n_estimators=1200, max_depth=3, criterion=entropy ...............\n",
      "[CV]  n_estimators=1200, max_depth=3, criterion=entropy, score=0.810, total=   3.1s\n",
      "[CV] n_estimators=1200, max_depth=3, criterion=entropy ...............\n",
      "[CV]  n_estimators=1200, max_depth=3, criterion=entropy, score=0.845, total=   3.0s\n",
      "[CV] n_estimators=1300, max_depth=5, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=5, criterion=entropy, score=0.783, total=   3.1s\n",
      "[CV] n_estimators=1300, max_depth=5, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=5, criterion=entropy, score=0.839, total=   3.1s\n",
      "[CV] n_estimators=1300, max_depth=5, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=5, criterion=entropy, score=0.803, total=   3.2s\n",
      "[CV] n_estimators=1300, max_depth=5, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=5, criterion=entropy, score=0.817, total=   3.5s\n",
      "[CV] n_estimators=1300, max_depth=5, criterion=entropy ...............\n",
      "[CV]  n_estimators=1300, max_depth=5, criterion=entropy, score=0.852, total=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8300561797752809\n",
      "0.8100558659217877\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 6 and input n_features is 7 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-0b88327e87f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandomisedSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-114-9d0cf5d9c86e>\u001b[0m in \u001b[0;36mrandomisedSearch\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtest_predictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSurvived\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtest_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 6 and input n_features is 7 "
     ]
    }
   ],
   "source": [
    "randomisedSearch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qqplot(train['Age_median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qqplot(train['log_Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_median_mab</th>\n",
       "      <th>Age_median_rs</th>\n",
       "      <th>SibSp_sc</th>\n",
       "      <th>SibSp_mm</th>\n",
       "      <th>SibSp_mab</th>\n",
       "      <th>SibSp_rs</th>\n",
       "      <th>Parch_sc</th>\n",
       "      <th>Parch_mm</th>\n",
       "      <th>Parch_mab</th>\n",
       "      <th>Parch_rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>-0.692308</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare  ... Age_median_mab Age_median_rs  \\\n",
       "0        0         A/5 21171   7.2500  ...         0.2750     -0.461538   \n",
       "1        0          PC 17599  71.2833  ...         0.4750      0.769231   \n",
       "2        0  STON/O2. 3101282   7.9250  ...         0.3250     -0.153846   \n",
       "3        0            113803  53.1000  ...         0.4375      0.538462   \n",
       "4        0            373450   8.0500  ...         0.4375      0.538462   \n",
       "..     ...               ...      ...  ...            ...           ...   \n",
       "886      0            211536  13.0000  ...         0.3375     -0.076923   \n",
       "887      0            112053  30.0000  ...         0.2375     -0.692308   \n",
       "888      2        W./C. 6607  23.4500  ...         0.3500      0.000000   \n",
       "889      0            111369  30.0000  ...         0.3250     -0.153846   \n",
       "890      0            370376   7.7500  ...         0.4000      0.307692   \n",
       "\n",
       "     SibSp_sc  SibSp_mm  SibSp_mab  SibSp_rs  Parch_sc  Parch_mm  Parch_mab  \\\n",
       "0    0.432793     0.125      0.125       1.0 -0.473674  0.000000   0.000000   \n",
       "1    0.432793     0.125      0.125       1.0 -0.473674  0.000000   0.000000   \n",
       "2   -0.474545     0.000      0.000       0.0 -0.473674  0.000000   0.000000   \n",
       "3    0.432793     0.125      0.125       1.0 -0.473674  0.000000   0.000000   \n",
       "4   -0.474545     0.000      0.000       0.0 -0.473674  0.000000   0.000000   \n",
       "..        ...       ...        ...       ...       ...       ...        ...   \n",
       "886 -0.474545     0.000      0.000       0.0 -0.473674  0.000000   0.000000   \n",
       "887 -0.474545     0.000      0.000       0.0 -0.473674  0.000000   0.000000   \n",
       "888  0.432793     0.125      0.125       1.0  2.008933  0.333333   0.333333   \n",
       "889 -0.474545     0.000      0.000       0.0 -0.473674  0.000000   0.000000   \n",
       "890 -0.474545     0.000      0.000       0.0 -0.473674  0.000000   0.000000   \n",
       "\n",
       "     Parch_rs  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "..        ...  \n",
       "886       0.0  \n",
       "887       0.0  \n",
       "888       2.0  \n",
       "889       0.0  \n",
       "890       0.0  \n",
       "\n",
       "[891 rows x 40 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_median', 'Age_rs',\n",
       "       'Fare_median', 'Fare_rs', 'Sex_le', 'Embarked_le', 'Fare_median_sc',\n",
       "       'Fare_median_mm', 'Fare_median_mab', 'Fare_median_rs', 'Fare_Poly',\n",
       "       'log_Fare', 'log_Fare_sc', 'log_Fare_mm', 'log_Fare_mab', 'log_Fare_rs',\n",
       "       'Age_median_sc', 'Age_median_mm', 'Age_median_mab', 'Age_median_rs',\n",
       "       'SibSp_sc', 'SibSp_mm', 'SibSp_mab', 'SibSp_rs', 'Parch_sc', 'Parch_mm',\n",
       "       'Parch_mab', 'Parch_rs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['log_Fare_sc', 'SibSp_sc', 'Parch_sc', 'Pclass', 'Sex_le', 'Embarked_le']]\n",
    "test=test[train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNN():\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(12, activation='relu', input_dim=6))\n",
    "    model.add(keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.wrappers.scikit_learn.KerasClassifier(createNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=[16,32,48]\n",
    "epochs=[30, 60, 90]\n",
    "\n",
    "param_grid=dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=model_selection.GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 535us/step - loss: 0.7035 - accuracy: 0.6166 - val_loss: 0.7217 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6903 - accuracy: 0.6166 - val_loss: 0.7051 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6813 - accuracy: 0.6166 - val_loss: 0.6952 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6746 - accuracy: 0.6166 - val_loss: 0.6866 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6680 - accuracy: 0.6166 - val_loss: 0.6773 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6613 - accuracy: 0.6166 - val_loss: 0.6681 - val_accuracy: 0.6145\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6537 - accuracy: 0.6208 - val_loss: 0.6577 - val_accuracy: 0.6201\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.6452 - accuracy: 0.6208 - val_loss: 0.6473 - val_accuracy: 0.6201\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6352 - accuracy: 0.6222 - val_loss: 0.6348 - val_accuracy: 0.6257\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6228 - accuracy: 0.6236 - val_loss: 0.6164 - val_accuracy: 0.6257\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.5999 - accuracy: 0.6250 - val_loss: 0.5835 - val_accuracy: 0.6313\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5716 - accuracy: 0.6348 - val_loss: 0.5521 - val_accuracy: 0.6480\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5496 - accuracy: 0.6812 - val_loss: 0.5277 - val_accuracy: 0.7430\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.5326 - accuracy: 0.7711 - val_loss: 0.5100 - val_accuracy: 0.7654\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5208 - accuracy: 0.7795 - val_loss: 0.4977 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5133 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5034 - accuracy: 0.7949 - val_loss: 0.4786 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4973 - accuracy: 0.7949 - val_loss: 0.4694 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4921 - accuracy: 0.7949 - val_loss: 0.4664 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4864 - accuracy: 0.8104 - val_loss: 0.4594 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4805 - accuracy: 0.7992 - val_loss: 0.4539 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4753 - accuracy: 0.8034 - val_loss: 0.4512 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4721 - accuracy: 0.8090 - val_loss: 0.4462 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4685 - accuracy: 0.8104 - val_loss: 0.4404 - val_accuracy: 0.8045\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4663 - accuracy: 0.8132 - val_loss: 0.4406 - val_accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4623 - accuracy: 0.8132 - val_loss: 0.4380 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4599 - accuracy: 0.8118 - val_loss: 0.4380 - val_accuracy: 0.8045\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4588 - accuracy: 0.8146 - val_loss: 0.4359 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4580 - accuracy: 0.8090 - val_loss: 0.4283 - val_accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4540 - accuracy: 0.8174 - val_loss: 0.4284 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4534 - accuracy: 0.8132 - val_loss: 0.4243 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4509 - accuracy: 0.8160 - val_loss: 0.4269 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4500 - accuracy: 0.8160 - val_loss: 0.4230 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4473 - accuracy: 0.8174 - val_loss: 0.4248 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4472 - accuracy: 0.8202 - val_loss: 0.4241 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4488 - accuracy: 0.8160 - val_loss: 0.4197 - val_accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4461 - accuracy: 0.8202 - val_loss: 0.4223 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4438 - accuracy: 0.8174 - val_loss: 0.4219 - val_accuracy: 0.7877\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4428 - accuracy: 0.8188 - val_loss: 0.4203 - val_accuracy: 0.7877\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4446 - accuracy: 0.8188 - val_loss: 0.4235 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4421 - accuracy: 0.8188 - val_loss: 0.4187 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4414 - accuracy: 0.8188 - val_loss: 0.4167 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4421 - accuracy: 0.8188 - val_loss: 0.4164 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4411 - accuracy: 0.8216 - val_loss: 0.4210 - val_accuracy: 0.7877\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4410 - accuracy: 0.8188 - val_loss: 0.4174 - val_accuracy: 0.7877\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4368 - accuracy: 0.8188 - val_loss: 0.4154 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4377 - accuracy: 0.8216 - val_loss: 0.4150 - val_accuracy: 0.7877\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4371 - accuracy: 0.8202 - val_loss: 0.4127 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4377 - accuracy: 0.8202 - val_loss: 0.4114 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4361 - accuracy: 0.8202 - val_loss: 0.4136 - val_accuracy: 0.7877\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 96us/step - loss: 0.4345 - accuracy: 0.8202 - val_loss: 0.4097 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4349 - accuracy: 0.8216 - val_loss: 0.4103 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4336 - accuracy: 0.8216 - val_loss: 0.4100 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4352 - accuracy: 0.8188 - val_loss: 0.4088 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4331 - accuracy: 0.8202 - val_loss: 0.4078 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4335 - accuracy: 0.8202 - val_loss: 0.4086 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4324 - accuracy: 0.8202 - val_loss: 0.4115 - val_accuracy: 0.7877\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4329 - accuracy: 0.8216 - val_loss: 0.4069 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4328 - accuracy: 0.8230 - val_loss: 0.4080 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4323 - accuracy: 0.8202 - val_loss: 0.4082 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4317 - accuracy: 0.8216 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4315 - accuracy: 0.8188 - val_loss: 0.4140 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4306 - accuracy: 0.8174 - val_loss: 0.4064 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4347 - accuracy: 0.8216 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4309 - accuracy: 0.8216 - val_loss: 0.4058 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4295 - accuracy: 0.8216 - val_loss: 0.4035 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4296 - accuracy: 0.8258 - val_loss: 0.4066 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4308 - accuracy: 0.8174 - val_loss: 0.4036 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4309 - accuracy: 0.8230 - val_loss: 0.4039 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4285 - accuracy: 0.8216 - val_loss: 0.4047 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.87 - 0s 77us/step - loss: 0.4272 - accuracy: 0.8230 - val_loss: 0.4043 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4293 - accuracy: 0.8188 - val_loss: 0.4028 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4308 - accuracy: 0.8244 - val_loss: 0.4039 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4287 - accuracy: 0.8258 - val_loss: 0.4039 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4303 - accuracy: 0.8202 - val_loss: 0.4071 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4272 - accuracy: 0.8230 - val_loss: 0.4038 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4283 - accuracy: 0.8272 - val_loss: 0.4043 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4352 - accuracy: 0.8174 - val_loss: 0.4040 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4267 - accuracy: 0.8258 - val_loss: 0.4058 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4291 - accuracy: 0.8230 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4271 - accuracy: 0.8315 - val_loss: 0.4035 - val_accuracy: 0.7989\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4276 - accuracy: 0.8188 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4268 - accuracy: 0.8258 - val_loss: 0.4035 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4275 - accuracy: 0.8258 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4260 - accuracy: 0.8202 - val_loss: 0.4047 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4299 - accuracy: 0.8287 - val_loss: 0.4046 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4281 - accuracy: 0.8188 - val_loss: 0.4077 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4271 - accuracy: 0.8230 - val_loss: 0.4048 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4241 - accuracy: 0.8272 - val_loss: 0.4049 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4242 - accuracy: 0.8244 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4244 - accuracy: 0.8230 - val_loss: 0.4019 - val_accuracy: 0.7989\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4243 - accuracy: 0.8188 - val_loss: 0.4014 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4241 - accuracy: 0.8244 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4238 - accuracy: 0.8202 - val_loss: 0.4034 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4270 - accuracy: 0.8216 - val_loss: 0.4039 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4240 - accuracy: 0.8258 - val_loss: 0.4032 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4225 - accuracy: 0.8230 - val_loss: 0.4032 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4227 - accuracy: 0.8301 - val_loss: 0.4026 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4232 - accuracy: 0.8244 - val_loss: 0.4036 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4239 - accuracy: 0.8258 - val_loss: 0.4033 - val_accuracy: 0.8156\n",
      "Epoch 1/30\n",
      "569/569 [==============================] - 0s 155us/step - loss: 0.4072 - accuracy: 0.8313\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 231us/step - loss: 0.4062 - accuracy: 0.8260\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 172us/step - loss: 0.4061 - accuracy: 0.8366\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 189us/step - loss: 0.4050 - accuracy: 0.8401\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 178us/step - loss: 0.4021 - accuracy: 0.8418\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4112 - accuracy: 0.8207\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.4012 - accuracy: 0.8260\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4063 - accuracy: 0.8401\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 153us/step - loss: 0.4006 - accuracy: 0.8330\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.4089 - accuracy: 0.8313\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4037 - accuracy: 0.8313\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 171us/step - loss: 0.4016 - accuracy: 0.8383\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.4013 - accuracy: 0.8366\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 166us/step - loss: 0.4031 - accuracy: 0.8330\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.4020 - accuracy: 0.8366\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4007 - accuracy: 0.8383\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4019 - accuracy: 0.8330\n",
      "Epoch 18/30\n",
      "569/569 [==============================] - 0s 183us/step - loss: 0.3998 - accuracy: 0.8348\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 165us/step - loss: 0.3995 - accuracy: 0.8401\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.3992 - accuracy: 0.8278\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 155us/step - loss: 0.3998 - accuracy: 0.8348\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.3972 - accuracy: 0.8418\n",
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 174us/step - loss: 0.3996 - accuracy: 0.8295\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - 0s 170us/step - loss: 0.3962 - accuracy: 0.8366\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4004 - accuracy: 0.8383\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.3993 - accuracy: 0.8313\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 181us/step - loss: 0.3960 - accuracy: 0.8366\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.3978 - accuracy: 0.8383\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 134us/step - loss: 0.3940 - accuracy: 0.8418\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.3953 - accuracy: 0.8383\n",
      "143/143 [==============================] - 0s 98us/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 563us/step - loss: 0.7043 - accuracy: 0.3638 - val_loss: 0.6976 - val_accuracy: 0.3352\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6915 - accuracy: 0.5716 - val_loss: 0.6905 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6838 - accuracy: 0.6236 - val_loss: 0.6812 - val_accuracy: 0.6201\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.6682 - accuracy: 0.6264 - val_loss: 0.6596 - val_accuracy: 0.6369\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6463 - accuracy: 0.6236 - val_loss: 0.6340 - val_accuracy: 0.6369\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.6232 - accuracy: 0.6292 - val_loss: 0.6147 - val_accuracy: 0.6313\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6080 - accuracy: 0.6292 - val_loss: 0.5997 - val_accuracy: 0.6313\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5936 - accuracy: 0.6362 - val_loss: 0.5877 - val_accuracy: 0.6201\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.5815 - accuracy: 0.6545 - val_loss: 0.5759 - val_accuracy: 0.6313\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5692 - accuracy: 0.6601 - val_loss: 0.5613 - val_accuracy: 0.6369\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5574 - accuracy: 0.6770 - val_loss: 0.5449 - val_accuracy: 0.6760\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.5439 - accuracy: 0.7402 - val_loss: 0.5321 - val_accuracy: 0.7486\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5320 - accuracy: 0.7626 - val_loss: 0.5153 - val_accuracy: 0.7654\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.5218 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.5127 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.5049 - accuracy: 0.7879 - val_loss: 0.4824 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4982 - accuracy: 0.7935 - val_loss: 0.4759 - val_accuracy: 0.7989\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4933 - accuracy: 0.7921 - val_loss: 0.4703 - val_accuracy: 0.7989\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4897 - accuracy: 0.7935 - val_loss: 0.4643 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4861 - accuracy: 0.8006 - val_loss: 0.4619 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4831 - accuracy: 0.8006 - val_loss: 0.4574 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4810 - accuracy: 0.8034 - val_loss: 0.4571 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4769 - accuracy: 0.8034 - val_loss: 0.4536 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4739 - accuracy: 0.8048 - val_loss: 0.4503 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4717 - accuracy: 0.8076 - val_loss: 0.4506 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4687 - accuracy: 0.8104 - val_loss: 0.4481 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4674 - accuracy: 0.8118 - val_loss: 0.4429 - val_accuracy: 0.7989\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4634 - accuracy: 0.8146 - val_loss: 0.4411 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4629 - accuracy: 0.8146 - val_loss: 0.4395 - val_accuracy: 0.8045\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4604 - accuracy: 0.8132 - val_loss: 0.4394 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4578 - accuracy: 0.8132 - val_loss: 0.4364 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4561 - accuracy: 0.8160 - val_loss: 0.4345 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4543 - accuracy: 0.8132 - val_loss: 0.4339 - val_accuracy: 0.8045\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4522 - accuracy: 0.8118 - val_loss: 0.4307 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 73us/step - loss: 0.4518 - accuracy: 0.8146 - val_loss: 0.4297 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4496 - accuracy: 0.8118 - val_loss: 0.4265 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4491 - accuracy: 0.8160 - val_loss: 0.4234 - val_accuracy: 0.7989\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4460 - accuracy: 0.8132 - val_loss: 0.4239 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4453 - accuracy: 0.8160 - val_loss: 0.4228 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4462 - accuracy: 0.8090 - val_loss: 0.4187 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4461 - accuracy: 0.8132 - val_loss: 0.4182 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4427 - accuracy: 0.8132 - val_loss: 0.4151 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4407 - accuracy: 0.8146 - val_loss: 0.4169 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4396 - accuracy: 0.8146 - val_loss: 0.4156 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4395 - accuracy: 0.8160 - val_loss: 0.4139 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4387 - accuracy: 0.8174 - val_loss: 0.4124 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4372 - accuracy: 0.8132 - val_loss: 0.4108 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4353 - accuracy: 0.8160 - val_loss: 0.4122 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4359 - accuracy: 0.8146 - val_loss: 0.4100 - val_accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4338 - accuracy: 0.8202 - val_loss: 0.4080 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4324 - accuracy: 0.8160 - val_loss: 0.4075 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4339 - accuracy: 0.8174 - val_loss: 0.4061 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4318 - accuracy: 0.8202 - val_loss: 0.4049 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4316 - accuracy: 0.8216 - val_loss: 0.4038 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4307 - accuracy: 0.8174 - val_loss: 0.4024 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4299 - accuracy: 0.8216 - val_loss: 0.4037 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4300 - accuracy: 0.8216 - val_loss: 0.4017 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4299 - accuracy: 0.8202 - val_loss: 0.4008 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4279 - accuracy: 0.8216 - val_loss: 0.3999 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4284 - accuracy: 0.8216 - val_loss: 0.3997 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4268 - accuracy: 0.8202 - val_loss: 0.3963 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4257 - accuracy: 0.8216 - val_loss: 0.3972 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4261 - accuracy: 0.8216 - val_loss: 0.3960 - val_accuracy: 0.8156\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4268 - accuracy: 0.8244 - val_loss: 0.3936 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4247 - accuracy: 0.8230 - val_loss: 0.3948 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4244 - accuracy: 0.8230 - val_loss: 0.3954 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4253 - accuracy: 0.8230 - val_loss: 0.3957 - val_accuracy: 0.8212\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4257 - accuracy: 0.8287 - val_loss: 0.3935 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4238 - accuracy: 0.8230 - val_loss: 0.3951 - val_accuracy: 0.8156\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4228 - accuracy: 0.8272 - val_loss: 0.3941 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4225 - accuracy: 0.8230 - val_loss: 0.3974 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4252 - accuracy: 0.8287 - val_loss: 0.3944 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4223 - accuracy: 0.8258 - val_loss: 0.3934 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4215 - accuracy: 0.8216 - val_loss: 0.3950 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4213 - accuracy: 0.8272 - val_loss: 0.3934 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4204 - accuracy: 0.8258 - val_loss: 0.3931 - val_accuracy: 0.8156\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4210 - accuracy: 0.8287 - val_loss: 0.3936 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4205 - accuracy: 0.8244 - val_loss: 0.3914 - val_accuracy: 0.8212\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4186 - accuracy: 0.8272 - val_loss: 0.3937 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4190 - accuracy: 0.8287 - val_loss: 0.3922 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4201 - accuracy: 0.8244 - val_loss: 0.3915 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4236 - accuracy: 0.8315 - val_loss: 0.3892 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4200 - accuracy: 0.8315 - val_loss: 0.3894 - val_accuracy: 0.8212\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4180 - accuracy: 0.8287 - val_loss: 0.3898 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4171 - accuracy: 0.8287 - val_loss: 0.3898 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4174 - accuracy: 0.8287 - val_loss: 0.3907 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4178 - accuracy: 0.8272 - val_loss: 0.3903 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4173 - accuracy: 0.8287 - val_loss: 0.3912 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4174 - accuracy: 0.8301 - val_loss: 0.3888 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4159 - accuracy: 0.8315 - val_loss: 0.3912 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 117us/step - loss: 0.4152 - accuracy: 0.8315 - val_loss: 0.3894 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4154 - accuracy: 0.8287 - val_loss: 0.3897 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4148 - accuracy: 0.8287 - val_loss: 0.3895 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4174 - accuracy: 0.8329 - val_loss: 0.3893 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4144 - accuracy: 0.8301 - val_loss: 0.3902 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4151 - accuracy: 0.8315 - val_loss: 0.3918 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4165 - accuracy: 0.8287 - val_loss: 0.3950 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4145 - accuracy: 0.8357 - val_loss: 0.3932 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4132 - accuracy: 0.8301 - val_loss: 0.3927 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4125 - accuracy: 0.8315 - val_loss: 0.3916 - val_accuracy: 0.8101\n",
      "Epoch 1/30\n",
      "569/569 [==============================] - 0s 199us/step - loss: 0.4252 - accuracy: 0.8295\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.4226 - accuracy: 0.8295\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 175us/step - loss: 0.4233 - accuracy: 0.8330\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 170us/step - loss: 0.4253 - accuracy: 0.8278\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4221 - accuracy: 0.8278\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 134us/step - loss: 0.4215 - accuracy: 0.8295\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 123us/step - loss: 0.4233 - accuracy: 0.8278\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4212 - accuracy: 0.8348\n",
      "Epoch 9/30\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4211 - accuracy: 0.8295\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4201 - accuracy: 0.8278\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.4204 - accuracy: 0.8348\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4191 - accuracy: 0.8260\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4191 - accuracy: 0.8260\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4159 - accuracy: 0.8348\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4179 - accuracy: 0.8260\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.4148 - accuracy: 0.8330\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4156 - accuracy: 0.8278\n",
      "Epoch 18/30\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.82 - 0s 158us/step - loss: 0.4154 - accuracy: 0.8295\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 164us/step - loss: 0.4132 - accuracy: 0.8295\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4145 - accuracy: 0.8313\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.4143 - accuracy: 0.8295\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 165us/step - loss: 0.4132 - accuracy: 0.8295\n",
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4127 - accuracy: 0.8330\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4111 - accuracy: 0.8278\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4113 - accuracy: 0.8295\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4119 - accuracy: 0.8295\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4147 - accuracy: 0.8330\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.4175 - accuracy: 0.8313\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4108 - accuracy: 0.8295\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4100 - accuracy: 0.8330\n",
      "143/143 [==============================] - 0s 88us/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 821us/step - loss: 0.6666 - accuracy: 0.6166 - val_loss: 0.6396 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.6314 - accuracy: 0.6166 - val_loss: 0.6232 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.6162 - accuracy: 0.6166 - val_loss: 0.6022 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5994 - accuracy: 0.6166 - val_loss: 0.5816 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5829 - accuracy: 0.6236 - val_loss: 0.5605 - val_accuracy: 0.6536\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.5692 - accuracy: 0.6671 - val_loss: 0.5456 - val_accuracy: 0.7039\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.5569 - accuracy: 0.7514 - val_loss: 0.5300 - val_accuracy: 0.7151\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.5460 - accuracy: 0.7458 - val_loss: 0.5135 - val_accuracy: 0.7542\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.5317 - accuracy: 0.7584 - val_loss: 0.4995 - val_accuracy: 0.7709\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.5199 - accuracy: 0.7809 - val_loss: 0.4835 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5106 - accuracy: 0.7851 - val_loss: 0.4736 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.5014 - accuracy: 0.7837 - val_loss: 0.4625 - val_accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4925 - accuracy: 0.7823 - val_loss: 0.4547 - val_accuracy: 0.7877\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4870 - accuracy: 0.7879 - val_loss: 0.4496 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4824 - accuracy: 0.7851 - val_loss: 0.4457 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4802 - accuracy: 0.7907 - val_loss: 0.4441 - val_accuracy: 0.7989\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4796 - accuracy: 0.7837 - val_loss: 0.4392 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4737 - accuracy: 0.7851 - val_loss: 0.4373 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 81us/step - loss: 0.4769 - accuracy: 0.7935 - val_loss: 0.4384 - val_accuracy: 0.7989\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4696 - accuracy: 0.7851 - val_loss: 0.4308 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4711 - accuracy: 0.7865 - val_loss: 0.4274 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4672 - accuracy: 0.7907 - val_loss: 0.4283 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4660 - accuracy: 0.7837 - val_loss: 0.4272 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4674 - accuracy: 0.7851 - val_loss: 0.4271 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4631 - accuracy: 0.7851 - val_loss: 0.4305 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4614 - accuracy: 0.7949 - val_loss: 0.4251 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4640 - accuracy: 0.7893 - val_loss: 0.4223 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4597 - accuracy: 0.7851 - val_loss: 0.4239 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4578 - accuracy: 0.7935 - val_loss: 0.4223 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4571 - accuracy: 0.7921 - val_loss: 0.4228 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4587 - accuracy: 0.7907 - val_loss: 0.4224 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4547 - accuracy: 0.7907 - val_loss: 0.4217 - val_accuracy: 0.7877\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4550 - accuracy: 0.7921 - val_loss: 0.4185 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4546 - accuracy: 0.7921 - val_loss: 0.4195 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4526 - accuracy: 0.7921 - val_loss: 0.4174 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4539 - accuracy: 0.8006 - val_loss: 0.4197 - val_accuracy: 0.8045\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4525 - accuracy: 0.7921 - val_loss: 0.4168 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4510 - accuracy: 0.7907 - val_loss: 0.4144 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4497 - accuracy: 0.7935 - val_loss: 0.4149 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4498 - accuracy: 0.7935 - val_loss: 0.4148 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4479 - accuracy: 0.7963 - val_loss: 0.4131 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4476 - accuracy: 0.7949 - val_loss: 0.4117 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4552 - accuracy: 0.8020 - val_loss: 0.4227 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4510 - accuracy: 0.7949 - val_loss: 0.4119 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4462 - accuracy: 0.7949 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4465 - accuracy: 0.8062 - val_loss: 0.4178 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4483 - accuracy: 0.8020 - val_loss: 0.4070 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4434 - accuracy: 0.8076 - val_loss: 0.4100 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4445 - accuracy: 0.8132 - val_loss: 0.4079 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4415 - accuracy: 0.8132 - val_loss: 0.4065 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4442 - accuracy: 0.8090 - val_loss: 0.4061 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4414 - accuracy: 0.8104 - val_loss: 0.4085 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4405 - accuracy: 0.8146 - val_loss: 0.4052 - val_accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4394 - accuracy: 0.8118 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4413 - accuracy: 0.8132 - val_loss: 0.4018 - val_accuracy: 0.7877\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4368 - accuracy: 0.8090 - val_loss: 0.4024 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4383 - accuracy: 0.8202 - val_loss: 0.4053 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4376 - accuracy: 0.8132 - val_loss: 0.4005 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4386 - accuracy: 0.8216 - val_loss: 0.4055 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4403 - accuracy: 0.8104 - val_loss: 0.4017 - val_accuracy: 0.7933\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4373 - accuracy: 0.8188 - val_loss: 0.3999 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4358 - accuracy: 0.8146 - val_loss: 0.3994 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4355 - accuracy: 0.8104 - val_loss: 0.3997 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4337 - accuracy: 0.8174 - val_loss: 0.3983 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4365 - accuracy: 0.8160 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4328 - accuracy: 0.8160 - val_loss: 0.3977 - val_accuracy: 0.7933\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4337 - accuracy: 0.8202 - val_loss: 0.4000 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4382 - accuracy: 0.8160 - val_loss: 0.3994 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4340 - accuracy: 0.8160 - val_loss: 0.3998 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4359 - accuracy: 0.8188 - val_loss: 0.3986 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4345 - accuracy: 0.8118 - val_loss: 0.3955 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4338 - accuracy: 0.8160 - val_loss: 0.3941 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4336 - accuracy: 0.8132 - val_loss: 0.3973 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4343 - accuracy: 0.8202 - val_loss: 0.3966 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 73us/step - loss: 0.4307 - accuracy: 0.8160 - val_loss: 0.3968 - val_accuracy: 0.8212\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4331 - accuracy: 0.8202 - val_loss: 0.3958 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4319 - accuracy: 0.8188 - val_loss: 0.3953 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4326 - accuracy: 0.8132 - val_loss: 0.3961 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4315 - accuracy: 0.8174 - val_loss: 0.3943 - val_accuracy: 0.8045\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4314 - accuracy: 0.8160 - val_loss: 0.3943 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4328 - accuracy: 0.8146 - val_loss: 0.3956 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4315 - accuracy: 0.8202 - val_loss: 0.3963 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4341 - accuracy: 0.8188 - val_loss: 0.3999 - val_accuracy: 0.8212\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4316 - accuracy: 0.8202 - val_loss: 0.3941 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4310 - accuracy: 0.8188 - val_loss: 0.3958 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4317 - accuracy: 0.8160 - val_loss: 0.3944 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4305 - accuracy: 0.8216 - val_loss: 0.3962 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4330 - accuracy: 0.8160 - val_loss: 0.3970 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4302 - accuracy: 0.8230 - val_loss: 0.3951 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4305 - accuracy: 0.8174 - val_loss: 0.3946 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4338 - accuracy: 0.8076 - val_loss: 0.3968 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4323 - accuracy: 0.8216 - val_loss: 0.3978 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4328 - accuracy: 0.8202 - val_loss: 0.3965 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4301 - accuracy: 0.8132 - val_loss: 0.4005 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4349 - accuracy: 0.8202 - val_loss: 0.4004 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4343 - accuracy: 0.8132 - val_loss: 0.3973 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4309 - accuracy: 0.8230 - val_loss: 0.3945 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4284 - accuracy: 0.8188 - val_loss: 0.3996 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4319 - accuracy: 0.8230 - val_loss: 0.3955 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4315 - accuracy: 0.8160 - val_loss: 0.4025 - val_accuracy: 0.8156\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4423 - accuracy: 0.8053\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4362 - accuracy: 0.8193\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4308 - accuracy: 0.8175\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4279 - accuracy: 0.8158\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4329 - accuracy: 0.8035\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4341 - accuracy: 0.8158\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4273 - accuracy: 0.8070\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4250 - accuracy: 0.8193\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4349 - accuracy: 0.8193\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4289 - accuracy: 0.8123\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4296 - accuracy: 0.8193\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4309 - accuracy: 0.8140\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4272 - accuracy: 0.8193\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4288 - accuracy: 0.8158\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4288 - accuracy: 0.8123\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.4268 - accuracy: 0.8123\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4330 - accuracy: 0.8123\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4252 - accuracy: 0.8140\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4219 - accuracy: 0.8211\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4279 - accuracy: 0.8105\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4323 - accuracy: 0.8158\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4219 - accuracy: 0.8105\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4243 - accuracy: 0.8158\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4247 - accuracy: 0.8158\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4194 - accuracy: 0.8193\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 121us/step - loss: 0.4288 - accuracy: 0.8105\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4266 - accuracy: 0.8140\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4222 - accuracy: 0.8211\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4249 - accuracy: 0.8140\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4195 - accuracy: 0.8158\n",
      "142/142 [==============================] - 0s 84us/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 577us/step - loss: 0.6836 - accuracy: 0.6292 - val_loss: 0.6807 - val_accuracy: 0.6592\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6738 - accuracy: 0.6236 - val_loss: 0.6729 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 93us/step - loss: 0.6643 - accuracy: 0.6180 - val_loss: 0.6649 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6564 - accuracy: 0.6166 - val_loss: 0.6559 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6471 - accuracy: 0.6250 - val_loss: 0.6442 - val_accuracy: 0.6313\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6353 - accuracy: 0.6376 - val_loss: 0.6309 - val_accuracy: 0.6536\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6220 - accuracy: 0.6545 - val_loss: 0.6127 - val_accuracy: 0.6760\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6048 - accuracy: 0.6812 - val_loss: 0.5892 - val_accuracy: 0.7151\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.5836 - accuracy: 0.6966 - val_loss: 0.5606 - val_accuracy: 0.7430\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.5598 - accuracy: 0.7177 - val_loss: 0.5304 - val_accuracy: 0.7542\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.5349 - accuracy: 0.7753 - val_loss: 0.5015 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.5126 - accuracy: 0.7851 - val_loss: 0.4801 - val_accuracy: 0.7709\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4990 - accuracy: 0.7767 - val_loss: 0.4616 - val_accuracy: 0.7598\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4884 - accuracy: 0.7837 - val_loss: 0.4523 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4806 - accuracy: 0.7865 - val_loss: 0.4423 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4767 - accuracy: 0.7907 - val_loss: 0.4379 - val_accuracy: 0.7765\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4722 - accuracy: 0.7907 - val_loss: 0.4327 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4717 - accuracy: 0.7921 - val_loss: 0.4322 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4677 - accuracy: 0.7907 - val_loss: 0.4269 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4664 - accuracy: 0.7963 - val_loss: 0.4256 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4656 - accuracy: 0.7907 - val_loss: 0.4228 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4617 - accuracy: 0.7935 - val_loss: 0.4219 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4613 - accuracy: 0.7949 - val_loss: 0.4198 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4599 - accuracy: 0.7907 - val_loss: 0.4180 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4582 - accuracy: 0.7935 - val_loss: 0.4190 - val_accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4580 - accuracy: 0.7949 - val_loss: 0.4162 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4563 - accuracy: 0.7921 - val_loss: 0.4151 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4558 - accuracy: 0.7949 - val_loss: 0.4127 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4539 - accuracy: 0.7978 - val_loss: 0.4146 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4529 - accuracy: 0.7978 - val_loss: 0.4143 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4530 - accuracy: 0.7935 - val_loss: 0.4093 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4536 - accuracy: 0.7963 - val_loss: 0.4094 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4522 - accuracy: 0.7978 - val_loss: 0.4091 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4509 - accuracy: 0.7978 - val_loss: 0.4094 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4488 - accuracy: 0.8020 - val_loss: 0.4070 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4494 - accuracy: 0.8034 - val_loss: 0.4060 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4491 - accuracy: 0.8006 - val_loss: 0.4050 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4492 - accuracy: 0.8034 - val_loss: 0.4048 - val_accuracy: 0.8045\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4487 - accuracy: 0.8062 - val_loss: 0.4022 - val_accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4459 - accuracy: 0.8048 - val_loss: 0.4021 - val_accuracy: 0.8045\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4450 - accuracy: 0.8020 - val_loss: 0.4046 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4442 - accuracy: 0.8048 - val_loss: 0.4025 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4454 - accuracy: 0.8062 - val_loss: 0.4029 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4434 - accuracy: 0.8048 - val_loss: 0.4029 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4425 - accuracy: 0.8062 - val_loss: 0.4014 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4439 - accuracy: 0.8062 - val_loss: 0.4023 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4447 - accuracy: 0.8076 - val_loss: 0.3990 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4421 - accuracy: 0.8076 - val_loss: 0.4011 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4411 - accuracy: 0.8076 - val_loss: 0.3987 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4393 - accuracy: 0.8090 - val_loss: 0.4015 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4414 - accuracy: 0.8104 - val_loss: 0.3985 - val_accuracy: 0.7933\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4403 - accuracy: 0.8090 - val_loss: 0.3989 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4390 - accuracy: 0.8104 - val_loss: 0.3984 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4395 - accuracy: 0.8118 - val_loss: 0.3984 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4382 - accuracy: 0.8090 - val_loss: 0.3961 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4386 - accuracy: 0.8118 - val_loss: 0.3960 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4386 - accuracy: 0.8104 - val_loss: 0.3932 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4369 - accuracy: 0.8090 - val_loss: 0.3963 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 109us/step - loss: 0.4393 - accuracy: 0.8104 - val_loss: 0.3943 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4381 - accuracy: 0.8104 - val_loss: 0.3927 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4371 - accuracy: 0.8104 - val_loss: 0.3937 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4369 - accuracy: 0.8104 - val_loss: 0.3930 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4369 - accuracy: 0.8118 - val_loss: 0.3912 - val_accuracy: 0.8156\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4361 - accuracy: 0.8104 - val_loss: 0.3918 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4401 - accuracy: 0.8132 - val_loss: 0.3924 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4357 - accuracy: 0.8104 - val_loss: 0.3918 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4341 - accuracy: 0.8090 - val_loss: 0.3916 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4338 - accuracy: 0.8090 - val_loss: 0.3926 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4351 - accuracy: 0.8090 - val_loss: 0.3915 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4340 - accuracy: 0.8118 - val_loss: 0.3886 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4337 - accuracy: 0.8118 - val_loss: 0.3923 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4342 - accuracy: 0.8118 - val_loss: 0.3900 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4381 - accuracy: 0.8062 - val_loss: 0.3900 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4367 - accuracy: 0.8160 - val_loss: 0.3881 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4356 - accuracy: 0.8160 - val_loss: 0.3890 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4347 - accuracy: 0.8062 - val_loss: 0.3862 - val_accuracy: 0.8156\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4405 - accuracy: 0.8188 - val_loss: 0.3892 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4352 - accuracy: 0.8090 - val_loss: 0.3882 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4319 - accuracy: 0.8132 - val_loss: 0.3871 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4315 - accuracy: 0.8146 - val_loss: 0.3895 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4331 - accuracy: 0.8118 - val_loss: 0.3872 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4310 - accuracy: 0.8160 - val_loss: 0.3871 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4326 - accuracy: 0.8132 - val_loss: 0.3886 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4297 - accuracy: 0.8146 - val_loss: 0.3861 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4300 - accuracy: 0.8132 - val_loss: 0.3864 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4322 - accuracy: 0.8202 - val_loss: 0.3850 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4307 - accuracy: 0.8146 - val_loss: 0.3862 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4306 - accuracy: 0.8146 - val_loss: 0.3866 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4322 - accuracy: 0.8202 - val_loss: 0.3861 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4292 - accuracy: 0.8160 - val_loss: 0.3852 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4298 - accuracy: 0.8118 - val_loss: 0.3861 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4296 - accuracy: 0.8188 - val_loss: 0.3859 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4295 - accuracy: 0.8118 - val_loss: 0.3858 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4287 - accuracy: 0.8146 - val_loss: 0.3856 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4293 - accuracy: 0.8132 - val_loss: 0.3844 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4295 - accuracy: 0.8174 - val_loss: 0.3846 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4295 - accuracy: 0.8132 - val_loss: 0.3848 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4289 - accuracy: 0.8160 - val_loss: 0.3848 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4271 - accuracy: 0.8146 - val_loss: 0.3842 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4272 - accuracy: 0.8132 - val_loss: 0.3834 - val_accuracy: 0.8212\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4309 - accuracy: 0.8105\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4304 - accuracy: 0.8123\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4320 - accuracy: 0.8123\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4285 - accuracy: 0.8158\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4320 - accuracy: 0.8193\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4275 - accuracy: 0.8123\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4308 - accuracy: 0.8105\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4267 - accuracy: 0.8175\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4274 - accuracy: 0.8123\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 156us/step - loss: 0.4276 - accuracy: 0.8140\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 157us/step - loss: 0.4248 - accuracy: 0.8140\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4333 - accuracy: 0.8158\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 161us/step - loss: 0.4266 - accuracy: 0.8140\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4257 - accuracy: 0.8158\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 155us/step - loss: 0.4277 - accuracy: 0.8175\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 164us/step - loss: 0.4250 - accuracy: 0.8123\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4302 - accuracy: 0.8175\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4261 - accuracy: 0.8175\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4285 - accuracy: 0.8193\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4275 - accuracy: 0.8158\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 147us/step - loss: 0.4303 - accuracy: 0.8193\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4246 - accuracy: 0.8140\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4317 - accuracy: 0.8123\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4260 - accuracy: 0.8193\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 168us/step - loss: 0.4252 - accuracy: 0.8193\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 230us/step - loss: 0.4236 - accuracy: 0.8140\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4239 - accuracy: 0.8158\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 157us/step - loss: 0.4251 - accuracy: 0.8175\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4242 - accuracy: 0.8175\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 176us/step - loss: 0.4250 - accuracy: 0.8140\n",
      "142/142 [==============================] - 0s 138us/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 544us/step - loss: 0.6900 - accuracy: 0.5421 - val_loss: 0.6654 - val_accuracy: 0.6983\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6681 - accuracy: 0.6264 - val_loss: 0.6507 - val_accuracy: 0.6872\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6551 - accuracy: 0.6404 - val_loss: 0.6398 - val_accuracy: 0.7039\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6446 - accuracy: 0.6559 - val_loss: 0.6290 - val_accuracy: 0.7207\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6328 - accuracy: 0.6657 - val_loss: 0.6159 - val_accuracy: 0.7374\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6199 - accuracy: 0.6784 - val_loss: 0.5999 - val_accuracy: 0.7430\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6057 - accuracy: 0.6798 - val_loss: 0.5831 - val_accuracy: 0.7486\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.5908 - accuracy: 0.7149 - val_loss: 0.5684 - val_accuracy: 0.7151\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5774 - accuracy: 0.7149 - val_loss: 0.5514 - val_accuracy: 0.7486\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.5624 - accuracy: 0.7317 - val_loss: 0.5322 - val_accuracy: 0.7430\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.5486 - accuracy: 0.7346 - val_loss: 0.5146 - val_accuracy: 0.7486\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.5358 - accuracy: 0.7486 - val_loss: 0.4993 - val_accuracy: 0.7598\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5251 - accuracy: 0.7514 - val_loss: 0.4844 - val_accuracy: 0.7542\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.5135 - accuracy: 0.7584 - val_loss: 0.4719 - val_accuracy: 0.7542\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.5049 - accuracy: 0.7570 - val_loss: 0.4616 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4973 - accuracy: 0.7697 - val_loss: 0.4539 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4926 - accuracy: 0.7767 - val_loss: 0.4486 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4869 - accuracy: 0.7823 - val_loss: 0.4431 - val_accuracy: 0.7765\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4830 - accuracy: 0.7837 - val_loss: 0.4388 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4800 - accuracy: 0.7809 - val_loss: 0.4365 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4790 - accuracy: 0.7907 - val_loss: 0.4335 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4759 - accuracy: 0.7865 - val_loss: 0.4334 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4736 - accuracy: 0.7823 - val_loss: 0.4318 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4711 - accuracy: 0.7851 - val_loss: 0.4286 - val_accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4704 - accuracy: 0.7837 - val_loss: 0.4245 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4249 - val_accuracy: 0.7821\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4668 - accuracy: 0.7893 - val_loss: 0.4246 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4669 - accuracy: 0.7907 - val_loss: 0.4229 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4668 - accuracy: 0.7851 - val_loss: 0.4212 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.4196 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4633 - accuracy: 0.7879 - val_loss: 0.4160 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4163 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4617 - accuracy: 0.7879 - val_loss: 0.4166 - val_accuracy: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4603 - accuracy: 0.7935 - val_loss: 0.4167 - val_accuracy: 0.7821\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4582 - accuracy: 0.7907 - val_loss: 0.4133 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4573 - accuracy: 0.7921 - val_loss: 0.4125 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4563 - accuracy: 0.7963 - val_loss: 0.4135 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4555 - accuracy: 0.7921 - val_loss: 0.4103 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4542 - accuracy: 0.7935 - val_loss: 0.4127 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4533 - accuracy: 0.7921 - val_loss: 0.4105 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4524 - accuracy: 0.8006 - val_loss: 0.4106 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4512 - accuracy: 0.8034 - val_loss: 0.4095 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4503 - accuracy: 0.8048 - val_loss: 0.4075 - val_accuracy: 0.7989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4497 - accuracy: 0.8034 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4539 - accuracy: 0.8034 - val_loss: 0.4036 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4490 - accuracy: 0.7992 - val_loss: 0.4068 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4484 - accuracy: 0.8076 - val_loss: 0.4054 - val_accuracy: 0.7877\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4471 - accuracy: 0.8048 - val_loss: 0.4026 - val_accuracy: 0.7877\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4464 - accuracy: 0.8090 - val_loss: 0.4014 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4455 - accuracy: 0.8048 - val_loss: 0.4017 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4456 - accuracy: 0.8076 - val_loss: 0.4015 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4452 - accuracy: 0.8020 - val_loss: 0.4021 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4442 - accuracy: 0.8062 - val_loss: 0.3998 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4431 - accuracy: 0.8034 - val_loss: 0.4006 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4454 - accuracy: 0.8020 - val_loss: 0.3984 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4424 - accuracy: 0.8104 - val_loss: 0.4019 - val_accuracy: 0.7933\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4415 - accuracy: 0.8090 - val_loss: 0.3986 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4402 - accuracy: 0.8090 - val_loss: 0.3959 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4403 - accuracy: 0.8048 - val_loss: 0.3937 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4406 - accuracy: 0.8090 - val_loss: 0.3960 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4402 - accuracy: 0.8076 - val_loss: 0.3946 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4393 - accuracy: 0.8146 - val_loss: 0.3946 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4380 - accuracy: 0.8090 - val_loss: 0.3926 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.3954 - val_accuracy: 0.8156\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4386 - accuracy: 0.8090 - val_loss: 0.3922 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4383 - accuracy: 0.8104 - val_loss: 0.3904 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4366 - accuracy: 0.8104 - val_loss: 0.3935 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4360 - accuracy: 0.8118 - val_loss: 0.3936 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4369 - accuracy: 0.8132 - val_loss: 0.3922 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4365 - accuracy: 0.8132 - val_loss: 0.3923 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4365 - accuracy: 0.8146 - val_loss: 0.3898 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4355 - accuracy: 0.8118 - val_loss: 0.3920 - val_accuracy: 0.8212\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4349 - accuracy: 0.8174 - val_loss: 0.3925 - val_accuracy: 0.8212\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4354 - accuracy: 0.8118 - val_loss: 0.3913 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4340 - accuracy: 0.8132 - val_loss: 0.3895 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4340 - accuracy: 0.8146 - val_loss: 0.3892 - val_accuracy: 0.8268\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4343 - accuracy: 0.8202 - val_loss: 0.3902 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4343 - accuracy: 0.8202 - val_loss: 0.3891 - val_accuracy: 0.8268\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4350 - accuracy: 0.8090 - val_loss: 0.3927 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4352 - accuracy: 0.8202 - val_loss: 0.3913 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4333 - accuracy: 0.8174 - val_loss: 0.3903 - val_accuracy: 0.8268\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4320 - accuracy: 0.8146 - val_loss: 0.3879 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4325 - accuracy: 0.8202 - val_loss: 0.3872 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4329 - accuracy: 0.8160 - val_loss: 0.3889 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4334 - accuracy: 0.8216 - val_loss: 0.3878 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4320 - accuracy: 0.8216 - val_loss: 0.3885 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4330 - accuracy: 0.8090 - val_loss: 0.3886 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4317 - accuracy: 0.8174 - val_loss: 0.3879 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4328 - accuracy: 0.8160 - val_loss: 0.3872 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4315 - accuracy: 0.8146 - val_loss: 0.3857 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4314 - accuracy: 0.8216 - val_loss: 0.3876 - val_accuracy: 0.8212\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4326 - accuracy: 0.8146 - val_loss: 0.3890 - val_accuracy: 0.8212\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4314 - accuracy: 0.8146 - val_loss: 0.3867 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4303 - accuracy: 0.8202 - val_loss: 0.3890 - val_accuracy: 0.8212\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4316 - accuracy: 0.8118 - val_loss: 0.3851 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4313 - accuracy: 0.8160 - val_loss: 0.3890 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4305 - accuracy: 0.8146 - val_loss: 0.3860 - val_accuracy: 0.8212\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4311 - accuracy: 0.8188 - val_loss: 0.3887 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4323 - accuracy: 0.8188 - val_loss: 0.3831 - val_accuracy: 0.8212\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 78us/step - loss: 0.4328 - accuracy: 0.8202 - val_loss: 0.3851 - val_accuracy: 0.8212\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4310 - accuracy: 0.8211\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4350 - accuracy: 0.8211\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4314 - accuracy: 0.8263\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4325 - accuracy: 0.8193\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4324 - accuracy: 0.8211\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4302 - accuracy: 0.8281\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 165us/step - loss: 0.4306 - accuracy: 0.8281\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4286 - accuracy: 0.8246\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4276 - accuracy: 0.8263\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4307 - accuracy: 0.8211\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 164us/step - loss: 0.4311 - accuracy: 0.8228\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 168us/step - loss: 0.4311 - accuracy: 0.8281\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4291 - accuracy: 0.8263\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4306 - accuracy: 0.8193\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 155us/step - loss: 0.4282 - accuracy: 0.8228\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 181us/step - loss: 0.4266 - accuracy: 0.8263\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 155us/step - loss: 0.4269 - accuracy: 0.8263\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 165us/step - loss: 0.4272 - accuracy: 0.8281\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 170us/step - loss: 0.4275 - accuracy: 0.8246\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4268 - accuracy: 0.8228\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4264 - accuracy: 0.8211\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4262 - accuracy: 0.8228\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4273 - accuracy: 0.8281\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 165us/step - loss: 0.4284 - accuracy: 0.8281\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 157us/step - loss: 0.4226 - accuracy: 0.8228\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 167us/step - loss: 0.4335 - accuracy: 0.8316\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4262 - accuracy: 0.8281\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 165us/step - loss: 0.4242 - accuracy: 0.8228\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4263 - accuracy: 0.8316\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4259 - accuracy: 0.8333\n",
      "142/142 [==============================] - 0s 124us/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 701us/step - loss: 0.6533 - accuracy: 0.6166 - val_loss: 0.6454 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.6409 - accuracy: 0.6166 - val_loss: 0.6325 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6282 - accuracy: 0.6166 - val_loss: 0.6181 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6139 - accuracy: 0.6166 - val_loss: 0.6035 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.5990 - accuracy: 0.6180 - val_loss: 0.5872 - val_accuracy: 0.6425\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.5837 - accuracy: 0.6559 - val_loss: 0.5699 - val_accuracy: 0.7151\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.5695 - accuracy: 0.7430 - val_loss: 0.5539 - val_accuracy: 0.7598\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.5559 - accuracy: 0.7626 - val_loss: 0.5378 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5436 - accuracy: 0.7781 - val_loss: 0.5249 - val_accuracy: 0.7821\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.5339 - accuracy: 0.7837 - val_loss: 0.5139 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.5261 - accuracy: 0.7879 - val_loss: 0.5027 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.5192 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7765\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.5133 - accuracy: 0.7879 - val_loss: 0.4850 - val_accuracy: 0.7877\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.5087 - accuracy: 0.7865 - val_loss: 0.4797 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.5031 - accuracy: 0.7865 - val_loss: 0.4737 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4994 - accuracy: 0.7865 - val_loss: 0.4677 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4961 - accuracy: 0.7865 - val_loss: 0.4649 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4946 - accuracy: 0.7865 - val_loss: 0.4624 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4937 - accuracy: 0.7851 - val_loss: 0.4588 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4892 - accuracy: 0.7865 - val_loss: 0.4564 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4886 - accuracy: 0.7879 - val_loss: 0.4556 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4865 - accuracy: 0.7851 - val_loss: 0.4528 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4864 - accuracy: 0.7851 - val_loss: 0.4515 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4858 - accuracy: 0.7865 - val_loss: 0.4506 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4843 - accuracy: 0.7851 - val_loss: 0.4498 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4810 - accuracy: 0.7851 - val_loss: 0.4484 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4809 - accuracy: 0.7851 - val_loss: 0.4468 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 84us/step - loss: 0.4811 - accuracy: 0.7865 - val_loss: 0.4459 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4772 - accuracy: 0.7879 - val_loss: 0.4444 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4779 - accuracy: 0.7851 - val_loss: 0.4437 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4765 - accuracy: 0.7823 - val_loss: 0.4421 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4746 - accuracy: 0.7865 - val_loss: 0.4407 - val_accuracy: 0.7877\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4791 - accuracy: 0.7809 - val_loss: 0.4408 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4731 - accuracy: 0.7921 - val_loss: 0.4392 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4706 - accuracy: 0.7865 - val_loss: 0.4395 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4694 - accuracy: 0.7837 - val_loss: 0.4394 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4690 - accuracy: 0.7879 - val_loss: 0.4365 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4684 - accuracy: 0.7865 - val_loss: 0.4366 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.4349 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4659 - accuracy: 0.7879 - val_loss: 0.4335 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4687 - accuracy: 0.7907 - val_loss: 0.4368 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4650 - accuracy: 0.7851 - val_loss: 0.4300 - val_accuracy: 0.7821\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4653 - accuracy: 0.7879 - val_loss: 0.4327 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4649 - accuracy: 0.7879 - val_loss: 0.4291 - val_accuracy: 0.7877\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4628 - accuracy: 0.7879 - val_loss: 0.4304 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4631 - accuracy: 0.7865 - val_loss: 0.4282 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4633 - accuracy: 0.7907 - val_loss: 0.4262 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4613 - accuracy: 0.7893 - val_loss: 0.4252 - val_accuracy: 0.7877\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4588 - accuracy: 0.7879 - val_loss: 0.4248 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4583 - accuracy: 0.7865 - val_loss: 0.4229 - val_accuracy: 0.7877\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4579 - accuracy: 0.7921 - val_loss: 0.4233 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4569 - accuracy: 0.7893 - val_loss: 0.4255 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4572 - accuracy: 0.7907 - val_loss: 0.4218 - val_accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4559 - accuracy: 0.7879 - val_loss: 0.4229 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4563 - accuracy: 0.7907 - val_loss: 0.4204 - val_accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4558 - accuracy: 0.7963 - val_loss: 0.4252 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4556 - accuracy: 0.7921 - val_loss: 0.4205 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4532 - accuracy: 0.7907 - val_loss: 0.4215 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4534 - accuracy: 0.7921 - val_loss: 0.4210 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4519 - accuracy: 0.7921 - val_loss: 0.4214 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4520 - accuracy: 0.7935 - val_loss: 0.4203 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4508 - accuracy: 0.7935 - val_loss: 0.4190 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4512 - accuracy: 0.7907 - val_loss: 0.4171 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4514 - accuracy: 0.7978 - val_loss: 0.4189 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4496 - accuracy: 0.7935 - val_loss: 0.4176 - val_accuracy: 0.7933\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4500 - accuracy: 0.7935 - val_loss: 0.4170 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4497 - accuracy: 0.7978 - val_loss: 0.4187 - val_accuracy: 0.7933\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4477 - accuracy: 0.7963 - val_loss: 0.4163 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4468 - accuracy: 0.7935 - val_loss: 0.4173 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4464 - accuracy: 0.7949 - val_loss: 0.4161 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4460 - accuracy: 0.7978 - val_loss: 0.4167 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4466 - accuracy: 0.7963 - val_loss: 0.4134 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4461 - accuracy: 0.8020 - val_loss: 0.4146 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4442 - accuracy: 0.7992 - val_loss: 0.4141 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4440 - accuracy: 0.7992 - val_loss: 0.4143 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4450 - accuracy: 0.8020 - val_loss: 0.4129 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4451 - accuracy: 0.8006 - val_loss: 0.4154 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4430 - accuracy: 0.7992 - val_loss: 0.4135 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4427 - accuracy: 0.8034 - val_loss: 0.4142 - val_accuracy: 0.8045\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4421 - accuracy: 0.8006 - val_loss: 0.4137 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4436 - accuracy: 0.8034 - val_loss: 0.4115 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4417 - accuracy: 0.8062 - val_loss: 0.4124 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4419 - accuracy: 0.8062 - val_loss: 0.4126 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 84us/step - loss: 0.4429 - accuracy: 0.8076 - val_loss: 0.4140 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4415 - accuracy: 0.8076 - val_loss: 0.4113 - val_accuracy: 0.7933\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4409 - accuracy: 0.8104 - val_loss: 0.4124 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4400 - accuracy: 0.8090 - val_loss: 0.4133 - val_accuracy: 0.7989\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4414 - accuracy: 0.8062 - val_loss: 0.4118 - val_accuracy: 0.7989\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4454 - accuracy: 0.8076 - val_loss: 0.4143 - val_accuracy: 0.7989\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4419 - accuracy: 0.8118 - val_loss: 0.4140 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4407 - accuracy: 0.8076 - val_loss: 0.4133 - val_accuracy: 0.7989\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4401 - accuracy: 0.8062 - val_loss: 0.4120 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4400 - accuracy: 0.8104 - val_loss: 0.4107 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4383 - accuracy: 0.8090 - val_loss: 0.4106 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4378 - accuracy: 0.8090 - val_loss: 0.4125 - val_accuracy: 0.8045\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4380 - accuracy: 0.8132 - val_loss: 0.4118 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4391 - accuracy: 0.8132 - val_loss: 0.4116 - val_accuracy: 0.7933\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4399 - accuracy: 0.8118 - val_loss: 0.4123 - val_accuracy: 0.7989\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4380 - accuracy: 0.8076 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4376 - accuracy: 0.8160 - val_loss: 0.4111 - val_accuracy: 0.7933\n",
      "Epoch 1/60\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4198 - accuracy: 0.8190\n",
      "Epoch 2/60\n",
      "569/569 [==============================] - 0s 136us/step - loss: 0.4200 - accuracy: 0.8172\n",
      "Epoch 3/60\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4177 - accuracy: 0.8207\n",
      "Epoch 4/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4183 - accuracy: 0.8190\n",
      "Epoch 5/60\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.4185 - accuracy: 0.8207\n",
      "Epoch 6/60\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4185 - accuracy: 0.8172\n",
      "Epoch 7/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4161 - accuracy: 0.8207\n",
      "Epoch 8/60\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.4161 - accuracy: 0.8190\n",
      "Epoch 9/60\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4226 - accuracy: 0.8155\n",
      "Epoch 10/60\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4214 - accuracy: 0.8155\n",
      "Epoch 11/60\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4161 - accuracy: 0.8190\n",
      "Epoch 12/60\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.4183 - accuracy: 0.8172\n",
      "Epoch 13/60\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4133 - accuracy: 0.8225\n",
      "Epoch 14/60\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4132 - accuracy: 0.8207\n",
      "Epoch 15/60\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4101 - accuracy: 0.8190\n",
      "Epoch 16/60\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4126 - accuracy: 0.8172\n",
      "Epoch 17/60\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.4127 - accuracy: 0.8190\n",
      "Epoch 18/60\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4149 - accuracy: 0.8190\n",
      "Epoch 19/60\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.4135 - accuracy: 0.8243\n",
      "Epoch 20/60\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4136 - accuracy: 0.8225\n",
      "Epoch 21/60\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4111 - accuracy: 0.8190\n",
      "Epoch 22/60\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4135 - accuracy: 0.8172\n",
      "Epoch 23/60\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4114 - accuracy: 0.8207\n",
      "Epoch 24/60\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.4096 - accuracy: 0.8243\n",
      "Epoch 25/60\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4164 - accuracy: 0.8137\n",
      "Epoch 26/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4089 - accuracy: 0.8207\n",
      "Epoch 27/60\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4094 - accuracy: 0.8207\n",
      "Epoch 28/60\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4085 - accuracy: 0.8225\n",
      "Epoch 29/60\n",
      "569/569 [==============================] - 0s 152us/step - loss: 0.4063 - accuracy: 0.8225\n",
      "Epoch 30/60\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4074 - accuracy: 0.8243\n",
      "Epoch 31/60\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4112 - accuracy: 0.8172\n",
      "Epoch 32/60\n",
      "569/569 [==============================] - 0s 159us/step - loss: 0.4064 - accuracy: 0.8243\n",
      "Epoch 33/60\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.4070 - accuracy: 0.8225\n",
      "Epoch 34/60\n",
      "569/569 [==============================] - 0s 191us/step - loss: 0.4061 - accuracy: 0.8190\n",
      "Epoch 35/60\n",
      "569/569 [==============================] - 0s 180us/step - loss: 0.4086 - accuracy: 0.8260\n",
      "Epoch 36/60\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.4066 - accuracy: 0.8190\n",
      "Epoch 37/60\n",
      "569/569 [==============================] - 0s 172us/step - loss: 0.4083 - accuracy: 0.8278\n",
      "Epoch 38/60\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.4056 - accuracy: 0.8278\n",
      "Epoch 39/60\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4053 - accuracy: 0.8207\n",
      "Epoch 40/60\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.4062 - accuracy: 0.8207\n",
      "Epoch 41/60\n",
      "569/569 [==============================] - 0s 158us/step - loss: 0.4040 - accuracy: 0.8278\n",
      "Epoch 42/60\n",
      "569/569 [==============================] - 0s 176us/step - loss: 0.4041 - accuracy: 0.8225\n",
      "Epoch 43/60\n",
      "569/569 [==============================] - 0s 169us/step - loss: 0.4047 - accuracy: 0.8207\n",
      "Epoch 44/60\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.4029 - accuracy: 0.8243\n",
      "Epoch 45/60\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.4043 - accuracy: 0.8260\n",
      "Epoch 46/60\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4042 - accuracy: 0.8260\n",
      "Epoch 47/60\n",
      "569/569 [==============================] - 0s 201us/step - loss: 0.4027 - accuracy: 0.8243\n",
      "Epoch 48/60\n",
      "569/569 [==============================] - 0s 169us/step - loss: 0.4014 - accuracy: 0.8278\n",
      "Epoch 49/60\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.4028 - accuracy: 0.8243\n",
      "Epoch 50/60\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4017 - accuracy: 0.8260\n",
      "Epoch 51/60\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.4037 - accuracy: 0.8207\n",
      "Epoch 52/60\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4025 - accuracy: 0.8172\n",
      "Epoch 53/60\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4119 - accuracy: 0.8155\n",
      "Epoch 54/60\n",
      "569/569 [==============================] - 0s 159us/step - loss: 0.4044 - accuracy: 0.8278\n",
      "Epoch 55/60\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4024 - accuracy: 0.8190\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 135us/step - loss: 0.4064 - accuracy: 0.8260\n",
      "Epoch 57/60\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4014 - accuracy: 0.8207\n",
      "Epoch 58/60\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.4055 - accuracy: 0.8243\n",
      "Epoch 59/60\n",
      "569/569 [==============================] - 0s 180us/step - loss: 0.4022 - accuracy: 0.8225\n",
      "Epoch 60/60\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4006 - accuracy: 0.8278\n",
      "143/143 [==============================] - 0s 123us/step\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 514us/step - loss: 0.7143 - accuracy: 0.3834 - val_loss: 0.6954 - val_accuracy: 0.3911\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.6923 - accuracy: 0.4775 - val_loss: 0.6789 - val_accuracy: 0.7374\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.6784 - accuracy: 0.6952 - val_loss: 0.6700 - val_accuracy: 0.7430\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6694 - accuracy: 0.7177 - val_loss: 0.6618 - val_accuracy: 0.7374\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6548 - accuracy: 0.6924 - val_loss: 0.6438 - val_accuracy: 0.6816\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6286 - accuracy: 0.6699 - val_loss: 0.6129 - val_accuracy: 0.6480\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5995 - accuracy: 0.6657 - val_loss: 0.5831 - val_accuracy: 0.7039\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5736 - accuracy: 0.7233 - val_loss: 0.5496 - val_accuracy: 0.7709\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5491 - accuracy: 0.7556 - val_loss: 0.5168 - val_accuracy: 0.7765\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5252 - accuracy: 0.7823 - val_loss: 0.4889 - val_accuracy: 0.7877\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5058 - accuracy: 0.7851 - val_loss: 0.4691 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.84 - 0s 62us/step - loss: 0.4943 - accuracy: 0.7865 - val_loss: 0.4546 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4862 - accuracy: 0.7851 - val_loss: 0.4442 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4820 - accuracy: 0.7837 - val_loss: 0.4413 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4773 - accuracy: 0.7893 - val_loss: 0.4380 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4748 - accuracy: 0.7879 - val_loss: 0.4385 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4743 - accuracy: 0.7837 - val_loss: 0.4360 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4716 - accuracy: 0.7879 - val_loss: 0.4335 - val_accuracy: 0.7765\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4705 - accuracy: 0.7851 - val_loss: 0.4318 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4688 - accuracy: 0.7837 - val_loss: 0.4309 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4676 - accuracy: 0.7879 - val_loss: 0.4291 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4668 - accuracy: 0.7837 - val_loss: 0.4274 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.4274 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4636 - accuracy: 0.7879 - val_loss: 0.4253 - val_accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4634 - accuracy: 0.7893 - val_loss: 0.4246 - val_accuracy: 0.7765\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4627 - accuracy: 0.7865 - val_loss: 0.4221 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4626 - accuracy: 0.7823 - val_loss: 0.4252 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4620 - accuracy: 0.7851 - val_loss: 0.4243 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4593 - accuracy: 0.7851 - val_loss: 0.4214 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4596 - accuracy: 0.7837 - val_loss: 0.4200 - val_accuracy: 0.7765\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4596 - accuracy: 0.7851 - val_loss: 0.4235 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4578 - accuracy: 0.7837 - val_loss: 0.4181 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4579 - accuracy: 0.7851 - val_loss: 0.4212 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - 0s 75us/step - loss: 0.4567 - accuracy: 0.7837 - val_loss: 0.4170 - val_accuracy: 0.7821\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4564 - accuracy: 0.7823 - val_loss: 0.4184 - val_accuracy: 0.7765\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4569 - accuracy: 0.7893 - val_loss: 0.4160 - val_accuracy: 0.7821\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4560 - accuracy: 0.7879 - val_loss: 0.4172 - val_accuracy: 0.7709\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4563 - accuracy: 0.7907 - val_loss: 0.4168 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4576 - accuracy: 0.7879 - val_loss: 0.4188 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4531 - accuracy: 0.7893 - val_loss: 0.4148 - val_accuracy: 0.7765\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4537 - accuracy: 0.7879 - val_loss: 0.4160 - val_accuracy: 0.7765\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4571 - accuracy: 0.7893 - val_loss: 0.4144 - val_accuracy: 0.7821\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.4147 - val_accuracy: 0.7821\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4508 - accuracy: 0.7907 - val_loss: 0.4141 - val_accuracy: 0.7765\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.4128 - val_accuracy: 0.7821\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.4135 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4512 - accuracy: 0.7865 - val_loss: 0.4097 - val_accuracy: 0.7821\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4498 - accuracy: 0.7907 - val_loss: 0.4114 - val_accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4496 - accuracy: 0.7893 - val_loss: 0.4124 - val_accuracy: 0.7765\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4516 - accuracy: 0.7935 - val_loss: 0.4102 - val_accuracy: 0.7821\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4500 - accuracy: 0.7879 - val_loss: 0.4116 - val_accuracy: 0.7821\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4504 - accuracy: 0.7851 - val_loss: 0.4134 - val_accuracy: 0.7765\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.4111 - val_accuracy: 0.7765\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4464 - accuracy: 0.7949 - val_loss: 0.4116 - val_accuracy: 0.7821\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4459 - accuracy: 0.7978 - val_loss: 0.4123 - val_accuracy: 0.7765\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4463 - accuracy: 0.7893 - val_loss: 0.4108 - val_accuracy: 0.7765\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4468 - accuracy: 0.7949 - val_loss: 0.4103 - val_accuracy: 0.7821\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4462 - accuracy: 0.7879 - val_loss: 0.4116 - val_accuracy: 0.7765\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4452 - accuracy: 0.7992 - val_loss: 0.4105 - val_accuracy: 0.7765\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4106 - val_accuracy: 0.7765\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4462 - accuracy: 0.7963 - val_loss: 0.4092 - val_accuracy: 0.7821\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4468 - accuracy: 0.7949 - val_loss: 0.4111 - val_accuracy: 0.7765\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4445 - accuracy: 0.8006 - val_loss: 0.4076 - val_accuracy: 0.7821\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4440 - accuracy: 0.7893 - val_loss: 0.4093 - val_accuracy: 0.7821\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4449 - accuracy: 0.7978 - val_loss: 0.4070 - val_accuracy: 0.7821\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4420 - accuracy: 0.7921 - val_loss: 0.4086 - val_accuracy: 0.7765\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4438 - accuracy: 0.8006 - val_loss: 0.4072 - val_accuracy: 0.7821\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4435 - accuracy: 0.7935 - val_loss: 0.4090 - val_accuracy: 0.7709\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4432 - accuracy: 0.8006 - val_loss: 0.4089 - val_accuracy: 0.7765\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4412 - accuracy: 0.8006 - val_loss: 0.4101 - val_accuracy: 0.7765\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4407 - accuracy: 0.7949 - val_loss: 0.4078 - val_accuracy: 0.7765\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4403 - accuracy: 0.8020 - val_loss: 0.4070 - val_accuracy: 0.7709\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4399 - accuracy: 0.7978 - val_loss: 0.4066 - val_accuracy: 0.7709\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4396 - accuracy: 0.7949 - val_loss: 0.4092 - val_accuracy: 0.7765\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4408 - accuracy: 0.8006 - val_loss: 0.4074 - val_accuracy: 0.7765\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4395 - accuracy: 0.7963 - val_loss: 0.4061 - val_accuracy: 0.7765\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4376 - accuracy: 0.7978 - val_loss: 0.4072 - val_accuracy: 0.7765\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4375 - accuracy: 0.8020 - val_loss: 0.4077 - val_accuracy: 0.7765\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4378 - accuracy: 0.8034 - val_loss: 0.4062 - val_accuracy: 0.7765\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4370 - accuracy: 0.7949 - val_loss: 0.4065 - val_accuracy: 0.7765\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4375 - accuracy: 0.8006 - val_loss: 0.4061 - val_accuracy: 0.7765\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4385 - accuracy: 0.7992 - val_loss: 0.4076 - val_accuracy: 0.7765\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4375 - accuracy: 0.8034 - val_loss: 0.4047 - val_accuracy: 0.7765\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4364 - accuracy: 0.7963 - val_loss: 0.4038 - val_accuracy: 0.7765\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4350 - accuracy: 0.8006 - val_loss: 0.4055 - val_accuracy: 0.7765\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4359 - accuracy: 0.8006 - val_loss: 0.4050 - val_accuracy: 0.7821\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4348 - accuracy: 0.7992 - val_loss: 0.4075 - val_accuracy: 0.7933\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4353 - accuracy: 0.8034 - val_loss: 0.4043 - val_accuracy: 0.7765\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4359 - accuracy: 0.8006 - val_loss: 0.4022 - val_accuracy: 0.7765\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4341 - accuracy: 0.8006 - val_loss: 0.4037 - val_accuracy: 0.7765\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4344 - accuracy: 0.8048 - val_loss: 0.4035 - val_accuracy: 0.7765\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4339 - accuracy: 0.8020 - val_loss: 0.4044 - val_accuracy: 0.7765\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4333 - accuracy: 0.8020 - val_loss: 0.4044 - val_accuracy: 0.7821\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4332 - accuracy: 0.8020 - val_loss: 0.4031 - val_accuracy: 0.7821\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4320 - accuracy: 0.8034 - val_loss: 0.4042 - val_accuracy: 0.7821\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4318 - accuracy: 0.8062 - val_loss: 0.4053 - val_accuracy: 0.7933\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4324 - accuracy: 0.8062 - val_loss: 0.4023 - val_accuracy: 0.7989\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4318 - accuracy: 0.8006 - val_loss: 0.4079 - val_accuracy: 0.7989\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4313 - accuracy: 0.8076 - val_loss: 0.4050 - val_accuracy: 0.7877\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4312 - accuracy: 0.8034 - val_loss: 0.4048 - val_accuracy: 0.7933\n",
      "Epoch 1/60\n",
      "569/569 [==============================] - 0s 155us/step - loss: 0.4476 - accuracy: 0.7996\n",
      "Epoch 2/60\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4447 - accuracy: 0.7944\n",
      "Epoch 3/60\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.4454 - accuracy: 0.8014\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 143us/step - loss: 0.4518 - accuracy: 0.7979\n",
      "Epoch 5/60\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4434 - accuracy: 0.8014\n",
      "Epoch 6/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4434 - accuracy: 0.7996\n",
      "Epoch 7/60\n",
      "569/569 [==============================] - 0s 190us/step - loss: 0.4410 - accuracy: 0.7979\n",
      "Epoch 8/60\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4425 - accuracy: 0.8014\n",
      "Epoch 9/60\n",
      "569/569 [==============================] - 0s 179us/step - loss: 0.4389 - accuracy: 0.7979\n",
      "Epoch 10/60\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4400 - accuracy: 0.7961\n",
      "Epoch 11/60\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4436 - accuracy: 0.8014\n",
      "Epoch 12/60\n",
      "569/569 [==============================] - 0s 133us/step - loss: 0.4398 - accuracy: 0.7961\n",
      "Epoch 13/60\n",
      "569/569 [==============================] - 0s 173us/step - loss: 0.4391 - accuracy: 0.8049\n",
      "Epoch 14/60\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.4391 - accuracy: 0.8014\n",
      "Epoch 15/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4373 - accuracy: 0.8032\n",
      "Epoch 16/60\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4400 - accuracy: 0.8032\n",
      "Epoch 17/60\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4373 - accuracy: 0.8014\n",
      "Epoch 18/60\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4370 - accuracy: 0.8067\n",
      "Epoch 19/60\n",
      "569/569 [==============================] - 0s 119us/step - loss: 0.4394 - accuracy: 0.8067\n",
      "Epoch 20/60\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4383 - accuracy: 0.8014\n",
      "Epoch 21/60\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4389 - accuracy: 0.8084\n",
      "Epoch 22/60\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4377 - accuracy: 0.8067\n",
      "Epoch 23/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4379 - accuracy: 0.8102\n",
      "Epoch 24/60\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4399 - accuracy: 0.8102\n",
      "Epoch 25/60\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4365 - accuracy: 0.8102\n",
      "Epoch 26/60\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4342 - accuracy: 0.8014\n",
      "Epoch 27/60\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4368 - accuracy: 0.8084\n",
      "Epoch 28/60\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4365 - accuracy: 0.8032\n",
      "Epoch 29/60\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4351 - accuracy: 0.8102\n",
      "Epoch 30/60\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4333 - accuracy: 0.8067\n",
      "Epoch 31/60\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4354 - accuracy: 0.8084\n",
      "Epoch 32/60\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4342 - accuracy: 0.8067\n",
      "Epoch 33/60\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4339 - accuracy: 0.8067\n",
      "Epoch 34/60\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4331 - accuracy: 0.8084\n",
      "Epoch 35/60\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4330 - accuracy: 0.8049\n",
      "Epoch 36/60\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.4371 - accuracy: 0.8102\n",
      "Epoch 37/60\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4336 - accuracy: 0.8049\n",
      "Epoch 38/60\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4327 - accuracy: 0.8137\n",
      "Epoch 39/60\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4356 - accuracy: 0.8032\n",
      "Epoch 40/60\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4330 - accuracy: 0.8120\n",
      "Epoch 41/60\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4331 - accuracy: 0.8067\n",
      "Epoch 42/60\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4322 - accuracy: 0.8084\n",
      "Epoch 43/60\n",
      "569/569 [==============================] - 0s 118us/step - loss: 0.4300 - accuracy: 0.8137\n",
      "Epoch 44/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4320 - accuracy: 0.8067\n",
      "Epoch 45/60\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4378 - accuracy: 0.8102\n",
      "Epoch 46/60\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4340 - accuracy: 0.8120\n",
      "Epoch 47/60\n",
      "569/569 [==============================] - 0s 122us/step - loss: 0.4323 - accuracy: 0.8049\n",
      "Epoch 48/60\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4317 - accuracy: 0.8067\n",
      "Epoch 49/60\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4299 - accuracy: 0.8067\n",
      "Epoch 50/60\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4293 - accuracy: 0.8102\n",
      "Epoch 51/60\n",
      "569/569 [==============================] - 0s 133us/step - loss: 0.4291 - accuracy: 0.8084\n",
      "Epoch 52/60\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4330 - accuracy: 0.8084\n",
      "Epoch 53/60\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4298 - accuracy: 0.8084\n",
      "Epoch 54/60\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.4297 - accuracy: 0.8084\n",
      "Epoch 55/60\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.4280 - accuracy: 0.8102\n",
      "Epoch 56/60\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4288 - accuracy: 0.8102\n",
      "Epoch 57/60\n",
      "569/569 [==============================] - 0s 136us/step - loss: 0.4280 - accuracy: 0.8137\n",
      "Epoch 58/60\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4293 - accuracy: 0.8102\n",
      "Epoch 59/60\n",
      "569/569 [==============================] - 0s 134us/step - loss: 0.4280 - accuracy: 0.8137\n",
      "Epoch 60/60\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4320 - accuracy: 0.8102\n",
      "143/143 [==============================] - 0s 88us/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 530us/step - loss: 0.6835 - accuracy: 0.5716 - val_loss: 0.6729 - val_accuracy: 0.6257\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6732 - accuracy: 0.5772 - val_loss: 0.6606 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6641 - accuracy: 0.6096 - val_loss: 0.6501 - val_accuracy: 0.6480\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6556 - accuracy: 0.6306 - val_loss: 0.6393 - val_accuracy: 0.6816\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6444 - accuracy: 0.6517 - val_loss: 0.6219 - val_accuracy: 0.6872\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6275 - accuracy: 0.6573 - val_loss: 0.5987 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6036 - accuracy: 0.6742 - val_loss: 0.5660 - val_accuracy: 0.7263\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5726 - accuracy: 0.7177 - val_loss: 0.5289 - val_accuracy: 0.7989\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5450 - accuracy: 0.7669 - val_loss: 0.5021 - val_accuracy: 0.8156\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 78us/step - loss: 0.5230 - accuracy: 0.7739 - val_loss: 0.4769 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5057 - accuracy: 0.7823 - val_loss: 0.4606 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4940 - accuracy: 0.7823 - val_loss: 0.4503 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4901 - accuracy: 0.7837 - val_loss: 0.4431 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4858 - accuracy: 0.7865 - val_loss: 0.4401 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4786 - accuracy: 0.7823 - val_loss: 0.4353 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4749 - accuracy: 0.7851 - val_loss: 0.4348 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4740 - accuracy: 0.7865 - val_loss: 0.4298 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4726 - accuracy: 0.7837 - val_loss: 0.4299 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4702 - accuracy: 0.7865 - val_loss: 0.4243 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4715 - accuracy: 0.7823 - val_loss: 0.4226 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4689 - accuracy: 0.7851 - val_loss: 0.4245 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4660 - accuracy: 0.7851 - val_loss: 0.4219 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4637 - accuracy: 0.7837 - val_loss: 0.4224 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4630 - accuracy: 0.7865 - val_loss: 0.4221 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4620 - accuracy: 0.7837 - val_loss: 0.4214 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4609 - accuracy: 0.7851 - val_loss: 0.4200 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4608 - accuracy: 0.7851 - val_loss: 0.4159 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4590 - accuracy: 0.7893 - val_loss: 0.4135 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4586 - accuracy: 0.7907 - val_loss: 0.4161 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4588 - accuracy: 0.7865 - val_loss: 0.4138 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4569 - accuracy: 0.7907 - val_loss: 0.4146 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4550 - accuracy: 0.7893 - val_loss: 0.4120 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4541 - accuracy: 0.7935 - val_loss: 0.4128 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4535 - accuracy: 0.7907 - val_loss: 0.4105 - val_accuracy: 0.7821\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4520 - accuracy: 0.7893 - val_loss: 0.4105 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4520 - accuracy: 0.7907 - val_loss: 0.4083 - val_accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4516 - accuracy: 0.7893 - val_loss: 0.4103 - val_accuracy: 0.7989\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4509 - accuracy: 0.7949 - val_loss: 0.4093 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4532 - accuracy: 0.7949 - val_loss: 0.4115 - val_accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4510 - accuracy: 0.7978 - val_loss: 0.4085 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4490 - accuracy: 0.7935 - val_loss: 0.4096 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4477 - accuracy: 0.7949 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4497 - accuracy: 0.7949 - val_loss: 0.4109 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4468 - accuracy: 0.8020 - val_loss: 0.4095 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4466 - accuracy: 0.7992 - val_loss: 0.4061 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4455 - accuracy: 0.8034 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4465 - accuracy: 0.8048 - val_loss: 0.4052 - val_accuracy: 0.8101\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4449 - accuracy: 0.8020 - val_loss: 0.4052 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4449 - accuracy: 0.8062 - val_loss: 0.4032 - val_accuracy: 0.8156\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4445 - accuracy: 0.8006 - val_loss: 0.4048 - val_accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4424 - accuracy: 0.8076 - val_loss: 0.4048 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4412 - accuracy: 0.8062 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4402 - accuracy: 0.8090 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4422 - accuracy: 0.8076 - val_loss: 0.4013 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4402 - accuracy: 0.8118 - val_loss: 0.4003 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4389 - accuracy: 0.8034 - val_loss: 0.4001 - val_accuracy: 0.8156\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4374 - accuracy: 0.8146 - val_loss: 0.3991 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4366 - accuracy: 0.8104 - val_loss: 0.3993 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4400 - accuracy: 0.8118 - val_loss: 0.3999 - val_accuracy: 0.8156\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4370 - accuracy: 0.8048 - val_loss: 0.3985 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4379 - accuracy: 0.8132 - val_loss: 0.3995 - val_accuracy: 0.8156\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4350 - accuracy: 0.8160 - val_loss: 0.4001 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.93 - 0s 74us/step - loss: 0.4343 - accuracy: 0.8174 - val_loss: 0.3973 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4348 - accuracy: 0.8146 - val_loss: 0.3967 - val_accuracy: 0.8156\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4338 - accuracy: 0.8132 - val_loss: 0.3958 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 78us/step - loss: 0.4335 - accuracy: 0.8118 - val_loss: 0.3959 - val_accuracy: 0.8156\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4336 - accuracy: 0.8132 - val_loss: 0.3959 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4330 - accuracy: 0.8104 - val_loss: 0.3971 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4318 - accuracy: 0.8146 - val_loss: 0.3954 - val_accuracy: 0.8156\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4323 - accuracy: 0.8104 - val_loss: 0.3928 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4347 - accuracy: 0.8020 - val_loss: 0.3974 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4393 - accuracy: 0.8301 - val_loss: 0.3961 - val_accuracy: 0.8268\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4342 - accuracy: 0.8118 - val_loss: 0.3943 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4319 - accuracy: 0.8118 - val_loss: 0.3924 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4295 - accuracy: 0.8160 - val_loss: 0.3927 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4290 - accuracy: 0.8104 - val_loss: 0.3925 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4309 - accuracy: 0.8174 - val_loss: 0.3917 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4306 - accuracy: 0.8146 - val_loss: 0.3940 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4292 - accuracy: 0.8174 - val_loss: 0.3946 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4303 - accuracy: 0.8132 - val_loss: 0.3909 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4278 - accuracy: 0.8146 - val_loss: 0.3900 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4286 - accuracy: 0.8132 - val_loss: 0.3943 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4276 - accuracy: 0.8160 - val_loss: 0.3946 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.81 - 0s 78us/step - loss: 0.4265 - accuracy: 0.8132 - val_loss: 0.3956 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4292 - accuracy: 0.8160 - val_loss: 0.3927 - val_accuracy: 0.8212\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4262 - accuracy: 0.8188 - val_loss: 0.3931 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4263 - accuracy: 0.8174 - val_loss: 0.3908 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4263 - accuracy: 0.8104 - val_loss: 0.3922 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4304 - accuracy: 0.8132 - val_loss: 0.3924 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4249 - accuracy: 0.8174 - val_loss: 0.3939 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4267 - accuracy: 0.8216 - val_loss: 0.3910 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4287 - accuracy: 0.8090 - val_loss: 0.3937 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4251 - accuracy: 0.8174 - val_loss: 0.3923 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4288 - accuracy: 0.8146 - val_loss: 0.3953 - val_accuracy: 0.8268\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4247 - accuracy: 0.8132 - val_loss: 0.3925 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4244 - accuracy: 0.8188 - val_loss: 0.3927 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4244 - accuracy: 0.8118 - val_loss: 0.3907 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4259 - accuracy: 0.8160 - val_loss: 0.3905 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4255 - accuracy: 0.8174 - val_loss: 0.3900 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4267 - accuracy: 0.8160 - val_loss: 0.3937 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4270 - accuracy: 0.8140\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4271 - accuracy: 0.8158\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4255 - accuracy: 0.8088\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4286 - accuracy: 0.8175\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4247 - accuracy: 0.8158\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4237 - accuracy: 0.8193\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4242 - accuracy: 0.8140\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4213 - accuracy: 0.8123\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4237 - accuracy: 0.8070\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4201 - accuracy: 0.8123\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4226 - accuracy: 0.8158\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4243 - accuracy: 0.8140\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4170 - accuracy: 0.8158\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4224 - accuracy: 0.8105\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4219 - accuracy: 0.8175\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4193 - accuracy: 0.8175\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4176 - accuracy: 0.8158\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4146 - accuracy: 0.8193\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4145 - accuracy: 0.8105\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4218 - accuracy: 0.8175\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4146 - accuracy: 0.8193\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4183 - accuracy: 0.8140\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4144 - accuracy: 0.8105\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4151 - accuracy: 0.8140\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4179 - accuracy: 0.8211\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4143 - accuracy: 0.8211\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4139 - accuracy: 0.8211\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4133 - accuracy: 0.8105\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4134 - accuracy: 0.8175\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4106 - accuracy: 0.8211\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 137us/step - loss: 0.4151 - accuracy: 0.8175\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4157 - accuracy: 0.8140\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4130 - accuracy: 0.8228\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4159 - accuracy: 0.8123\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4119 - accuracy: 0.8211\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4113 - accuracy: 0.8228\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4098 - accuracy: 0.8211\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4098 - accuracy: 0.8158\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4132 - accuracy: 0.8263\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4090 - accuracy: 0.8281\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.4066 - accuracy: 0.8211\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4123 - accuracy: 0.8193\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4102 - accuracy: 0.8211\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4077 - accuracy: 0.8228\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 160us/step - loss: 0.4077 - accuracy: 0.8175\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4102 - accuracy: 0.8281\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4055 - accuracy: 0.8193\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4067 - accuracy: 0.8263\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4105 - accuracy: 0.8158\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4065 - accuracy: 0.8211\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4071 - accuracy: 0.8123\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4091 - accuracy: 0.8263\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4052 - accuracy: 0.8281\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4059 - accuracy: 0.8228\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4050 - accuracy: 0.8298\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4025 - accuracy: 0.8263\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4021 - accuracy: 0.8263\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4024 - accuracy: 0.8228\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.4043 - accuracy: 0.8298\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4041 - accuracy: 0.8211\n",
      "142/142 [==============================] - 0s 70us/step\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 514us/step - loss: 0.7859 - accuracy: 0.3834 - val_loss: 0.7092 - val_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6993 - accuracy: 0.4789 - val_loss: 0.6873 - val_accuracy: 0.6760\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6840 - accuracy: 0.6728 - val_loss: 0.6803 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6774 - accuracy: 0.6138 - val_loss: 0.6754 - val_accuracy: 0.6089\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6724 - accuracy: 0.6138 - val_loss: 0.6713 - val_accuracy: 0.6089\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.6678 - accuracy: 0.6152 - val_loss: 0.6672 - val_accuracy: 0.6145\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6633 - accuracy: 0.6166 - val_loss: 0.6631 - val_accuracy: 0.6145\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6584 - accuracy: 0.6166 - val_loss: 0.6581 - val_accuracy: 0.6145\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6523 - accuracy: 0.6166 - val_loss: 0.6508 - val_accuracy: 0.6145\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6426 - accuracy: 0.6166 - val_loss: 0.6376 - val_accuracy: 0.6145\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6290 - accuracy: 0.6306 - val_loss: 0.6207 - val_accuracy: 0.6313\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6110 - accuracy: 0.6728 - val_loss: 0.5944 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5878 - accuracy: 0.7907 - val_loss: 0.5664 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5614 - accuracy: 0.7907 - val_loss: 0.5360 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5399 - accuracy: 0.7851 - val_loss: 0.5146 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.5188 - accuracy: 0.7921 - val_loss: 0.4943 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5037 - accuracy: 0.7907 - val_loss: 0.4809 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4909 - accuracy: 0.7907 - val_loss: 0.4678 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4872 - accuracy: 0.7893 - val_loss: 0.4566 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4837 - accuracy: 0.7865 - val_loss: 0.4549 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4838 - accuracy: 0.7921 - val_loss: 0.4493 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4805 - accuracy: 0.7921 - val_loss: 0.4460 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4744 - accuracy: 0.7907 - val_loss: 0.4418 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4722 - accuracy: 0.7907 - val_loss: 0.4380 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4715 - accuracy: 0.7907 - val_loss: 0.4369 - val_accuracy: 0.7765\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4710 - accuracy: 0.7907 - val_loss: 0.4352 - val_accuracy: 0.7821\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4709 - accuracy: 0.7893 - val_loss: 0.4350 - val_accuracy: 0.7709\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4712 - accuracy: 0.7907 - val_loss: 0.4344 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 80us/step - loss: 0.4679 - accuracy: 0.7893 - val_loss: 0.4324 - val_accuracy: 0.7709\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4677 - accuracy: 0.7893 - val_loss: 0.4290 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4690 - accuracy: 0.7921 - val_loss: 0.4306 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4676 - accuracy: 0.7879 - val_loss: 0.4290 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4647 - accuracy: 0.7893 - val_loss: 0.4292 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4636 - accuracy: 0.7879 - val_loss: 0.4280 - val_accuracy: 0.7709\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4664 - accuracy: 0.7949 - val_loss: 0.4268 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4653 - accuracy: 0.7893 - val_loss: 0.4243 - val_accuracy: 0.7821\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4626 - accuracy: 0.7921 - val_loss: 0.4254 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4618 - accuracy: 0.7893 - val_loss: 0.4256 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4629 - accuracy: 0.7893 - val_loss: 0.4227 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4609 - accuracy: 0.7893 - val_loss: 0.4247 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4234 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4675 - accuracy: 0.7837 - val_loss: 0.4235 - val_accuracy: 0.7709\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4242 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4594 - accuracy: 0.7893 - val_loss: 0.4222 - val_accuracy: 0.7877\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4592 - accuracy: 0.7907 - val_loss: 0.4215 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4587 - accuracy: 0.7837 - val_loss: 0.4224 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4592 - accuracy: 0.7893 - val_loss: 0.4202 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.4206 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4572 - accuracy: 0.7907 - val_loss: 0.4195 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4598 - accuracy: 0.7893 - val_loss: 0.4184 - val_accuracy: 0.7877\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4592 - accuracy: 0.7921 - val_loss: 0.4227 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4583 - accuracy: 0.7907 - val_loss: 0.4170 - val_accuracy: 0.7877\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4568 - accuracy: 0.7921 - val_loss: 0.4159 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4566 - accuracy: 0.7963 - val_loss: 0.4154 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4591 - accuracy: 0.7893 - val_loss: 0.4162 - val_accuracy: 0.7821\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4563 - accuracy: 0.7949 - val_loss: 0.4148 - val_accuracy: 0.7877\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4565 - accuracy: 0.7935 - val_loss: 0.4169 - val_accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4570 - accuracy: 0.7935 - val_loss: 0.4159 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4542 - accuracy: 0.7949 - val_loss: 0.4156 - val_accuracy: 0.7877\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4586 - accuracy: 0.7921 - val_loss: 0.4215 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4556 - accuracy: 0.7935 - val_loss: 0.4144 - val_accuracy: 0.7877\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4564 - accuracy: 0.7963 - val_loss: 0.4130 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4543 - accuracy: 0.7963 - val_loss: 0.4139 - val_accuracy: 0.7877\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4528 - accuracy: 0.7935 - val_loss: 0.4120 - val_accuracy: 0.7877\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4520 - accuracy: 0.7949 - val_loss: 0.4144 - val_accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4528 - accuracy: 0.7963 - val_loss: 0.4127 - val_accuracy: 0.7877\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4531 - accuracy: 0.7978 - val_loss: 0.4135 - val_accuracy: 0.7877\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4539 - accuracy: 0.7949 - val_loss: 0.4137 - val_accuracy: 0.7933\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4505 - accuracy: 0.7963 - val_loss: 0.4168 - val_accuracy: 0.7877\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4557 - accuracy: 0.7949 - val_loss: 0.4129 - val_accuracy: 0.7877\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4506 - accuracy: 0.7949 - val_loss: 0.4130 - val_accuracy: 0.7877\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4491 - accuracy: 0.7949 - val_loss: 0.4113 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4498 - accuracy: 0.7992 - val_loss: 0.4092 - val_accuracy: 0.7933\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4493 - accuracy: 0.7949 - val_loss: 0.4117 - val_accuracy: 0.7877\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4483 - accuracy: 0.7963 - val_loss: 0.4100 - val_accuracy: 0.7989\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4485 - accuracy: 0.7978 - val_loss: 0.4105 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4482 - accuracy: 0.7963 - val_loss: 0.4132 - val_accuracy: 0.7933\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4481 - accuracy: 0.7978 - val_loss: 0.4114 - val_accuracy: 0.7933\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4476 - accuracy: 0.7949 - val_loss: 0.4081 - val_accuracy: 0.7877\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4467 - accuracy: 0.7921 - val_loss: 0.4088 - val_accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4468 - accuracy: 0.7992 - val_loss: 0.4078 - val_accuracy: 0.7933\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4462 - accuracy: 0.7963 - val_loss: 0.4102 - val_accuracy: 0.7933\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4515 - accuracy: 0.8076 - val_loss: 0.4130 - val_accuracy: 0.7933\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4451 - accuracy: 0.8076 - val_loss: 0.4094 - val_accuracy: 0.7933\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 82us/step - loss: 0.4451 - accuracy: 0.7978 - val_loss: 0.4092 - val_accuracy: 0.7989\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4450 - accuracy: 0.7992 - val_loss: 0.4081 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4437 - accuracy: 0.7963 - val_loss: 0.4079 - val_accuracy: 0.7933\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4456 - accuracy: 0.8006 - val_loss: 0.4108 - val_accuracy: 0.7933\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4441 - accuracy: 0.7978 - val_loss: 0.4126 - val_accuracy: 0.7933\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4458 - accuracy: 0.8034 - val_loss: 0.4134 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4484 - accuracy: 0.8020 - val_loss: 0.4073 - val_accuracy: 0.7989\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4420 - accuracy: 0.7978 - val_loss: 0.4069 - val_accuracy: 0.7989\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4416 - accuracy: 0.7992 - val_loss: 0.4053 - val_accuracy: 0.7989\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4417 - accuracy: 0.8048 - val_loss: 0.4087 - val_accuracy: 0.7989\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4426 - accuracy: 0.8006 - val_loss: 0.4064 - val_accuracy: 0.7989\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4416 - accuracy: 0.8076 - val_loss: 0.4069 - val_accuracy: 0.7989\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4402 - accuracy: 0.8062 - val_loss: 0.4048 - val_accuracy: 0.7989\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4401 - accuracy: 0.8006 - val_loss: 0.4059 - val_accuracy: 0.7989\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4393 - accuracy: 0.8034 - val_loss: 0.4047 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4401 - accuracy: 0.8062 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4497 - accuracy: 0.8123\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4389 - accuracy: 0.8053\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4378 - accuracy: 0.8105\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 154us/step - loss: 0.4419 - accuracy: 0.8193\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4372 - accuracy: 0.8053\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4391 - accuracy: 0.8018\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4434 - accuracy: 0.8053\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4346 - accuracy: 0.8140\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4352 - accuracy: 0.8070\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4398 - accuracy: 0.8070\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 120us/step - loss: 0.4339 - accuracy: 0.8140\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4310 - accuracy: 0.8105\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4358 - accuracy: 0.8035\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4343 - accuracy: 0.8105\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4316 - accuracy: 0.8105\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4306 - accuracy: 0.8105\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4298 - accuracy: 0.8193\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4314 - accuracy: 0.8140\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4304 - accuracy: 0.8140\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4274 - accuracy: 0.8211\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4308 - accuracy: 0.8123\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4286 - accuracy: 0.8105\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4287 - accuracy: 0.8175\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4278 - accuracy: 0.8193\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4291 - accuracy: 0.8123\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4333 - accuracy: 0.8211\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4309 - accuracy: 0.8175\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4312 - accuracy: 0.8158\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4299 - accuracy: 0.8193\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4247 - accuracy: 0.8175\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4242 - accuracy: 0.8193\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4266 - accuracy: 0.8193\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4271 - accuracy: 0.8175\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4292 - accuracy: 0.8175\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4253 - accuracy: 0.8228\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4226 - accuracy: 0.8175\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4266 - accuracy: 0.8211\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 121us/step - loss: 0.4241 - accuracy: 0.8158\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4216 - accuracy: 0.8175\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4220 - accuracy: 0.8158\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4206 - accuracy: 0.8193\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4207 - accuracy: 0.8211\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4220 - accuracy: 0.8158\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 119us/step - loss: 0.4257 - accuracy: 0.8175\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4234 - accuracy: 0.8140\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4254 - accuracy: 0.8158\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4234 - accuracy: 0.8211\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4178 - accuracy: 0.8211\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4211 - accuracy: 0.8193\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4191 - accuracy: 0.8175\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4187 - accuracy: 0.8211\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4197 - accuracy: 0.8140\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4197 - accuracy: 0.8175\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4200 - accuracy: 0.8211\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4188 - accuracy: 0.8175\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4243 - accuracy: 0.8175\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4183 - accuracy: 0.8211\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 154us/step - loss: 0.4246 - accuracy: 0.8193\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4176 - accuracy: 0.8193\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4166 - accuracy: 0.8193\n",
      "142/142 [==============================] - 0s 123us/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 500us/step - loss: 0.6847 - accuracy: 0.5435 - val_loss: 0.6326 - val_accuracy: 0.7598\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6301 - accuracy: 0.6910 - val_loss: 0.5944 - val_accuracy: 0.7095\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6066 - accuracy: 0.6685 - val_loss: 0.5744 - val_accuracy: 0.7095\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5874 - accuracy: 0.6812 - val_loss: 0.5531 - val_accuracy: 0.7318\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5657 - accuracy: 0.7219 - val_loss: 0.5295 - val_accuracy: 0.7709\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5446 - accuracy: 0.7739 - val_loss: 0.5084 - val_accuracy: 0.7765\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5282 - accuracy: 0.7753 - val_loss: 0.4915 - val_accuracy: 0.7821\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5165 - accuracy: 0.7851 - val_loss: 0.4773 - val_accuracy: 0.7765\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5061 - accuracy: 0.7837 - val_loss: 0.4651 - val_accuracy: 0.7765\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4998 - accuracy: 0.7851 - val_loss: 0.4571 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4957 - accuracy: 0.7865 - val_loss: 0.4532 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4922 - accuracy: 0.7865 - val_loss: 0.4499 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4893 - accuracy: 0.7907 - val_loss: 0.4484 - val_accuracy: 0.7877\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4858 - accuracy: 0.7851 - val_loss: 0.4431 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4854 - accuracy: 0.7865 - val_loss: 0.4437 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4826 - accuracy: 0.7907 - val_loss: 0.4400 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4803 - accuracy: 0.7907 - val_loss: 0.4387 - val_accuracy: 0.7933\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4802 - accuracy: 0.7907 - val_loss: 0.4351 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4777 - accuracy: 0.7921 - val_loss: 0.4347 - val_accuracy: 0.7989\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4746 - accuracy: 0.7907 - val_loss: 0.4322 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4740 - accuracy: 0.7893 - val_loss: 0.4309 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4715 - accuracy: 0.7921 - val_loss: 0.4303 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4712 - accuracy: 0.7978 - val_loss: 0.4292 - val_accuracy: 0.7989\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4696 - accuracy: 0.7978 - val_loss: 0.4274 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4683 - accuracy: 0.7963 - val_loss: 0.4259 - val_accuracy: 0.8045\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4661 - accuracy: 0.7949 - val_loss: 0.4234 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4647 - accuracy: 0.7963 - val_loss: 0.4229 - val_accuracy: 0.8045\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4645 - accuracy: 0.7978 - val_loss: 0.4185 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4626 - accuracy: 0.7978 - val_loss: 0.4192 - val_accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4650 - accuracy: 0.7949 - val_loss: 0.4208 - val_accuracy: 0.8045\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4602 - accuracy: 0.8062 - val_loss: 0.4204 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4594 - accuracy: 0.8006 - val_loss: 0.4159 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4585 - accuracy: 0.7978 - val_loss: 0.4149 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4561 - accuracy: 0.8020 - val_loss: 0.4135 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4558 - accuracy: 0.7992 - val_loss: 0.4103 - val_accuracy: 0.8101\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4542 - accuracy: 0.8006 - val_loss: 0.4104 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4537 - accuracy: 0.8020 - val_loss: 0.4089 - val_accuracy: 0.8101\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4542 - accuracy: 0.7992 - val_loss: 0.4093 - val_accuracy: 0.8101\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4504 - accuracy: 0.8006 - val_loss: 0.4080 - val_accuracy: 0.8156\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4501 - accuracy: 0.8020 - val_loss: 0.4079 - val_accuracy: 0.8101\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4500 - accuracy: 0.8020 - val_loss: 0.4079 - val_accuracy: 0.8045\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4479 - accuracy: 0.8034 - val_loss: 0.4049 - val_accuracy: 0.8101\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4479 - accuracy: 0.8034 - val_loss: 0.4049 - val_accuracy: 0.8156\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4460 - accuracy: 0.8034 - val_loss: 0.4061 - val_accuracy: 0.8101\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4485 - accuracy: 0.8048 - val_loss: 0.4062 - val_accuracy: 0.8156\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4464 - accuracy: 0.8034 - val_loss: 0.4027 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4451 - accuracy: 0.8104 - val_loss: 0.4044 - val_accuracy: 0.8101\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4429 - accuracy: 0.8076 - val_loss: 0.4025 - val_accuracy: 0.8045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4432 - accuracy: 0.8048 - val_loss: 0.3989 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4446 - accuracy: 0.8160 - val_loss: 0.4017 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4430 - accuracy: 0.8062 - val_loss: 0.4026 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4427 - accuracy: 0.8090 - val_loss: 0.4004 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4407 - accuracy: 0.8090 - val_loss: 0.4004 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4436 - accuracy: 0.8090 - val_loss: 0.4013 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4410 - accuracy: 0.8118 - val_loss: 0.3981 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4395 - accuracy: 0.8076 - val_loss: 0.3984 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4403 - accuracy: 0.8118 - val_loss: 0.3991 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4386 - accuracy: 0.8090 - val_loss: 0.3999 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4381 - accuracy: 0.8104 - val_loss: 0.3985 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4371 - accuracy: 0.8104 - val_loss: 0.3972 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4378 - accuracy: 0.8132 - val_loss: 0.3957 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.81 - 0s 81us/step - loss: 0.4399 - accuracy: 0.8132 - val_loss: 0.3975 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4373 - accuracy: 0.8076 - val_loss: 0.3943 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4378 - accuracy: 0.8132 - val_loss: 0.3934 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4364 - accuracy: 0.8118 - val_loss: 0.3939 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.3923 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4361 - accuracy: 0.8160 - val_loss: 0.3942 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4342 - accuracy: 0.8076 - val_loss: 0.3909 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4335 - accuracy: 0.8104 - val_loss: 0.3926 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4331 - accuracy: 0.8104 - val_loss: 0.3945 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4341 - accuracy: 0.8132 - val_loss: 0.3914 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4339 - accuracy: 0.8160 - val_loss: 0.3933 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4341 - accuracy: 0.8132 - val_loss: 0.3886 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4322 - accuracy: 0.8076 - val_loss: 0.3921 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4327 - accuracy: 0.8090 - val_loss: 0.3928 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4333 - accuracy: 0.8118 - val_loss: 0.3886 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4310 - accuracy: 0.8118 - val_loss: 0.3918 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4314 - accuracy: 0.8118 - val_loss: 0.3916 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4336 - accuracy: 0.8146 - val_loss: 0.3903 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4319 - accuracy: 0.8076 - val_loss: 0.3920 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4317 - accuracy: 0.8174 - val_loss: 0.3879 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4321 - accuracy: 0.8062 - val_loss: 0.3912 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4335 - accuracy: 0.8174 - val_loss: 0.3903 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4301 - accuracy: 0.8160 - val_loss: 0.3861 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4309 - accuracy: 0.8104 - val_loss: 0.3876 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4323 - accuracy: 0.8174 - val_loss: 0.3907 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4303 - accuracy: 0.8118 - val_loss: 0.3888 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4331 - accuracy: 0.8174 - val_loss: 0.3902 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4290 - accuracy: 0.8132 - val_loss: 0.3884 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4295 - accuracy: 0.8202 - val_loss: 0.3896 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4283 - accuracy: 0.8132 - val_loss: 0.3907 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4268 - accuracy: 0.8146 - val_loss: 0.3889 - val_accuracy: 0.8045\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4271 - accuracy: 0.8174 - val_loss: 0.3862 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4278 - accuracy: 0.8174 - val_loss: 0.3859 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4297 - accuracy: 0.8188 - val_loss: 0.3863 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4298 - accuracy: 0.8132 - val_loss: 0.3891 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4286 - accuracy: 0.8104 - val_loss: 0.3861 - val_accuracy: 0.8045\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4314 - accuracy: 0.8160 - val_loss: 0.3885 - val_accuracy: 0.8045\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4276 - accuracy: 0.8202 - val_loss: 0.3876 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4268 - accuracy: 0.8104 - val_loss: 0.3874 - val_accuracy: 0.8045\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4312 - accuracy: 0.8246\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4307 - accuracy: 0.8246\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4308 - accuracy: 0.8228\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4298 - accuracy: 0.8263\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4291 - accuracy: 0.8158\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4312 - accuracy: 0.8193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4342 - accuracy: 0.8211\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 162us/step - loss: 0.4268 - accuracy: 0.8263\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4310 - accuracy: 0.8246\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.81 - 0s 155us/step - loss: 0.4273 - accuracy: 0.8246\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4281 - accuracy: 0.8228\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4282 - accuracy: 0.8175\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4268 - accuracy: 0.8140\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4294 - accuracy: 0.8228\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4258 - accuracy: 0.8281\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 183us/step - loss: 0.4252 - accuracy: 0.8228\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4258 - accuracy: 0.8281\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4269 - accuracy: 0.8211\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 162us/step - loss: 0.4291 - accuracy: 0.8211\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4246 - accuracy: 0.8211\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4234 - accuracy: 0.8263\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4247 - accuracy: 0.8246\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4212 - accuracy: 0.8263\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4247 - accuracy: 0.8175\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4237 - accuracy: 0.8281\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4234 - accuracy: 0.8281\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4216 - accuracy: 0.8298\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 156us/step - loss: 0.4234 - accuracy: 0.8246\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4197 - accuracy: 0.8211\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4204 - accuracy: 0.8281\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4241 - accuracy: 0.8228\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4203 - accuracy: 0.8246\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4227 - accuracy: 0.8228\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4206 - accuracy: 0.8228\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4207 - accuracy: 0.8228\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4237 - accuracy: 0.8333\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4211 - accuracy: 0.8193\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4182 - accuracy: 0.8246\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4199 - accuracy: 0.8158\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4192 - accuracy: 0.8246\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4191 - accuracy: 0.8281\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4179 - accuracy: 0.8228\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4191 - accuracy: 0.8228\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4236 - accuracy: 0.8211\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4167 - accuracy: 0.8281\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4181 - accuracy: 0.8246\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4159 - accuracy: 0.8193\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4177 - accuracy: 0.8281\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4137 - accuracy: 0.8211\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4149 - accuracy: 0.8281\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4142 - accuracy: 0.8175\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 117us/step - loss: 0.4149 - accuracy: 0.8246\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4173 - accuracy: 0.8228\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4200 - accuracy: 0.8246\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4133 - accuracy: 0.8228\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4131 - accuracy: 0.8246\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4131 - accuracy: 0.8175\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4140 - accuracy: 0.8228\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4135 - accuracy: 0.8228\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4120 - accuracy: 0.8246\n",
      "142/142 [==============================] - 0s 74us/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_83 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 559us/step - loss: 0.6662 - accuracy: 0.5871 - val_loss: 0.6616 - val_accuracy: 0.6201\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6501 - accuracy: 0.6194 - val_loss: 0.6475 - val_accuracy: 0.6201\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6410 - accuracy: 0.6208 - val_loss: 0.6382 - val_accuracy: 0.6257\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.6310 - accuracy: 0.6250 - val_loss: 0.6276 - val_accuracy: 0.6369\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6166 - accuracy: 0.6278 - val_loss: 0.6015 - val_accuracy: 0.6480\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.5889 - accuracy: 0.6685 - val_loss: 0.5665 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5634 - accuracy: 0.7331 - val_loss: 0.5414 - val_accuracy: 0.7374\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5450 - accuracy: 0.7486 - val_loss: 0.5254 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5303 - accuracy: 0.7739 - val_loss: 0.5049 - val_accuracy: 0.7654\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5179 - accuracy: 0.7739 - val_loss: 0.4937 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5099 - accuracy: 0.7837 - val_loss: 0.4844 - val_accuracy: 0.7765\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 77us/step - loss: 0.5020 - accuracy: 0.7851 - val_loss: 0.4769 - val_accuracy: 0.7765\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4974 - accuracy: 0.7851 - val_loss: 0.4701 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4948 - accuracy: 0.7851 - val_loss: 0.4670 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4911 - accuracy: 0.7865 - val_loss: 0.4625 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4892 - accuracy: 0.7851 - val_loss: 0.4585 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4875 - accuracy: 0.7907 - val_loss: 0.4560 - val_accuracy: 0.7709\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4872 - accuracy: 0.7865 - val_loss: 0.4543 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4836 - accuracy: 0.7893 - val_loss: 0.4515 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4806 - accuracy: 0.7879 - val_loss: 0.4467 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4780 - accuracy: 0.7879 - val_loss: 0.4454 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4758 - accuracy: 0.7879 - val_loss: 0.4433 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4740 - accuracy: 0.7865 - val_loss: 0.4409 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4757 - accuracy: 0.7879 - val_loss: 0.4410 - val_accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4730 - accuracy: 0.7879 - val_loss: 0.4408 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4717 - accuracy: 0.7907 - val_loss: 0.4391 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4700 - accuracy: 0.7893 - val_loss: 0.4355 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4687 - accuracy: 0.7935 - val_loss: 0.4340 - val_accuracy: 0.7765\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4672 - accuracy: 0.7879 - val_loss: 0.4323 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4636 - accuracy: 0.7893 - val_loss: 0.4322 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4624 - accuracy: 0.7879 - val_loss: 0.4298 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4639 - accuracy: 0.7893 - val_loss: 0.4274 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4282 - val_accuracy: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4602 - accuracy: 0.7907 - val_loss: 0.4300 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4578 - accuracy: 0.7907 - val_loss: 0.4251 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4569 - accuracy: 0.7921 - val_loss: 0.4240 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4552 - accuracy: 0.7893 - val_loss: 0.4199 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4550 - accuracy: 0.7907 - val_loss: 0.4193 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4534 - accuracy: 0.7893 - val_loss: 0.4181 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4587 - accuracy: 0.7963 - val_loss: 0.4258 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4510 - accuracy: 0.7921 - val_loss: 0.4189 - val_accuracy: 0.7821\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4520 - accuracy: 0.8006 - val_loss: 0.4291 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4594 - accuracy: 0.8006 - val_loss: 0.4149 - val_accuracy: 0.7765\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4541 - accuracy: 0.7921 - val_loss: 0.4158 - val_accuracy: 0.7821\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4557 - accuracy: 0.8006 - val_loss: 0.4195 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4476 - accuracy: 0.7963 - val_loss: 0.4118 - val_accuracy: 0.7765\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4493 - accuracy: 0.7963 - val_loss: 0.4096 - val_accuracy: 0.7877\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4466 - accuracy: 0.7978 - val_loss: 0.4110 - val_accuracy: 0.7877\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4461 - accuracy: 0.8006 - val_loss: 0.4092 - val_accuracy: 0.7765\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4461 - accuracy: 0.8006 - val_loss: 0.4082 - val_accuracy: 0.7765\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4433 - accuracy: 0.8006 - val_loss: 0.4080 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4437 - accuracy: 0.8034 - val_loss: 0.4060 - val_accuracy: 0.7821\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4421 - accuracy: 0.8048 - val_loss: 0.4071 - val_accuracy: 0.7821\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4416 - accuracy: 0.8090 - val_loss: 0.4065 - val_accuracy: 0.7877\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4402 - accuracy: 0.8090 - val_loss: 0.4055 - val_accuracy: 0.7821\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4397 - accuracy: 0.8132 - val_loss: 0.4038 - val_accuracy: 0.7877\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4395 - accuracy: 0.8034 - val_loss: 0.4035 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4417 - accuracy: 0.8104 - val_loss: 0.4010 - val_accuracy: 0.7877\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4375 - accuracy: 0.8076 - val_loss: 0.3989 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.3999 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4408 - accuracy: 0.8076 - val_loss: 0.3992 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4344 - accuracy: 0.8132 - val_loss: 0.3999 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4358 - accuracy: 0.8076 - val_loss: 0.4022 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4362 - accuracy: 0.8146 - val_loss: 0.3999 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4352 - accuracy: 0.8146 - val_loss: 0.3966 - val_accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4339 - accuracy: 0.8118 - val_loss: 0.3962 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4324 - accuracy: 0.8104 - val_loss: 0.3974 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 82us/step - loss: 0.4351 - accuracy: 0.8118 - val_loss: 0.3927 - val_accuracy: 0.7933\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4349 - accuracy: 0.8146 - val_loss: 0.3932 - val_accuracy: 0.7933\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4329 - accuracy: 0.8132 - val_loss: 0.3941 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4329 - accuracy: 0.8076 - val_loss: 0.3920 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4314 - accuracy: 0.8132 - val_loss: 0.3964 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4318 - accuracy: 0.8090 - val_loss: 0.3916 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4315 - accuracy: 0.8132 - val_loss: 0.3936 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4286 - accuracy: 0.8160 - val_loss: 0.3918 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4301 - accuracy: 0.8174 - val_loss: 0.3920 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4297 - accuracy: 0.8160 - val_loss: 0.3901 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4281 - accuracy: 0.8132 - val_loss: 0.3881 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4284 - accuracy: 0.8188 - val_loss: 0.3967 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4346 - accuracy: 0.8076 - val_loss: 0.3880 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4290 - accuracy: 0.8090 - val_loss: 0.3897 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4305 - accuracy: 0.8174 - val_loss: 0.3903 - val_accuracy: 0.7989\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4270 - accuracy: 0.8188 - val_loss: 0.3890 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4288 - accuracy: 0.8118 - val_loss: 0.3895 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4271 - accuracy: 0.8188 - val_loss: 0.3926 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4283 - accuracy: 0.8132 - val_loss: 0.3903 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4249 - accuracy: 0.8160 - val_loss: 0.3922 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4285 - accuracy: 0.8132 - val_loss: 0.3918 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4252 - accuracy: 0.8146 - val_loss: 0.3883 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4243 - accuracy: 0.8132 - val_loss: 0.3883 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4275 - accuracy: 0.8160 - val_loss: 0.3952 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4237 - accuracy: 0.8132 - val_loss: 0.3901 - val_accuracy: 0.8045\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4272 - accuracy: 0.8104 - val_loss: 0.3888 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4253 - accuracy: 0.8174 - val_loss: 0.3874 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4249 - accuracy: 0.8174 - val_loss: 0.3855 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4231 - accuracy: 0.8118 - val_loss: 0.3887 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4236 - accuracy: 0.8230 - val_loss: 0.3935 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4246 - accuracy: 0.8160 - val_loss: 0.3879 - val_accuracy: 0.8045\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4234 - accuracy: 0.8132 - val_loss: 0.3887 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4229 - accuracy: 0.8174 - val_loss: 0.3881 - val_accuracy: 0.8101\n",
      "Epoch 1/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.4168 - accuracy: 0.8190\n",
      "Epoch 2/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.4125 - accuracy: 0.8260\n",
      "Epoch 3/90\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4078 - accuracy: 0.8225\n",
      "Epoch 4/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.4060 - accuracy: 0.8137\n",
      "Epoch 5/90\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4167 - accuracy: 0.8190\n",
      "Epoch 6/90\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4071 - accuracy: 0.8155\n",
      "Epoch 7/90\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4082 - accuracy: 0.8295\n",
      "Epoch 8/90\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4085 - accuracy: 0.8207\n",
      "Epoch 9/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4062 - accuracy: 0.8207\n",
      "Epoch 10/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4078 - accuracy: 0.8243\n",
      "Epoch 11/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.4049 - accuracy: 0.8243\n",
      "Epoch 12/90\n",
      "569/569 [==============================] - 0s 133us/step - loss: 0.4005 - accuracy: 0.8207\n",
      "Epoch 13/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4046 - accuracy: 0.8225\n",
      "Epoch 14/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4011 - accuracy: 0.8155\n",
      "Epoch 15/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4002 - accuracy: 0.8207\n",
      "Epoch 16/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.4005 - accuracy: 0.8190\n",
      "Epoch 17/90\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4005 - accuracy: 0.8225\n",
      "Epoch 18/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4010 - accuracy: 0.8172\n",
      "Epoch 19/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.3987 - accuracy: 0.8243\n",
      "Epoch 20/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.3982 - accuracy: 0.8190\n",
      "Epoch 21/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4042 - accuracy: 0.8278\n",
      "Epoch 22/90\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.4013 - accuracy: 0.8330\n",
      "Epoch 23/90\n",
      "569/569 [==============================] - 0s 136us/step - loss: 0.3996 - accuracy: 0.8243\n",
      "Epoch 24/90\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4009 - accuracy: 0.8207\n",
      "Epoch 25/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.3994 - accuracy: 0.8207\n",
      "Epoch 26/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4054 - accuracy: 0.8295\n",
      "Epoch 27/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.3990 - accuracy: 0.8278\n",
      "Epoch 28/90\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.3946 - accuracy: 0.8225\n",
      "Epoch 29/90\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.3947 - accuracy: 0.8295\n",
      "Epoch 30/90\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.4018 - accuracy: 0.8207\n",
      "Epoch 31/90\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.3960 - accuracy: 0.8172\n",
      "Epoch 32/90\n",
      "569/569 [==============================] - 0s 152us/step - loss: 0.3946 - accuracy: 0.8225\n",
      "Epoch 33/90\n",
      "569/569 [==============================] - 0s 165us/step - loss: 0.4024 - accuracy: 0.8278\n",
      "Epoch 34/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 174us/step - loss: 0.3958 - accuracy: 0.8225\n",
      "Epoch 35/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.3979 - accuracy: 0.8190\n",
      "Epoch 36/90\n",
      "569/569 [==============================] - 0s 173us/step - loss: 0.3968 - accuracy: 0.8260\n",
      "Epoch 37/90\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.4013 - accuracy: 0.8278\n",
      "Epoch 38/90\n",
      "569/569 [==============================] - 0s 176us/step - loss: 0.3958 - accuracy: 0.8260\n",
      "Epoch 39/90\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.3929 - accuracy: 0.8278\n",
      "Epoch 40/90\n",
      "569/569 [==============================] - 0s 158us/step - loss: 0.3941 - accuracy: 0.8278\n",
      "Epoch 41/90\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.3945 - accuracy: 0.8313\n",
      "Epoch 42/90\n",
      "569/569 [==============================] - 0s 163us/step - loss: 0.3922 - accuracy: 0.8225\n",
      "Epoch 43/90\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.3950 - accuracy: 0.8295\n",
      "Epoch 44/90\n",
      "569/569 [==============================] - 0s 178us/step - loss: 0.3946 - accuracy: 0.8278\n",
      "Epoch 45/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.3948 - accuracy: 0.8313\n",
      "Epoch 46/90\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.3956 - accuracy: 0.8260\n",
      "Epoch 47/90\n",
      "569/569 [==============================] - 0s 169us/step - loss: 0.3921 - accuracy: 0.8243\n",
      "Epoch 48/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.3935 - accuracy: 0.8260\n",
      "Epoch 49/90\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.3919 - accuracy: 0.8243\n",
      "Epoch 50/90\n",
      "569/569 [==============================] - 0s 153us/step - loss: 0.3909 - accuracy: 0.8313\n",
      "Epoch 51/90\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.3963 - accuracy: 0.8260\n",
      "Epoch 52/90\n",
      "569/569 [==============================] - 0s 164us/step - loss: 0.3946 - accuracy: 0.8348\n",
      "Epoch 53/90\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.3938 - accuracy: 0.8225\n",
      "Epoch 54/90\n",
      "569/569 [==============================] - 0s 152us/step - loss: 0.3912 - accuracy: 0.8295\n",
      "Epoch 55/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.3897 - accuracy: 0.8243\n",
      "Epoch 56/90\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.3995 - accuracy: 0.8207\n",
      "Epoch 57/90\n",
      "569/569 [==============================] - 0s 119us/step - loss: 0.3893 - accuracy: 0.8295\n",
      "Epoch 58/90\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.3957 - accuracy: 0.8137\n",
      "Epoch 59/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.3893 - accuracy: 0.8366\n",
      "Epoch 60/90\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.3922 - accuracy: 0.8295\n",
      "Epoch 61/90\n",
      "569/569 [==============================] - 0s 136us/step - loss: 0.3961 - accuracy: 0.8295\n",
      "Epoch 62/90\n",
      "569/569 [==============================] - 0s 155us/step - loss: 0.3916 - accuracy: 0.8313\n",
      "Epoch 63/90\n",
      "569/569 [==============================] - 0s 142us/step - loss: 0.3941 - accuracy: 0.8278\n",
      "Epoch 64/90\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.3902 - accuracy: 0.8295\n",
      "Epoch 65/90\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.3931 - accuracy: 0.8348\n",
      "Epoch 66/90\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.3903 - accuracy: 0.8260\n",
      "Epoch 67/90\n",
      "569/569 [==============================] - 0s 174us/step - loss: 0.3913 - accuracy: 0.8295\n",
      "Epoch 68/90\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.3885 - accuracy: 0.8313\n",
      "Epoch 69/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.3959 - accuracy: 0.8260\n",
      "Epoch 70/90\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.3871 - accuracy: 0.8295\n",
      "Epoch 71/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.3890 - accuracy: 0.8295\n",
      "Epoch 72/90\n",
      "569/569 [==============================] - 0s 122us/step - loss: 0.3864 - accuracy: 0.8295\n",
      "Epoch 73/90\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.3880 - accuracy: 0.8278\n",
      "Epoch 74/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.3894 - accuracy: 0.8383\n",
      "Epoch 75/90\n",
      "569/569 [==============================] - 0s 182us/step - loss: 0.3870 - accuracy: 0.8313\n",
      "Epoch 76/90\n",
      "569/569 [==============================] - 0s 177us/step - loss: 0.3873 - accuracy: 0.82430s - loss: 0.4167 - accuracy: 0.79\n",
      "Epoch 77/90\n",
      "569/569 [==============================] - 0s 119us/step - loss: 0.3893 - accuracy: 0.8295\n",
      "Epoch 78/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.3866 - accuracy: 0.8313\n",
      "Epoch 79/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.3884 - accuracy: 0.8260\n",
      "Epoch 80/90\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.3856 - accuracy: 0.8313\n",
      "Epoch 81/90\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.3867 - accuracy: 0.8348\n",
      "Epoch 82/90\n",
      "569/569 [==============================] - 0s 182us/step - loss: 0.3857 - accuracy: 0.8383\n",
      "Epoch 83/90\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.3878 - accuracy: 0.8330\n",
      "Epoch 84/90\n",
      "569/569 [==============================] - 0s 122us/step - loss: 0.3846 - accuracy: 0.8313\n",
      "Epoch 85/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.3847 - accuracy: 0.8366\n",
      "Epoch 86/90\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.3843 - accuracy: 0.8295\n",
      "Epoch 87/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.3897 - accuracy: 0.8330\n",
      "Epoch 88/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.3830 - accuracy: 0.8295\n",
      "Epoch 89/90\n",
      "569/569 [==============================] - 0s 158us/step - loss: 0.3852 - accuracy: 0.8383\n",
      "Epoch 90/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.3840 - accuracy: 0.8348\n",
      "143/143 [==============================] - 0s 92us/step\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 534us/step - loss: 0.6454 - accuracy: 0.6784 - val_loss: 0.6297 - val_accuracy: 0.6872\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.6210 - accuracy: 0.6657 - val_loss: 0.6077 - val_accuracy: 0.7095\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.6002 - accuracy: 0.6882 - val_loss: 0.5825 - val_accuracy: 0.7430\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5773 - accuracy: 0.7388 - val_loss: 0.5540 - val_accuracy: 0.7598\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.5556 - accuracy: 0.7486 - val_loss: 0.5252 - val_accuracy: 0.7598\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5350 - accuracy: 0.7528 - val_loss: 0.5022 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5181 - accuracy: 0.7725 - val_loss: 0.4811 - val_accuracy: 0.7598\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5039 - accuracy: 0.7739 - val_loss: 0.4648 - val_accuracy: 0.7877\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4953 - accuracy: 0.7697 - val_loss: 0.4535 - val_accuracy: 0.7654\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 78us/step - loss: 0.4879 - accuracy: 0.7837 - val_loss: 0.4442 - val_accuracy: 0.7877\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.78 - 0s 93us/step - loss: 0.4815 - accuracy: 0.7837 - val_loss: 0.4374 - val_accuracy: 0.7765\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4778 - accuracy: 0.7893 - val_loss: 0.4351 - val_accuracy: 0.7765\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4743 - accuracy: 0.7907 - val_loss: 0.4317 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4727 - accuracy: 0.7935 - val_loss: 0.4308 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4733 - accuracy: 0.7907 - val_loss: 0.4310 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4698 - accuracy: 0.7893 - val_loss: 0.4288 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4694 - accuracy: 0.7907 - val_loss: 0.4276 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4670 - accuracy: 0.7837 - val_loss: 0.4266 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4657 - accuracy: 0.7879 - val_loss: 0.4257 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4656 - accuracy: 0.7893 - val_loss: 0.4274 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4673 - accuracy: 0.7865 - val_loss: 0.4266 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4630 - accuracy: 0.7879 - val_loss: 0.4257 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4637 - accuracy: 0.7865 - val_loss: 0.4261 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4616 - accuracy: 0.7879 - val_loss: 0.4234 - val_accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4610 - accuracy: 0.7879 - val_loss: 0.4225 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4607 - accuracy: 0.7865 - val_loss: 0.4205 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4595 - accuracy: 0.7851 - val_loss: 0.4212 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4628 - accuracy: 0.7837 - val_loss: 0.4215 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4589 - accuracy: 0.7851 - val_loss: 0.4217 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4585 - accuracy: 0.7865 - val_loss: 0.4195 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4576 - accuracy: 0.7851 - val_loss: 0.4213 - val_accuracy: 0.7821\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4581 - accuracy: 0.7907 - val_loss: 0.4195 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4569 - accuracy: 0.7851 - val_loss: 0.4176 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4574 - accuracy: 0.7893 - val_loss: 0.4183 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4556 - accuracy: 0.7837 - val_loss: 0.4171 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4554 - accuracy: 0.7893 - val_loss: 0.4176 - val_accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4555 - accuracy: 0.7879 - val_loss: 0.4159 - val_accuracy: 0.7989\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4547 - accuracy: 0.7935 - val_loss: 0.4162 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4538 - accuracy: 0.7907 - val_loss: 0.4143 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4534 - accuracy: 0.7907 - val_loss: 0.4162 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4547 - accuracy: 0.7963 - val_loss: 0.4136 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4567 - accuracy: 0.7949 - val_loss: 0.4172 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4499 - accuracy: 0.7935 - val_loss: 0.4196 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4577 - accuracy: 0.7992 - val_loss: 0.4147 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4510 - accuracy: 0.7949 - val_loss: 0.4145 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4529 - accuracy: 0.7949 - val_loss: 0.4153 - val_accuracy: 0.7877\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4493 - accuracy: 0.7921 - val_loss: 0.4124 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4494 - accuracy: 0.7935 - val_loss: 0.4119 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4483 - accuracy: 0.7921 - val_loss: 0.4129 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4496 - accuracy: 0.8020 - val_loss: 0.4116 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4503 - accuracy: 0.7907 - val_loss: 0.4136 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4547 - accuracy: 0.7978 - val_loss: 0.4169 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4486 - accuracy: 0.7949 - val_loss: 0.4131 - val_accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4471 - accuracy: 0.7935 - val_loss: 0.4085 - val_accuracy: 0.8045\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4467 - accuracy: 0.7992 - val_loss: 0.4110 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.78 - 0s 74us/step - loss: 0.4465 - accuracy: 0.7921 - val_loss: 0.4108 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4467 - accuracy: 0.7978 - val_loss: 0.4104 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4466 - accuracy: 0.7963 - val_loss: 0.4118 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4474 - accuracy: 0.7949 - val_loss: 0.4107 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4444 - accuracy: 0.8034 - val_loss: 0.4103 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4435 - accuracy: 0.8020 - val_loss: 0.4121 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4440 - accuracy: 0.7992 - val_loss: 0.4086 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4461 - accuracy: 0.7963 - val_loss: 0.4078 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4453 - accuracy: 0.8048 - val_loss: 0.4082 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4419 - accuracy: 0.8062 - val_loss: 0.4082 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 63us/step - loss: 0.4431 - accuracy: 0.7992 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4424 - accuracy: 0.8034 - val_loss: 0.4089 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4435 - accuracy: 0.8062 - val_loss: 0.4093 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4417 - accuracy: 0.8020 - val_loss: 0.4057 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4405 - accuracy: 0.8034 - val_loss: 0.4087 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4416 - accuracy: 0.8062 - val_loss: 0.4095 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4413 - accuracy: 0.8048 - val_loss: 0.4068 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4401 - accuracy: 0.8048 - val_loss: 0.4051 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4390 - accuracy: 0.8062 - val_loss: 0.4119 - val_accuracy: 0.7989\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4443 - accuracy: 0.8104 - val_loss: 0.4095 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4396 - accuracy: 0.8090 - val_loss: 0.4064 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4435 - accuracy: 0.8048 - val_loss: 0.4053 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4411 - accuracy: 0.8020 - val_loss: 0.4046 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4380 - accuracy: 0.8090 - val_loss: 0.4054 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4390 - accuracy: 0.8104 - val_loss: 0.4039 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4380 - accuracy: 0.8076 - val_loss: 0.4022 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4379 - accuracy: 0.8118 - val_loss: 0.4026 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4363 - accuracy: 0.8104 - val_loss: 0.4020 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4370 - accuracy: 0.8118 - val_loss: 0.4003 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4353 - accuracy: 0.8146 - val_loss: 0.4013 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4361 - accuracy: 0.8160 - val_loss: 0.3995 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4379 - accuracy: 0.8216 - val_loss: 0.4063 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4381 - accuracy: 0.8202 - val_loss: 0.3999 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4349 - accuracy: 0.8216 - val_loss: 0.4020 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4341 - accuracy: 0.8132 - val_loss: 0.4009 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4340 - accuracy: 0.8216 - val_loss: 0.3985 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4336 - accuracy: 0.8160 - val_loss: 0.4001 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4345 - accuracy: 0.8160 - val_loss: 0.4021 - val_accuracy: 0.8212\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4333 - accuracy: 0.8202 - val_loss: 0.3991 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.75 - 0s 87us/step - loss: 0.4321 - accuracy: 0.8202 - val_loss: 0.4005 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4320 - accuracy: 0.8188 - val_loss: 0.4001 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4348 - accuracy: 0.8160 - val_loss: 0.4042 - val_accuracy: 0.8212\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4337 - accuracy: 0.8188 - val_loss: 0.3972 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4318 - accuracy: 0.8202 - val_loss: 0.4002 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4325 - accuracy: 0.8174 - val_loss: 0.4000 - val_accuracy: 0.8212\n",
      "Epoch 1/90\n",
      "569/569 [==============================] - 0s 133us/step - loss: 0.4482 - accuracy: 0.8120\n",
      "Epoch 2/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4449 - accuracy: 0.8102\n",
      "Epoch 3/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4472 - accuracy: 0.8120\n",
      "Epoch 4/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4436 - accuracy: 0.8102\n",
      "Epoch 5/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.4424 - accuracy: 0.8137\n",
      "Epoch 6/90\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4445 - accuracy: 0.8207\n",
      "Epoch 7/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4433 - accuracy: 0.8172\n",
      "Epoch 8/90\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.4409 - accuracy: 0.8137\n",
      "Epoch 9/90\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4453 - accuracy: 0.8243\n",
      "Epoch 10/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4400 - accuracy: 0.8137\n",
      "Epoch 11/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4422 - accuracy: 0.8155\n",
      "Epoch 12/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4399 - accuracy: 0.8172\n",
      "Epoch 13/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4421 - accuracy: 0.8155\n",
      "Epoch 14/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4405 - accuracy: 0.8137\n",
      "Epoch 15/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4400 - accuracy: 0.8190\n",
      "Epoch 16/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4461 - accuracy: 0.8225\n",
      "Epoch 17/90\n",
      "569/569 [==============================] - 0s 134us/step - loss: 0.4421 - accuracy: 0.8137\n",
      "Epoch 18/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4402 - accuracy: 0.8137\n",
      "Epoch 19/90\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4401 - accuracy: 0.8207\n",
      "Epoch 20/90\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4406 - accuracy: 0.8190\n",
      "Epoch 21/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4369 - accuracy: 0.8102\n",
      "Epoch 22/90\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4389 - accuracy: 0.8190\n",
      "Epoch 23/90\n",
      "569/569 [==============================] - 0s 159us/step - loss: 0.4380 - accuracy: 0.8225\n",
      "Epoch 24/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4394 - accuracy: 0.8155\n",
      "Epoch 25/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4375 - accuracy: 0.8190\n",
      "Epoch 26/90\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.4368 - accuracy: 0.8207\n",
      "Epoch 27/90\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4376 - accuracy: 0.8172\n",
      "Epoch 28/90\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4361 - accuracy: 0.8243\n",
      "Epoch 29/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4492 - accuracy: 0.8155\n",
      "Epoch 30/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4400 - accuracy: 0.8225\n",
      "Epoch 31/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 149us/step - loss: 0.4448 - accuracy: 0.8120\n",
      "Epoch 32/90\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4405 - accuracy: 0.8172\n",
      "Epoch 33/90\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.4329 - accuracy: 0.8225\n",
      "Epoch 34/90\n",
      "569/569 [==============================] - 0s 164us/step - loss: 0.4347 - accuracy: 0.8207\n",
      "Epoch 35/90\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.4314 - accuracy: 0.8225\n",
      "Epoch 36/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4414 - accuracy: 0.8155\n",
      "Epoch 37/90\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.4326 - accuracy: 0.8207\n",
      "Epoch 38/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4352 - accuracy: 0.8243\n",
      "Epoch 39/90\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.4326 - accuracy: 0.8190\n",
      "Epoch 40/90\n",
      "569/569 [==============================] - 0s 163us/step - loss: 0.4353 - accuracy: 0.8225\n",
      "Epoch 41/90\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4345 - accuracy: 0.8243\n",
      "Epoch 42/90\n",
      "569/569 [==============================] - 0s 175us/step - loss: 0.4331 - accuracy: 0.8225\n",
      "Epoch 43/90\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4313 - accuracy: 0.8225\n",
      "Epoch 44/90\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4328 - accuracy: 0.8260\n",
      "Epoch 45/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4333 - accuracy: 0.8120\n",
      "Epoch 46/90\n",
      "569/569 [==============================] - 0s 177us/step - loss: 0.4400 - accuracy: 0.8155\n",
      "Epoch 47/90\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4400 - accuracy: 0.8207\n",
      "Epoch 48/90\n",
      "569/569 [==============================] - 0s 140us/step - loss: 0.4346 - accuracy: 0.8243\n",
      "Epoch 49/90\n",
      "569/569 [==============================] - 0s 173us/step - loss: 0.4359 - accuracy: 0.8225\n",
      "Epoch 50/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4285 - accuracy: 0.8243\n",
      "Epoch 51/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4359 - accuracy: 0.8260\n",
      "Epoch 52/90\n",
      "569/569 [==============================] - 0s 184us/step - loss: 0.4311 - accuracy: 0.8207\n",
      "Epoch 53/90\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.4344 - accuracy: 0.8190\n",
      "Epoch 54/90\n",
      "569/569 [==============================] - 0s 170us/step - loss: 0.4331 - accuracy: 0.8190\n",
      "Epoch 55/90\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.4289 - accuracy: 0.8225\n",
      "Epoch 56/90\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.4312 - accuracy: 0.8260\n",
      "Epoch 57/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4301 - accuracy: 0.8260\n",
      "Epoch 58/90\n",
      "569/569 [==============================] - 0s 155us/step - loss: 0.4335 - accuracy: 0.8207\n",
      "Epoch 59/90\n",
      "569/569 [==============================] - 0s 124us/step - loss: 0.4318 - accuracy: 0.8260\n",
      "Epoch 60/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4314 - accuracy: 0.8207\n",
      "Epoch 61/90\n",
      "569/569 [==============================] - 0s 133us/step - loss: 0.4289 - accuracy: 0.8243\n",
      "Epoch 62/90\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4278 - accuracy: 0.8243\n",
      "Epoch 63/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.4320 - accuracy: 0.8190\n",
      "Epoch 64/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4275 - accuracy: 0.8207\n",
      "Epoch 65/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4290 - accuracy: 0.8225\n",
      "Epoch 66/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.4314 - accuracy: 0.8190\n",
      "Epoch 67/90\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4268 - accuracy: 0.8225\n",
      "Epoch 68/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4278 - accuracy: 0.8190\n",
      "Epoch 69/90\n",
      "569/569 [==============================] - 0s 153us/step - loss: 0.4322 - accuracy: 0.8172\n",
      "Epoch 70/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4272 - accuracy: 0.8225\n",
      "Epoch 71/90\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.4286 - accuracy: 0.8207\n",
      "Epoch 72/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4288 - accuracy: 0.8225\n",
      "Epoch 73/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4290 - accuracy: 0.8243\n",
      "Epoch 74/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.4302 - accuracy: 0.8207\n",
      "Epoch 75/90\n",
      "569/569 [==============================] - 0s 127us/step - loss: 0.4309 - accuracy: 0.8278\n",
      "Epoch 76/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.4258 - accuracy: 0.8207\n",
      "Epoch 77/90\n",
      "569/569 [==============================] - 0s 145us/step - loss: 0.4244 - accuracy: 0.8243\n",
      "Epoch 78/90\n",
      "569/569 [==============================] - 0s 150us/step - loss: 0.4260 - accuracy: 0.8190\n",
      "Epoch 79/90\n",
      "569/569 [==============================] - 0s 129us/step - loss: 0.4246 - accuracy: 0.8243\n",
      "Epoch 80/90\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4266 - accuracy: 0.8260\n",
      "Epoch 81/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4272 - accuracy: 0.8207\n",
      "Epoch 82/90\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4254 - accuracy: 0.8225\n",
      "Epoch 83/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.4258 - accuracy: 0.8260\n",
      "Epoch 84/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4247 - accuracy: 0.8207\n",
      "Epoch 85/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4259 - accuracy: 0.8155\n",
      "Epoch 86/90\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4248 - accuracy: 0.8190\n",
      "Epoch 87/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4258 - accuracy: 0.8225\n",
      "Epoch 88/90\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4273 - accuracy: 0.8225\n",
      "Epoch 89/90\n",
      "569/569 [==============================] - 0s 133us/step - loss: 0.4230 - accuracy: 0.8207\n",
      "Epoch 90/90\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4230 - accuracy: 0.8225\n",
      "143/143 [==============================] - 0s 88us/step\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 518us/step - loss: 1.1391 - accuracy: 0.3834 - val_loss: 0.9165 - val_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.8552 - accuracy: 0.3806 - val_loss: 0.7480 - val_accuracy: 0.3855\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.7293 - accuracy: 0.3961 - val_loss: 0.6900 - val_accuracy: 0.4972\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6803 - accuracy: 0.5829 - val_loss: 0.6627 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6626 - accuracy: 0.6166 - val_loss: 0.6505 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6512 - accuracy: 0.6166 - val_loss: 0.6359 - val_accuracy: 0.6145\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6363 - accuracy: 0.6166 - val_loss: 0.6197 - val_accuracy: 0.6145\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 74us/step - loss: 0.6210 - accuracy: 0.6194 - val_loss: 0.6030 - val_accuracy: 0.6201\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6050 - accuracy: 0.6236 - val_loss: 0.5854 - val_accuracy: 0.6425\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5885 - accuracy: 0.6447 - val_loss: 0.5688 - val_accuracy: 0.6592\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5724 - accuracy: 0.6756 - val_loss: 0.5538 - val_accuracy: 0.7039\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5580 - accuracy: 0.7331 - val_loss: 0.5377 - val_accuracy: 0.7486\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5449 - accuracy: 0.7683 - val_loss: 0.5221 - val_accuracy: 0.7598\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5285 - accuracy: 0.7837 - val_loss: 0.5037 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5091 - accuracy: 0.7907 - val_loss: 0.4786 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4948 - accuracy: 0.7893 - val_loss: 0.4606 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4844 - accuracy: 0.7935 - val_loss: 0.4466 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4775 - accuracy: 0.7865 - val_loss: 0.4381 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4730 - accuracy: 0.7851 - val_loss: 0.4350 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4703 - accuracy: 0.7907 - val_loss: 0.4315 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4677 - accuracy: 0.7879 - val_loss: 0.4300 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4657 - accuracy: 0.7893 - val_loss: 0.4284 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4639 - accuracy: 0.7921 - val_loss: 0.4293 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4633 - accuracy: 0.7935 - val_loss: 0.4264 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4614 - accuracy: 0.7907 - val_loss: 0.4234 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4590 - accuracy: 0.7893 - val_loss: 0.4219 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4573 - accuracy: 0.7921 - val_loss: 0.4192 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4577 - accuracy: 0.7907 - val_loss: 0.4212 - val_accuracy: 0.7765\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4552 - accuracy: 0.7879 - val_loss: 0.4185 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4539 - accuracy: 0.7963 - val_loss: 0.4187 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4524 - accuracy: 0.7992 - val_loss: 0.4199 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4517 - accuracy: 0.7978 - val_loss: 0.4174 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4509 - accuracy: 0.8006 - val_loss: 0.4159 - val_accuracy: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4480 - accuracy: 0.8020 - val_loss: 0.4135 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4499 - accuracy: 0.7963 - val_loss: 0.4137 - val_accuracy: 0.7765\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4480 - accuracy: 0.8020 - val_loss: 0.4131 - val_accuracy: 0.7821\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4478 - accuracy: 0.8048 - val_loss: 0.4125 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4452 - accuracy: 0.8034 - val_loss: 0.4114 - val_accuracy: 0.7877\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4454 - accuracy: 0.8048 - val_loss: 0.4112 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4435 - accuracy: 0.8048 - val_loss: 0.4090 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4449 - accuracy: 0.8048 - val_loss: 0.4106 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4453 - accuracy: 0.8076 - val_loss: 0.4085 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4424 - accuracy: 0.8062 - val_loss: 0.4092 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4413 - accuracy: 0.8090 - val_loss: 0.4062 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4417 - accuracy: 0.8104 - val_loss: 0.4068 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4414 - accuracy: 0.8090 - val_loss: 0.4035 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4394 - accuracy: 0.8104 - val_loss: 0.4049 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4404 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4388 - accuracy: 0.8104 - val_loss: 0.4047 - val_accuracy: 0.7877\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4375 - accuracy: 0.8104 - val_loss: 0.4041 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4379 - accuracy: 0.8104 - val_loss: 0.4057 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4368 - accuracy: 0.8118 - val_loss: 0.4019 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4357 - accuracy: 0.8104 - val_loss: 0.4027 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4361 - accuracy: 0.8118 - val_loss: 0.4030 - val_accuracy: 0.8045\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4357 - accuracy: 0.8104 - val_loss: 0.4013 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4346 - accuracy: 0.8118 - val_loss: 0.4023 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4361 - accuracy: 0.8160 - val_loss: 0.4030 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4357 - accuracy: 0.8132 - val_loss: 0.4015 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4339 - accuracy: 0.8160 - val_loss: 0.4011 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4345 - accuracy: 0.8118 - val_loss: 0.4016 - val_accuracy: 0.8156\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4429 - accuracy: 0.8216 - val_loss: 0.4022 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4340 - accuracy: 0.8118 - val_loss: 0.4010 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4325 - accuracy: 0.8174 - val_loss: 0.3992 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 78us/step - loss: 0.4335 - accuracy: 0.8118 - val_loss: 0.3998 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4341 - accuracy: 0.8160 - val_loss: 0.3991 - val_accuracy: 0.7989\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4322 - accuracy: 0.8174 - val_loss: 0.4004 - val_accuracy: 0.8156\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4336 - accuracy: 0.8146 - val_loss: 0.4003 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4309 - accuracy: 0.8160 - val_loss: 0.3990 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4308 - accuracy: 0.8146 - val_loss: 0.3976 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4322 - accuracy: 0.8174 - val_loss: 0.3992 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4301 - accuracy: 0.8160 - val_loss: 0.3971 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4313 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4311 - accuracy: 0.8160 - val_loss: 0.3978 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4327 - accuracy: 0.8174 - val_loss: 0.3972 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4313 - accuracy: 0.8188 - val_loss: 0.3968 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4311 - accuracy: 0.8174 - val_loss: 0.3970 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4288 - accuracy: 0.8174 - val_loss: 0.3958 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4309 - accuracy: 0.8216 - val_loss: 0.3963 - val_accuracy: 0.7989\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4308 - accuracy: 0.8202 - val_loss: 0.3984 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4303 - accuracy: 0.8188 - val_loss: 0.3943 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4334 - accuracy: 0.8104 - val_loss: 0.3942 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4288 - accuracy: 0.8188 - val_loss: 0.3927 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4273 - accuracy: 0.8202 - val_loss: 0.3924 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4278 - accuracy: 0.8174 - val_loss: 0.3921 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4279 - accuracy: 0.8174 - val_loss: 0.3964 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4284 - accuracy: 0.8202 - val_loss: 0.3965 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4286 - accuracy: 0.8230 - val_loss: 0.3922 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4261 - accuracy: 0.8216 - val_loss: 0.3934 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4266 - accuracy: 0.8216 - val_loss: 0.3917 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4254 - accuracy: 0.8216 - val_loss: 0.3917 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4276 - accuracy: 0.8216 - val_loss: 0.3927 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4267 - accuracy: 0.8230 - val_loss: 0.3912 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4282 - accuracy: 0.8202 - val_loss: 0.3937 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4270 - accuracy: 0.8244 - val_loss: 0.3912 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4266 - accuracy: 0.8202 - val_loss: 0.3885 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4252 - accuracy: 0.8216 - val_loss: 0.3923 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4246 - accuracy: 0.8230 - val_loss: 0.3904 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4264 - accuracy: 0.8244 - val_loss: 0.3907 - val_accuracy: 0.8045\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4276 - accuracy: 0.8301 - val_loss: 0.3905 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4246 - accuracy: 0.8230 - val_loss: 0.3901 - val_accuracy: 0.8101\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 121us/step - loss: 0.4243 - accuracy: 0.8175\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4266 - accuracy: 0.8140\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4230 - accuracy: 0.8228\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4200 - accuracy: 0.8246\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4195 - accuracy: 0.8228\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4209 - accuracy: 0.8228\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4211 - accuracy: 0.8211\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4158 - accuracy: 0.8263\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4199 - accuracy: 0.8228\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4179 - accuracy: 0.8263\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4197 - accuracy: 0.8228\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4163 - accuracy: 0.8211\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4176 - accuracy: 0.8228\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4156 - accuracy: 0.8263\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4178 - accuracy: 0.8228\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4143 - accuracy: 0.8263\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4141 - accuracy: 0.8298\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4155 - accuracy: 0.8228\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4155 - accuracy: 0.8228\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4182 - accuracy: 0.8298\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4127 - accuracy: 0.8263\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4132 - accuracy: 0.8228\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4193 - accuracy: 0.8316\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4176 - accuracy: 0.8228\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4132 - accuracy: 0.8263\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4190 - accuracy: 0.8228\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4098 - accuracy: 0.8281\n",
      "Epoch 28/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 125us/step - loss: 0.4132 - accuracy: 0.8263\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4131 - accuracy: 0.8263\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4125 - accuracy: 0.8316\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.82 - 0s 123us/step - loss: 0.4111 - accuracy: 0.8298\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4114 - accuracy: 0.8281\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4134 - accuracy: 0.8246\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4095 - accuracy: 0.8333\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4115 - accuracy: 0.8281\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4100 - accuracy: 0.8263\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 175us/step - loss: 0.4088 - accuracy: 0.8298\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4106 - accuracy: 0.8246\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4080 - accuracy: 0.8246\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 157us/step - loss: 0.4077 - accuracy: 0.8316\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 175us/step - loss: 0.4142 - accuracy: 0.8246\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4094 - accuracy: 0.8298\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4072 - accuracy: 0.8298\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4081 - accuracy: 0.8263\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 159us/step - loss: 0.4111 - accuracy: 0.8263\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 155us/step - loss: 0.4137 - accuracy: 0.8298\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 188us/step - loss: 0.4064 - accuracy: 0.8281\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4089 - accuracy: 0.8298\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4083 - accuracy: 0.8333\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4086 - accuracy: 0.8263\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4076 - accuracy: 0.8298\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4091 - accuracy: 0.8316\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 174us/step - loss: 0.4056 - accuracy: 0.8316\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4051 - accuracy: 0.8281\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4079 - accuracy: 0.8281\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 170us/step - loss: 0.4068 - accuracy: 0.8333\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4084 - accuracy: 0.8211\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4064 - accuracy: 0.8281\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4058 - accuracy: 0.8316\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 165us/step - loss: 0.4053 - accuracy: 0.8298\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4044 - accuracy: 0.8298\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4068 - accuracy: 0.8263\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4041 - accuracy: 0.8316\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4045 - accuracy: 0.8351\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4063 - accuracy: 0.8281\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4033 - accuracy: 0.8316\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4033 - accuracy: 0.8316\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 158us/step - loss: 0.4029 - accuracy: 0.8316\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4079 - accuracy: 0.8246\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4033 - accuracy: 0.8281\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4031 - accuracy: 0.8281\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4018 - accuracy: 0.8316\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4070 - accuracy: 0.8298\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4044 - accuracy: 0.8316\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4040 - accuracy: 0.8316\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4043 - accuracy: 0.8281\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4018 - accuracy: 0.8281\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.83 - 0s 132us/step - loss: 0.4035 - accuracy: 0.8263\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 120us/step - loss: 0.4013 - accuracy: 0.8333\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.3990 - accuracy: 0.8298\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4077 - accuracy: 0.8351\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4018 - accuracy: 0.8281\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4001 - accuracy: 0.8316\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4005 - accuracy: 0.8281\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4014 - accuracy: 0.8298\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4022 - accuracy: 0.8316\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4037 - accuracy: 0.8246\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4053 - accuracy: 0.8298\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.3994 - accuracy: 0.8298\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4008 - accuracy: 0.8263\n",
      "142/142 [==============================] - 0s 76us/step\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 502us/step - loss: 0.6591 - accuracy: 0.6053 - val_loss: 0.6531 - val_accuracy: 0.6313\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6377 - accuracy: 0.6194 - val_loss: 0.6332 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6238 - accuracy: 0.6250 - val_loss: 0.6157 - val_accuracy: 0.6257\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6118 - accuracy: 0.6419 - val_loss: 0.5987 - val_accuracy: 0.7039\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 81us/step - loss: 0.5984 - accuracy: 0.6742 - val_loss: 0.5820 - val_accuracy: 0.7151\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5854 - accuracy: 0.6896 - val_loss: 0.5660 - val_accuracy: 0.6983\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5719 - accuracy: 0.6910 - val_loss: 0.5499 - val_accuracy: 0.7095\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5597 - accuracy: 0.7051 - val_loss: 0.5358 - val_accuracy: 0.7318\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5484 - accuracy: 0.7289 - val_loss: 0.5218 - val_accuracy: 0.7374\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5356 - accuracy: 0.7542 - val_loss: 0.5070 - val_accuracy: 0.7598\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5251 - accuracy: 0.7598 - val_loss: 0.4959 - val_accuracy: 0.7598\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5140 - accuracy: 0.7711 - val_loss: 0.4870 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5052 - accuracy: 0.7851 - val_loss: 0.4772 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.75 - 0s 77us/step - loss: 0.4982 - accuracy: 0.7851 - val_loss: 0.4710 - val_accuracy: 0.7989\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4948 - accuracy: 0.7851 - val_loss: 0.4649 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4894 - accuracy: 0.7879 - val_loss: 0.4609 - val_accuracy: 0.8045\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4862 - accuracy: 0.7865 - val_loss: 0.4586 - val_accuracy: 0.8045\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4835 - accuracy: 0.7893 - val_loss: 0.4576 - val_accuracy: 0.7989\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4831 - accuracy: 0.7893 - val_loss: 0.4546 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4794 - accuracy: 0.7963 - val_loss: 0.4547 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4772 - accuracy: 0.7893 - val_loss: 0.4506 - val_accuracy: 0.7989\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4769 - accuracy: 0.7921 - val_loss: 0.4492 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4742 - accuracy: 0.7935 - val_loss: 0.4503 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4733 - accuracy: 0.7978 - val_loss: 0.4504 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4722 - accuracy: 0.7935 - val_loss: 0.4467 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4720 - accuracy: 0.7935 - val_loss: 0.4469 - val_accuracy: 0.7821\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4696 - accuracy: 0.7978 - val_loss: 0.4465 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4687 - accuracy: 0.8006 - val_loss: 0.4468 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4669 - accuracy: 0.7992 - val_loss: 0.4443 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4669 - accuracy: 0.7978 - val_loss: 0.4428 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4644 - accuracy: 0.8034 - val_loss: 0.4452 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4665 - accuracy: 0.8048 - val_loss: 0.4420 - val_accuracy: 0.7877\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4631 - accuracy: 0.8020 - val_loss: 0.4403 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4627 - accuracy: 0.8034 - val_loss: 0.4399 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4606 - accuracy: 0.8020 - val_loss: 0.4385 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4594 - accuracy: 0.8076 - val_loss: 0.4379 - val_accuracy: 0.7821\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4606 - accuracy: 0.8006 - val_loss: 0.4390 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4572 - accuracy: 0.8062 - val_loss: 0.4361 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4572 - accuracy: 0.8090 - val_loss: 0.4349 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4554 - accuracy: 0.8090 - val_loss: 0.4354 - val_accuracy: 0.7821\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4542 - accuracy: 0.8118 - val_loss: 0.4327 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4539 - accuracy: 0.8062 - val_loss: 0.4323 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4524 - accuracy: 0.8118 - val_loss: 0.4329 - val_accuracy: 0.7821\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4523 - accuracy: 0.8104 - val_loss: 0.4310 - val_accuracy: 0.7821\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4509 - accuracy: 0.8118 - val_loss: 0.4300 - val_accuracy: 0.7821\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4509 - accuracy: 0.8104 - val_loss: 0.4312 - val_accuracy: 0.7821\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4496 - accuracy: 0.8104 - val_loss: 0.4279 - val_accuracy: 0.7821\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4488 - accuracy: 0.8118 - val_loss: 0.4275 - val_accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4480 - accuracy: 0.8104 - val_loss: 0.4279 - val_accuracy: 0.7877\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4469 - accuracy: 0.8104 - val_loss: 0.4268 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4486 - accuracy: 0.8104 - val_loss: 0.4255 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4459 - accuracy: 0.8104 - val_loss: 0.4262 - val_accuracy: 0.7877\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4454 - accuracy: 0.8118 - val_loss: 0.4252 - val_accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4455 - accuracy: 0.8104 - val_loss: 0.4249 - val_accuracy: 0.7877\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4446 - accuracy: 0.8104 - val_loss: 0.4258 - val_accuracy: 0.7877\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4448 - accuracy: 0.8048 - val_loss: 0.4235 - val_accuracy: 0.7877\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4437 - accuracy: 0.8104 - val_loss: 0.4228 - val_accuracy: 0.7877\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4425 - accuracy: 0.8104 - val_loss: 0.4229 - val_accuracy: 0.7877\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4413 - accuracy: 0.8104 - val_loss: 0.4233 - val_accuracy: 0.7877\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4417 - accuracy: 0.8118 - val_loss: 0.4222 - val_accuracy: 0.7877\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 78us/step - loss: 0.4409 - accuracy: 0.8132 - val_loss: 0.4216 - val_accuracy: 0.7877\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4406 - accuracy: 0.8090 - val_loss: 0.4216 - val_accuracy: 0.7877\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4403 - accuracy: 0.8160 - val_loss: 0.4203 - val_accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4392 - accuracy: 0.8104 - val_loss: 0.4211 - val_accuracy: 0.7877\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4379 - accuracy: 0.8160 - val_loss: 0.4215 - val_accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4380 - accuracy: 0.8132 - val_loss: 0.4195 - val_accuracy: 0.7877\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4378 - accuracy: 0.8118 - val_loss: 0.4181 - val_accuracy: 0.7877\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4369 - accuracy: 0.8132 - val_loss: 0.4183 - val_accuracy: 0.7877\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4361 - accuracy: 0.8118 - val_loss: 0.4183 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4360 - accuracy: 0.8160 - val_loss: 0.4165 - val_accuracy: 0.7877\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4355 - accuracy: 0.8132 - val_loss: 0.4146 - val_accuracy: 0.7933\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4370 - accuracy: 0.8160 - val_loss: 0.4150 - val_accuracy: 0.7933\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4416 - accuracy: 0.8076 - val_loss: 0.4157 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4349 - accuracy: 0.8174 - val_loss: 0.4152 - val_accuracy: 0.7989\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4347 - accuracy: 0.8118 - val_loss: 0.4174 - val_accuracy: 0.7989\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4337 - accuracy: 0.8118 - val_loss: 0.4157 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4325 - accuracy: 0.8118 - val_loss: 0.4152 - val_accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4331 - accuracy: 0.8146 - val_loss: 0.4136 - val_accuracy: 0.7989\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4333 - accuracy: 0.8118 - val_loss: 0.4139 - val_accuracy: 0.7989\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4317 - accuracy: 0.8146 - val_loss: 0.4142 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4313 - accuracy: 0.8146 - val_loss: 0.4121 - val_accuracy: 0.7989\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4333 - accuracy: 0.8132 - val_loss: 0.4113 - val_accuracy: 0.7989\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4303 - accuracy: 0.8146 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.90 - 0s 79us/step - loss: 0.4297 - accuracy: 0.8146 - val_loss: 0.4127 - val_accuracy: 0.7989\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4323 - accuracy: 0.8090 - val_loss: 0.4140 - val_accuracy: 0.7989\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4297 - accuracy: 0.8174 - val_loss: 0.4114 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4320 - accuracy: 0.8160 - val_loss: 0.4101 - val_accuracy: 0.7989\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4305 - accuracy: 0.8188 - val_loss: 0.4117 - val_accuracy: 0.7989\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4313 - accuracy: 0.8160 - val_loss: 0.4116 - val_accuracy: 0.7989\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4289 - accuracy: 0.8160 - val_loss: 0.4109 - val_accuracy: 0.7989\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4284 - accuracy: 0.8146 - val_loss: 0.4110 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4306 - accuracy: 0.8216 - val_loss: 0.4112 - val_accuracy: 0.7989\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.78 - 0s 73us/step - loss: 0.4292 - accuracy: 0.8118 - val_loss: 0.4102 - val_accuracy: 0.7989\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4280 - accuracy: 0.8174 - val_loss: 0.4106 - val_accuracy: 0.7989\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4269 - accuracy: 0.8132 - val_loss: 0.4098 - val_accuracy: 0.7989\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4278 - accuracy: 0.8188 - val_loss: 0.4105 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4276 - accuracy: 0.8160 - val_loss: 0.4102 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4305 - accuracy: 0.8146 - val_loss: 0.4097 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4292 - accuracy: 0.8244 - val_loss: 0.4087 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4273 - accuracy: 0.8146 - val_loss: 0.4057 - val_accuracy: 0.8101\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4321 - accuracy: 0.81580s - loss: 0.4467 - accuracy: 0.79\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 119us/step - loss: 0.4343 - accuracy: 0.8088\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4335 - accuracy: 0.8140\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4325 - accuracy: 0.8123\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4306 - accuracy: 0.8088\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4325 - accuracy: 0.8088\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4311 - accuracy: 0.8193\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4304 - accuracy: 0.8105\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4295 - accuracy: 0.8175\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4286 - accuracy: 0.8193\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4322 - accuracy: 0.8140\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4281 - accuracy: 0.8175\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4309 - accuracy: 0.8123\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4296 - accuracy: 0.8193\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4314 - accuracy: 0.8053\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4277 - accuracy: 0.8193\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.82 - 0s 125us/step - loss: 0.4275 - accuracy: 0.8193\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4301 - accuracy: 0.8140\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4256 - accuracy: 0.8175\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4260 - accuracy: 0.8211\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4293 - accuracy: 0.8193\n",
      "Epoch 22/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 145us/step - loss: 0.4263 - accuracy: 0.8193\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4280 - accuracy: 0.8105\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4259 - accuracy: 0.8123\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4261 - accuracy: 0.8228\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 117us/step - loss: 0.4244 - accuracy: 0.8193\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4252 - accuracy: 0.8211\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4265 - accuracy: 0.8193\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4242 - accuracy: 0.8175\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4230 - accuracy: 0.8158\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 135us/step - loss: 0.4227 - accuracy: 0.8211\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4246 - accuracy: 0.8193\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4227 - accuracy: 0.8211\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4228 - accuracy: 0.8193\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4234 - accuracy: 0.8211\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4236 - accuracy: 0.8158\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4211 - accuracy: 0.8228\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4220 - accuracy: 0.8246\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4248 - accuracy: 0.8175\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 154us/step - loss: 0.4223 - accuracy: 0.8211\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4242 - accuracy: 0.8175\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4223 - accuracy: 0.8211\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 164us/step - loss: 0.4213 - accuracy: 0.8211\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4205 - accuracy: 0.8175\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 159us/step - loss: 0.4233 - accuracy: 0.8175\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4204 - accuracy: 0.8211\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4214 - accuracy: 0.8228\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4201 - accuracy: 0.8246\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4202 - accuracy: 0.8211\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 149us/step - loss: 0.4184 - accuracy: 0.8211\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 154us/step - loss: 0.4212 - accuracy: 0.8193\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 155us/step - loss: 0.4185 - accuracy: 0.8193\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4230 - accuracy: 0.8211\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4188 - accuracy: 0.8246\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 154us/step - loss: 0.4193 - accuracy: 0.8193\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4188 - accuracy: 0.8211\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4179 - accuracy: 0.8193\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4217 - accuracy: 0.8193\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4175 - accuracy: 0.8193\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 157us/step - loss: 0.4167 - accuracy: 0.8211\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4172 - accuracy: 0.8193\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4168 - accuracy: 0.8228\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4175 - accuracy: 0.8228\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4167 - accuracy: 0.8193\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4201 - accuracy: 0.8193\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4174 - accuracy: 0.8211\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4163 - accuracy: 0.8246\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4182 - accuracy: 0.8228\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4183 - accuracy: 0.8228\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4166 - accuracy: 0.8228\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4170 - accuracy: 0.8246\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4154 - accuracy: 0.8211\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4146 - accuracy: 0.8211\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4162 - accuracy: 0.8211\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4147 - accuracy: 0.8228\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 119us/step - loss: 0.4153 - accuracy: 0.8263\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 156us/step - loss: 0.4150 - accuracy: 0.8246\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4149 - accuracy: 0.8228\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4159 - accuracy: 0.8246\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4207 - accuracy: 0.8298\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4179 - accuracy: 0.8193\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4131 - accuracy: 0.8228\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4147 - accuracy: 0.8228\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4129 - accuracy: 0.8211\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4134 - accuracy: 0.8263\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4138 - accuracy: 0.8246\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4137 - accuracy: 0.8263\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 151us/step - loss: 0.4153 - accuracy: 0.8246\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4136 - accuracy: 0.8228\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4145 - accuracy: 0.8246\n",
      "142/142 [==============================] - 0s 91us/step\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 525us/step - loss: 0.6890 - accuracy: 0.5365 - val_loss: 0.6721 - val_accuracy: 0.5810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.6742 - accuracy: 0.5983 - val_loss: 0.6613 - val_accuracy: 0.6257\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6644 - accuracy: 0.6124 - val_loss: 0.6540 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6563 - accuracy: 0.6152 - val_loss: 0.6467 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6476 - accuracy: 0.6152 - val_loss: 0.6386 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.6373 - accuracy: 0.6222 - val_loss: 0.6288 - val_accuracy: 0.6257\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6257 - accuracy: 0.6292 - val_loss: 0.6150 - val_accuracy: 0.6313\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6110 - accuracy: 0.6376 - val_loss: 0.5991 - val_accuracy: 0.6201\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5937 - accuracy: 0.6770 - val_loss: 0.5802 - val_accuracy: 0.6760\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.5726 - accuracy: 0.7289 - val_loss: 0.5580 - val_accuracy: 0.7374\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5525 - accuracy: 0.7725 - val_loss: 0.5343 - val_accuracy: 0.7709\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.5326 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.5170 - accuracy: 0.7907 - val_loss: 0.4981 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5064 - accuracy: 0.7879 - val_loss: 0.4870 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4950 - accuracy: 0.7893 - val_loss: 0.4772 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4904 - accuracy: 0.7921 - val_loss: 0.4713 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4856 - accuracy: 0.7879 - val_loss: 0.4651 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4816 - accuracy: 0.7879 - val_loss: 0.4561 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4766 - accuracy: 0.7907 - val_loss: 0.4504 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4752 - accuracy: 0.7907 - val_loss: 0.4442 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4707 - accuracy: 0.7907 - val_loss: 0.4421 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4713 - accuracy: 0.7935 - val_loss: 0.4360 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4663 - accuracy: 0.7921 - val_loss: 0.4338 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4674 - accuracy: 0.7935 - val_loss: 0.4323 - val_accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4633 - accuracy: 0.7935 - val_loss: 0.4305 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4621 - accuracy: 0.7935 - val_loss: 0.4290 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4637 - accuracy: 0.7921 - val_loss: 0.4262 - val_accuracy: 0.7989\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4601 - accuracy: 0.7949 - val_loss: 0.4258 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4578 - accuracy: 0.7949 - val_loss: 0.4225 - val_accuracy: 0.8045\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4591 - accuracy: 0.7907 - val_loss: 0.4201 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4569 - accuracy: 0.7921 - val_loss: 0.4213 - val_accuracy: 0.8045\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4553 - accuracy: 0.7949 - val_loss: 0.4200 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4576 - accuracy: 0.7963 - val_loss: 0.4185 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4596 - accuracy: 0.7963 - val_loss: 0.4192 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4547 - accuracy: 0.7978 - val_loss: 0.4177 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4545 - accuracy: 0.7907 - val_loss: 0.4189 - val_accuracy: 0.8045\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4519 - accuracy: 0.7935 - val_loss: 0.4167 - val_accuracy: 0.8045\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4530 - accuracy: 0.7893 - val_loss: 0.4163 - val_accuracy: 0.8045\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4547 - accuracy: 0.7935 - val_loss: 0.4167 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4509 - accuracy: 0.7893 - val_loss: 0.4167 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4480 - accuracy: 0.7963 - val_loss: 0.4159 - val_accuracy: 0.8045\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4482 - accuracy: 0.7935 - val_loss: 0.4142 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4487 - accuracy: 0.7963 - val_loss: 0.4135 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4480 - accuracy: 0.7949 - val_loss: 0.4146 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4466 - accuracy: 0.7949 - val_loss: 0.4123 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4466 - accuracy: 0.7935 - val_loss: 0.4141 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4472 - accuracy: 0.7935 - val_loss: 0.4129 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4460 - accuracy: 0.7935 - val_loss: 0.4120 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4443 - accuracy: 0.7921 - val_loss: 0.4123 - val_accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4448 - accuracy: 0.7992 - val_loss: 0.4098 - val_accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4445 - accuracy: 0.7992 - val_loss: 0.4115 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4464 - accuracy: 0.7963 - val_loss: 0.4112 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4442 - accuracy: 0.7978 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4427 - accuracy: 0.7963 - val_loss: 0.4099 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4418 - accuracy: 0.7992 - val_loss: 0.4116 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4419 - accuracy: 0.7949 - val_loss: 0.4098 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4408 - accuracy: 0.8006 - val_loss: 0.4114 - val_accuracy: 0.7933\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 79us/step - loss: 0.4428 - accuracy: 0.7949 - val_loss: 0.4105 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4422 - accuracy: 0.8076 - val_loss: 0.4086 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4429 - accuracy: 0.7949 - val_loss: 0.4105 - val_accuracy: 0.8156\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4408 - accuracy: 0.8048 - val_loss: 0.4083 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4393 - accuracy: 0.7992 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4391 - accuracy: 0.8020 - val_loss: 0.4102 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4433 - accuracy: 0.7963 - val_loss: 0.4090 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4392 - accuracy: 0.7992 - val_loss: 0.4085 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4374 - accuracy: 0.7978 - val_loss: 0.4081 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4363 - accuracy: 0.7978 - val_loss: 0.4063 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4377 - accuracy: 0.7978 - val_loss: 0.4084 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4360 - accuracy: 0.8020 - val_loss: 0.4082 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4375 - accuracy: 0.7978 - val_loss: 0.4065 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4388 - accuracy: 0.8062 - val_loss: 0.4060 - val_accuracy: 0.7989\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4386 - accuracy: 0.8020 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4335 - accuracy: 0.7963 - val_loss: 0.4085 - val_accuracy: 0.7933\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4380 - accuracy: 0.8034 - val_loss: 0.4069 - val_accuracy: 0.7989\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4342 - accuracy: 0.8034 - val_loss: 0.4056 - val_accuracy: 0.7933\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4352 - accuracy: 0.7992 - val_loss: 0.4061 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4361 - accuracy: 0.8006 - val_loss: 0.4070 - val_accuracy: 0.7933\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4340 - accuracy: 0.8034 - val_loss: 0.4068 - val_accuracy: 0.7933\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4323 - accuracy: 0.8034 - val_loss: 0.4063 - val_accuracy: 0.7933\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4333 - accuracy: 0.7992 - val_loss: 0.4032 - val_accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4320 - accuracy: 0.7992 - val_loss: 0.4033 - val_accuracy: 0.7933\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4318 - accuracy: 0.7963 - val_loss: 0.4043 - val_accuracy: 0.7989\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4313 - accuracy: 0.8076 - val_loss: 0.4022 - val_accuracy: 0.7933\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4312 - accuracy: 0.8048 - val_loss: 0.3988 - val_accuracy: 0.7933\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4303 - accuracy: 0.8034 - val_loss: 0.3993 - val_accuracy: 0.7933\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4290 - accuracy: 0.8076 - val_loss: 0.4004 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4310 - accuracy: 0.8020 - val_loss: 0.3997 - val_accuracy: 0.7933\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4297 - accuracy: 0.8104 - val_loss: 0.4038 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4278 - accuracy: 0.8104 - val_loss: 0.4001 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4300 - accuracy: 0.8076 - val_loss: 0.3987 - val_accuracy: 0.7989\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4291 - accuracy: 0.8076 - val_loss: 0.4006 - val_accuracy: 0.7989\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4299 - accuracy: 0.8104 - val_loss: 0.3982 - val_accuracy: 0.7989\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4290 - accuracy: 0.8076 - val_loss: 0.3981 - val_accuracy: 0.7989\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4318 - accuracy: 0.8146 - val_loss: 0.4017 - val_accuracy: 0.7989\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4274 - accuracy: 0.8090 - val_loss: 0.4021 - val_accuracy: 0.7989\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4284 - accuracy: 0.8090 - val_loss: 0.3992 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4296 - accuracy: 0.8062 - val_loss: 0.3996 - val_accuracy: 0.8045\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4291 - accuracy: 0.8146 - val_loss: 0.4024 - val_accuracy: 0.8045\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4278 - accuracy: 0.8118 - val_loss: 0.3979 - val_accuracy: 0.7989\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4262 - accuracy: 0.8090 - val_loss: 0.3975 - val_accuracy: 0.8045\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.4330 - accuracy: 0.8123\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4321 - accuracy: 0.8140\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4279 - accuracy: 0.8175\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4296 - accuracy: 0.8123\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4261 - accuracy: 0.8193\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4291 - accuracy: 0.8140\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4279 - accuracy: 0.8140\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4281 - accuracy: 0.8158\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4279 - accuracy: 0.8211\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4243 - accuracy: 0.8158\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4245 - accuracy: 0.8140\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4266 - accuracy: 0.8158\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4277 - accuracy: 0.8140\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4266 - accuracy: 0.8211\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 115us/step - loss: 0.4239 - accuracy: 0.8193\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4213 - accuracy: 0.8228\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4233 - accuracy: 0.8123\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4232 - accuracy: 0.8246\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4202 - accuracy: 0.8158\n",
      "Epoch 20/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 125us/step - loss: 0.4238 - accuracy: 0.8158\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4191 - accuracy: 0.8246\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4186 - accuracy: 0.8228\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4246 - accuracy: 0.8246\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4205 - accuracy: 0.8246\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4192 - accuracy: 0.8298\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4221 - accuracy: 0.8211\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4214 - accuracy: 0.8228\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4209 - accuracy: 0.8263\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4206 - accuracy: 0.8246\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4179 - accuracy: 0.8281\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4169 - accuracy: 0.8316\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4191 - accuracy: 0.8193\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4205 - accuracy: 0.8298\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4188 - accuracy: 0.8211\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 141us/step - loss: 0.4172 - accuracy: 0.8263\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4208 - accuracy: 0.8263\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 158us/step - loss: 0.4164 - accuracy: 0.8228\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4175 - accuracy: 0.8246\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4175 - accuracy: 0.8246\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 143us/step - loss: 0.4161 - accuracy: 0.8281\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4146 - accuracy: 0.8333\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.4142 - accuracy: 0.8298\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4132 - accuracy: 0.8333\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4176 - accuracy: 0.8298\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4137 - accuracy: 0.8298\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4227 - accuracy: 0.8175\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4157 - accuracy: 0.8351\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 210us/step - loss: 0.4135 - accuracy: 0.8281\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 172us/step - loss: 0.4130 - accuracy: 0.8333\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 166us/step - loss: 0.4134 - accuracy: 0.8263\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 204us/step - loss: 0.4123 - accuracy: 0.8351\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 207us/step - loss: 0.4121 - accuracy: 0.8281\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 159us/step - loss: 0.4131 - accuracy: 0.8316\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 150us/step - loss: 0.4153 - accuracy: 0.8298\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 173us/step - loss: 0.4138 - accuracy: 0.8316\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 182us/step - loss: 0.4108 - accuracy: 0.8333\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 168us/step - loss: 0.4117 - accuracy: 0.8281\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 198us/step - loss: 0.4120 - accuracy: 0.8386\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 191us/step - loss: 0.4124 - accuracy: 0.8333\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 187us/step - loss: 0.4158 - accuracy: 0.8298\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 180us/step - loss: 0.4155 - accuracy: 0.8298\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 169us/step - loss: 0.4118 - accuracy: 0.8281\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 157us/step - loss: 0.4115 - accuracy: 0.8404\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4152 - accuracy: 0.8263\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4105 - accuracy: 0.8281\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 152us/step - loss: 0.4136 - accuracy: 0.8333\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.4119 - accuracy: 0.8281\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 155us/step - loss: 0.4100 - accuracy: 0.8368\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 144us/step - loss: 0.4087 - accuracy: 0.8281\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 159us/step - loss: 0.4099 - accuracy: 0.8368\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 156us/step - loss: 0.4102 - accuracy: 0.8333\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 139us/step - loss: 0.4088 - accuracy: 0.8333\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4090 - accuracy: 0.8316\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4114 - accuracy: 0.8386\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4115 - accuracy: 0.8316\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 137us/step - loss: 0.4078 - accuracy: 0.8368\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4066 - accuracy: 0.8351\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4096 - accuracy: 0.8298\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 138us/step - loss: 0.4084 - accuracy: 0.8316\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4071 - accuracy: 0.8298\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4088 - accuracy: 0.8281\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.4082 - accuracy: 0.8333\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4047 - accuracy: 0.8333\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4097 - accuracy: 0.8351\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4054 - accuracy: 0.8368\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4053 - accuracy: 0.8421\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 132us/step - loss: 0.4061 - accuracy: 0.8333\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4064 - accuracy: 0.8333\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4041 - accuracy: 0.8298\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4085 - accuracy: 0.8351\n",
      "142/142 [==============================] - 0s 69us/step\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 500us/step - loss: 0.6619 - accuracy: 0.6166 - val_loss: 0.6503 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.6481 - accuracy: 0.6166 - val_loss: 0.6370 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6361 - accuracy: 0.6166 - val_loss: 0.6234 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6248 - accuracy: 0.6166 - val_loss: 0.6103 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6114 - accuracy: 0.6166 - val_loss: 0.5981 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6016 - accuracy: 0.6166 - val_loss: 0.5866 - val_accuracy: 0.6145\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5905 - accuracy: 0.6278 - val_loss: 0.5758 - val_accuracy: 0.6816\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5798 - accuracy: 0.6629 - val_loss: 0.5620 - val_accuracy: 0.7151\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5680 - accuracy: 0.7037 - val_loss: 0.5510 - val_accuracy: 0.7207\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.5571 - accuracy: 0.7317 - val_loss: 0.5400 - val_accuracy: 0.7542\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5466 - accuracy: 0.7598 - val_loss: 0.5308 - val_accuracy: 0.7542\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5368 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7542\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5294 - accuracy: 0.7823 - val_loss: 0.5117 - val_accuracy: 0.7654\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5212 - accuracy: 0.7921 - val_loss: 0.5037 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5152 - accuracy: 0.7865 - val_loss: 0.4970 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5089 - accuracy: 0.7949 - val_loss: 0.4923 - val_accuracy: 0.7654\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5045 - accuracy: 0.7879 - val_loss: 0.4870 - val_accuracy: 0.7654\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4990 - accuracy: 0.7907 - val_loss: 0.4830 - val_accuracy: 0.7654\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4948 - accuracy: 0.7893 - val_loss: 0.4773 - val_accuracy: 0.7709\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4911 - accuracy: 0.7963 - val_loss: 0.4754 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4870 - accuracy: 0.7921 - val_loss: 0.4715 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4842 - accuracy: 0.7893 - val_loss: 0.4669 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4825 - accuracy: 0.7949 - val_loss: 0.4650 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4795 - accuracy: 0.7949 - val_loss: 0.4624 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4768 - accuracy: 0.7921 - val_loss: 0.4604 - val_accuracy: 0.7765\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4751 - accuracy: 0.8006 - val_loss: 0.4591 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4722 - accuracy: 0.7992 - val_loss: 0.4593 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4725 - accuracy: 0.7963 - val_loss: 0.4562 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4704 - accuracy: 0.8006 - val_loss: 0.4551 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4692 - accuracy: 0.7992 - val_loss: 0.4557 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4685 - accuracy: 0.7949 - val_loss: 0.4518 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4667 - accuracy: 0.7992 - val_loss: 0.4504 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4671 - accuracy: 0.8006 - val_loss: 0.4511 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4687 - accuracy: 0.7963 - val_loss: 0.4498 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4640 - accuracy: 0.7992 - val_loss: 0.4497 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4638 - accuracy: 0.7963 - val_loss: 0.4462 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4606 - accuracy: 0.8006 - val_loss: 0.4435 - val_accuracy: 0.7989\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4597 - accuracy: 0.8006 - val_loss: 0.4454 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4592 - accuracy: 0.8020 - val_loss: 0.4439 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4594 - accuracy: 0.7978 - val_loss: 0.4435 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4576 - accuracy: 0.8020 - val_loss: 0.4391 - val_accuracy: 0.8101\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4566 - accuracy: 0.8020 - val_loss: 0.4409 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4599 - accuracy: 0.8076 - val_loss: 0.4401 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4573 - accuracy: 0.8090 - val_loss: 0.4397 - val_accuracy: 0.8101\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4555 - accuracy: 0.8062 - val_loss: 0.4391 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4532 - accuracy: 0.8048 - val_loss: 0.4362 - val_accuracy: 0.8101\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4535 - accuracy: 0.8034 - val_loss: 0.4381 - val_accuracy: 0.8101\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4526 - accuracy: 0.8076 - val_loss: 0.4366 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4519 - accuracy: 0.8076 - val_loss: 0.4375 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4545 - accuracy: 0.8062 - val_loss: 0.4373 - val_accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4514 - accuracy: 0.8118 - val_loss: 0.4350 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4504 - accuracy: 0.8090 - val_loss: 0.4358 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4504 - accuracy: 0.8132 - val_loss: 0.4348 - val_accuracy: 0.8101\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4491 - accuracy: 0.8104 - val_loss: 0.4345 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4486 - accuracy: 0.8118 - val_loss: 0.4327 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4480 - accuracy: 0.8146 - val_loss: 0.4330 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 74us/step - loss: 0.4499 - accuracy: 0.8118 - val_loss: 0.4316 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4485 - accuracy: 0.8132 - val_loss: 0.4307 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4471 - accuracy: 0.8146 - val_loss: 0.4304 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4481 - accuracy: 0.8174 - val_loss: 0.4340 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4470 - accuracy: 0.8174 - val_loss: 0.4297 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4458 - accuracy: 0.8160 - val_loss: 0.4283 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4444 - accuracy: 0.8216 - val_loss: 0.4302 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4476 - accuracy: 0.8146 - val_loss: 0.4305 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4460 - accuracy: 0.8188 - val_loss: 0.4283 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4453 - accuracy: 0.8202 - val_loss: 0.4270 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4434 - accuracy: 0.8202 - val_loss: 0.4280 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4437 - accuracy: 0.8230 - val_loss: 0.4259 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4437 - accuracy: 0.8216 - val_loss: 0.4228 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4429 - accuracy: 0.8188 - val_loss: 0.4244 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4428 - accuracy: 0.8216 - val_loss: 0.4264 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4413 - accuracy: 0.8216 - val_loss: 0.4264 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4421 - accuracy: 0.8230 - val_loss: 0.4252 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4415 - accuracy: 0.8244 - val_loss: 0.4254 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4437 - accuracy: 0.8230 - val_loss: 0.4265 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4406 - accuracy: 0.8216 - val_loss: 0.4276 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4409 - accuracy: 0.8244 - val_loss: 0.4255 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4403 - accuracy: 0.8244 - val_loss: 0.4267 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4393 - accuracy: 0.8230 - val_loss: 0.4253 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4395 - accuracy: 0.8230 - val_loss: 0.4271 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4390 - accuracy: 0.8216 - val_loss: 0.4244 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4382 - accuracy: 0.8244 - val_loss: 0.4267 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4374 - accuracy: 0.8202 - val_loss: 0.4233 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4381 - accuracy: 0.8258 - val_loss: 0.4266 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4380 - accuracy: 0.8230 - val_loss: 0.4242 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4383 - accuracy: 0.8244 - val_loss: 0.4211 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4363 - accuracy: 0.8244 - val_loss: 0.4235 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4343 - accuracy: 0.8258 - val_loss: 0.4229 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.75 - 0s 64us/step - loss: 0.4391 - accuracy: 0.8258 - val_loss: 0.4247 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4356 - accuracy: 0.8258 - val_loss: 0.4255 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4351 - accuracy: 0.8287 - val_loss: 0.4250 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4345 - accuracy: 0.8258 - val_loss: 0.4231 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4338 - accuracy: 0.8287 - val_loss: 0.4234 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4352 - accuracy: 0.8258 - val_loss: 0.4205 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4341 - accuracy: 0.8244 - val_loss: 0.4202 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4326 - accuracy: 0.8287 - val_loss: 0.4287 - val_accuracy: 0.7989\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4419 - accuracy: 0.8188 - val_loss: 0.4218 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4317 - accuracy: 0.8272 - val_loss: 0.4226 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4321 - accuracy: 0.8287 - val_loss: 0.4217 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4318 - accuracy: 0.8244 - val_loss: 0.4184 - val_accuracy: 0.8101\n",
      "Epoch 1/30\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4111 - accuracy: 0.8348\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.4143 - accuracy: 0.8295\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4073 - accuracy: 0.8348\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4068 - accuracy: 0.8348\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4061 - accuracy: 0.8295\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4066 - accuracy: 0.8313\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4097 - accuracy: 0.8313\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4043 - accuracy: 0.8313\n",
      "Epoch 9/30\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4051 - accuracy: 0.8366\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4063 - accuracy: 0.8295\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4029 - accuracy: 0.8295\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4035 - accuracy: 0.8348\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4040 - accuracy: 0.8295\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4021 - accuracy: 0.8295\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4057 - accuracy: 0.8295\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4031 - accuracy: 0.8313\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4005 - accuracy: 0.8295\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 58us/step - loss: 0.4006 - accuracy: 0.8330\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4017 - accuracy: 0.8278\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4012 - accuracy: 0.8313\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.3984 - accuracy: 0.8295\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.3988 - accuracy: 0.8295\n",
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.3978 - accuracy: 0.8295\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.3984 - accuracy: 0.8313\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.3994 - accuracy: 0.8295\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.3977 - accuracy: 0.8295\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.3973 - accuracy: 0.8313\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.3966 - accuracy: 0.8330\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 74us/step - loss: 0.3957 - accuracy: 0.8295\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.3958 - accuracy: 0.8313\n",
      "143/143 [==============================] - 0s 59us/step\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 499us/step - loss: 0.6867 - accuracy: 0.6166 - val_loss: 0.6777 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.6605 - accuracy: 0.6166 - val_loss: 0.6587 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6438 - accuracy: 0.6166 - val_loss: 0.6405 - val_accuracy: 0.6257\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6251 - accuracy: 0.6348 - val_loss: 0.6197 - val_accuracy: 0.6480\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6067 - accuracy: 0.6489 - val_loss: 0.5967 - val_accuracy: 0.6425\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5851 - accuracy: 0.6966 - val_loss: 0.5687 - val_accuracy: 0.7486\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5631 - accuracy: 0.7669 - val_loss: 0.5404 - val_accuracy: 0.7486\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5414 - accuracy: 0.7626 - val_loss: 0.5170 - val_accuracy: 0.7709\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5239 - accuracy: 0.7921 - val_loss: 0.4962 - val_accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5076 - accuracy: 0.7921 - val_loss: 0.4771 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4964 - accuracy: 0.7978 - val_loss: 0.4641 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4886 - accuracy: 0.8020 - val_loss: 0.4545 - val_accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4845 - accuracy: 0.7935 - val_loss: 0.4505 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4778 - accuracy: 0.8020 - val_loss: 0.4410 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4773 - accuracy: 0.7935 - val_loss: 0.4384 - val_accuracy: 0.7989\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4715 - accuracy: 0.7978 - val_loss: 0.4356 - val_accuracy: 0.7989\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4678 - accuracy: 0.7992 - val_loss: 0.4327 - val_accuracy: 0.7989\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4665 - accuracy: 0.7992 - val_loss: 0.4287 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4635 - accuracy: 0.8020 - val_loss: 0.4277 - val_accuracy: 0.7989\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4598 - accuracy: 0.7978 - val_loss: 0.4244 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4278 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4583 - accuracy: 0.8006 - val_loss: 0.4217 - val_accuracy: 0.7989\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4560 - accuracy: 0.8034 - val_loss: 0.4183 - val_accuracy: 0.7989\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4612 - accuracy: 0.7978 - val_loss: 0.4188 - val_accuracy: 0.8101\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4528 - accuracy: 0.8062 - val_loss: 0.4176 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4550 - accuracy: 0.8090 - val_loss: 0.4217 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4507 - accuracy: 0.8048 - val_loss: 0.4154 - val_accuracy: 0.8045\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4493 - accuracy: 0.8090 - val_loss: 0.4145 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4478 - accuracy: 0.8020 - val_loss: 0.4111 - val_accuracy: 0.8156\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4497 - accuracy: 0.8048 - val_loss: 0.4146 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4480 - accuracy: 0.8034 - val_loss: 0.4099 - val_accuracy: 0.8156\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4481 - accuracy: 0.8062 - val_loss: 0.4100 - val_accuracy: 0.8212\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4512 - accuracy: 0.8118 - val_loss: 0.4195 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4446 - accuracy: 0.8090 - val_loss: 0.4087 - val_accuracy: 0.8212\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4425 - accuracy: 0.8090 - val_loss: 0.4072 - val_accuracy: 0.8212\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4420 - accuracy: 0.8076 - val_loss: 0.4082 - val_accuracy: 0.8101\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4437 - accuracy: 0.8076 - val_loss: 0.4044 - val_accuracy: 0.8212\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4428 - accuracy: 0.8104 - val_loss: 0.4087 - val_accuracy: 0.8101\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4429 - accuracy: 0.8076 - val_loss: 0.4075 - val_accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4396 - accuracy: 0.8090 - val_loss: 0.4040 - val_accuracy: 0.8212\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 96us/step - loss: 0.4394 - accuracy: 0.8104 - val_loss: 0.4065 - val_accuracy: 0.8101\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4412 - accuracy: 0.8076 - val_loss: 0.4024 - val_accuracy: 0.8212\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4412 - accuracy: 0.8118 - val_loss: 0.4060 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4376 - accuracy: 0.8090 - val_loss: 0.4023 - val_accuracy: 0.8212\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4400 - accuracy: 0.8104 - val_loss: 0.4024 - val_accuracy: 0.8212\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4375 - accuracy: 0.8160 - val_loss: 0.4023 - val_accuracy: 0.8156\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4403 - accuracy: 0.8090 - val_loss: 0.4018 - val_accuracy: 0.8212\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4366 - accuracy: 0.8090 - val_loss: 0.4003 - val_accuracy: 0.8212\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4347 - accuracy: 0.8174 - val_loss: 0.4014 - val_accuracy: 0.8212\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4361 - accuracy: 0.8104 - val_loss: 0.4012 - val_accuracy: 0.8156\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4369 - accuracy: 0.8076 - val_loss: 0.4010 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4384 - accuracy: 0.8174 - val_loss: 0.4036 - val_accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4342 - accuracy: 0.8118 - val_loss: 0.3990 - val_accuracy: 0.8156\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4340 - accuracy: 0.8132 - val_loss: 0.3990 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4332 - accuracy: 0.8146 - val_loss: 0.3995 - val_accuracy: 0.8156\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4358 - accuracy: 0.8146 - val_loss: 0.3983 - val_accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4353 - accuracy: 0.8188 - val_loss: 0.3987 - val_accuracy: 0.8156\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4337 - accuracy: 0.8132 - val_loss: 0.3965 - val_accuracy: 0.8156\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4324 - accuracy: 0.8174 - val_loss: 0.3976 - val_accuracy: 0.8156\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4329 - accuracy: 0.8118 - val_loss: 0.3994 - val_accuracy: 0.8156\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4326 - accuracy: 0.8132 - val_loss: 0.3991 - val_accuracy: 0.8156\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4315 - accuracy: 0.8160 - val_loss: 0.3997 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4342 - accuracy: 0.8146 - val_loss: 0.4000 - val_accuracy: 0.8156\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4330 - accuracy: 0.8216 - val_loss: 0.3992 - val_accuracy: 0.8156\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4335 - accuracy: 0.8188 - val_loss: 0.3983 - val_accuracy: 0.8212\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4309 - accuracy: 0.8160 - val_loss: 0.3997 - val_accuracy: 0.8156\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4336 - accuracy: 0.8146 - val_loss: 0.4001 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4318 - accuracy: 0.8244 - val_loss: 0.4004 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4301 - accuracy: 0.8160 - val_loss: 0.3990 - val_accuracy: 0.8156\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4317 - accuracy: 0.8090 - val_loss: 0.3948 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4335 - accuracy: 0.8160 - val_loss: 0.3956 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4284 - accuracy: 0.8188 - val_loss: 0.3964 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4300 - accuracy: 0.8160 - val_loss: 0.3958 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4294 - accuracy: 0.8160 - val_loss: 0.3942 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4289 - accuracy: 0.8188 - val_loss: 0.3950 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4292 - accuracy: 0.8160 - val_loss: 0.3954 - val_accuracy: 0.8156\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4290 - accuracy: 0.8216 - val_loss: 0.3968 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4299 - accuracy: 0.8146 - val_loss: 0.3949 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4288 - accuracy: 0.8216 - val_loss: 0.3993 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4295 - accuracy: 0.8188 - val_loss: 0.3932 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4281 - accuracy: 0.8160 - val_loss: 0.3933 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4279 - accuracy: 0.8174 - val_loss: 0.3958 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4326 - accuracy: 0.8188 - val_loss: 0.3939 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4264 - accuracy: 0.8202 - val_loss: 0.3945 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4271 - accuracy: 0.8216 - val_loss: 0.3949 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4274 - accuracy: 0.8188 - val_loss: 0.3940 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4281 - accuracy: 0.8202 - val_loss: 0.3969 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4292 - accuracy: 0.8188 - val_loss: 0.3934 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4267 - accuracy: 0.8174 - val_loss: 0.3933 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4283 - accuracy: 0.8160 - val_loss: 0.3952 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4281 - accuracy: 0.8216 - val_loss: 0.3939 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4264 - accuracy: 0.8174 - val_loss: 0.3926 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4251 - accuracy: 0.8160 - val_loss: 0.3921 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4254 - accuracy: 0.8174 - val_loss: 0.3925 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4257 - accuracy: 0.8174 - val_loss: 0.3929 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4252 - accuracy: 0.8202 - val_loss: 0.3921 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 80us/step - loss: 0.4266 - accuracy: 0.8188 - val_loss: 0.3928 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4259 - accuracy: 0.8216 - val_loss: 0.3911 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4282 - accuracy: 0.8146 - val_loss: 0.3927 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4283 - accuracy: 0.8216 - val_loss: 0.3949 - val_accuracy: 0.8212\n",
      "Epoch 1/30\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.4319 - accuracy: 0.8190\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4318 - accuracy: 0.8120\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 74us/step - loss: 0.4295 - accuracy: 0.8155\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4322 - accuracy: 0.8207\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4307 - accuracy: 0.8155\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4296 - accuracy: 0.8190\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.4299 - accuracy: 0.8155\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4308 - accuracy: 0.8190\n",
      "Epoch 9/30\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4276 - accuracy: 0.8190\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4322 - accuracy: 0.8137\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4311 - accuracy: 0.8137\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4282 - accuracy: 0.8172\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.4291 - accuracy: 0.8190\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4299 - accuracy: 0.8102\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.4271 - accuracy: 0.8172\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4287 - accuracy: 0.8102\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4266 - accuracy: 0.8155\n",
      "Epoch 18/30\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.4283 - accuracy: 0.8155\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4286 - accuracy: 0.8190\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4270 - accuracy: 0.8172\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.4264 - accuracy: 0.8190\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4267 - accuracy: 0.8172\n",
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4266 - accuracy: 0.8190\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4277 - accuracy: 0.8155\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4259 - accuracy: 0.8172\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4262 - accuracy: 0.8120\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4289 - accuracy: 0.8172\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4277 - accuracy: 0.8120\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4246 - accuracy: 0.8190\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4259 - accuracy: 0.8155\n",
      "143/143 [==============================] - 0s 63us/step\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 541us/step - loss: 0.7332 - accuracy: 0.3525 - val_loss: 0.7285 - val_accuracy: 0.3799\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6970 - accuracy: 0.5478 - val_loss: 0.6840 - val_accuracy: 0.6313\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6587 - accuracy: 0.6292 - val_loss: 0.6338 - val_accuracy: 0.6480\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6224 - accuracy: 0.6362 - val_loss: 0.5897 - val_accuracy: 0.6816\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5966 - accuracy: 0.6587 - val_loss: 0.5604 - val_accuracy: 0.7318\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5773 - accuracy: 0.6952 - val_loss: 0.5390 - val_accuracy: 0.7318\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.65 - 0s 72us/step - loss: 0.5608 - accuracy: 0.7163 - val_loss: 0.5216 - val_accuracy: 0.7430\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.5493 - accuracy: 0.7402 - val_loss: 0.5064 - val_accuracy: 0.7374\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5368 - accuracy: 0.7388 - val_loss: 0.4890 - val_accuracy: 0.7207\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5208 - accuracy: 0.7570 - val_loss: 0.4778 - val_accuracy: 0.7263\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.5105 - accuracy: 0.7584 - val_loss: 0.4637 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4993 - accuracy: 0.7809 - val_loss: 0.4590 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4909 - accuracy: 0.7781 - val_loss: 0.4515 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4831 - accuracy: 0.7949 - val_loss: 0.4452 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4786 - accuracy: 0.7992 - val_loss: 0.4413 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4789 - accuracy: 0.7879 - val_loss: 0.4396 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4753 - accuracy: 0.7992 - val_loss: 0.4391 - val_accuracy: 0.8045\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4735 - accuracy: 0.7851 - val_loss: 0.4361 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.4322 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4659 - accuracy: 0.7837 - val_loss: 0.4319 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4638 - accuracy: 0.7992 - val_loss: 0.4295 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4656 - accuracy: 0.7893 - val_loss: 0.4299 - val_accuracy: 0.7989\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4613 - accuracy: 0.7963 - val_loss: 0.4352 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4643 - accuracy: 0.7879 - val_loss: 0.4260 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 87us/step - loss: 0.4597 - accuracy: 0.7893 - val_loss: 0.4242 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4599 - accuracy: 0.7921 - val_loss: 0.4231 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4571 - accuracy: 0.7935 - val_loss: 0.4239 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4586 - accuracy: 0.7963 - val_loss: 0.4242 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4575 - accuracy: 0.7921 - val_loss: 0.4224 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4549 - accuracy: 0.7949 - val_loss: 0.4208 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4535 - accuracy: 0.7949 - val_loss: 0.4237 - val_accuracy: 0.7821\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4522 - accuracy: 0.7963 - val_loss: 0.4188 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4515 - accuracy: 0.7992 - val_loss: 0.4207 - val_accuracy: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4557 - accuracy: 0.8020 - val_loss: 0.4252 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4509 - accuracy: 0.7992 - val_loss: 0.4180 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4490 - accuracy: 0.8034 - val_loss: 0.4206 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4495 - accuracy: 0.8048 - val_loss: 0.4210 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4510 - accuracy: 0.7978 - val_loss: 0.4159 - val_accuracy: 0.7877\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4473 - accuracy: 0.8048 - val_loss: 0.4181 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4480 - accuracy: 0.7992 - val_loss: 0.4142 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4506 - accuracy: 0.8020 - val_loss: 0.4170 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4469 - accuracy: 0.8062 - val_loss: 0.4153 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4459 - accuracy: 0.8062 - val_loss: 0.4134 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4445 - accuracy: 0.8034 - val_loss: 0.4110 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4450 - accuracy: 0.8034 - val_loss: 0.4110 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4436 - accuracy: 0.8020 - val_loss: 0.4119 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4433 - accuracy: 0.8062 - val_loss: 0.4135 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4447 - accuracy: 0.8048 - val_loss: 0.4147 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4438 - accuracy: 0.8062 - val_loss: 0.4097 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4425 - accuracy: 0.8062 - val_loss: 0.4107 - val_accuracy: 0.7877\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4464 - accuracy: 0.8048 - val_loss: 0.4086 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4405 - accuracy: 0.8062 - val_loss: 0.4068 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4396 - accuracy: 0.8062 - val_loss: 0.4082 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4410 - accuracy: 0.8048 - val_loss: 0.4077 - val_accuracy: 0.7877\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4411 - accuracy: 0.8076 - val_loss: 0.4065 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4391 - accuracy: 0.8076 - val_loss: 0.4079 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4455 - accuracy: 0.8076 - val_loss: 0.4063 - val_accuracy: 0.7877\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4381 - accuracy: 0.8048 - val_loss: 0.4058 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4387 - accuracy: 0.8076 - val_loss: 0.4067 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4384 - accuracy: 0.8062 - val_loss: 0.4056 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4396 - accuracy: 0.8062 - val_loss: 0.4093 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4364 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4370 - accuracy: 0.8062 - val_loss: 0.4057 - val_accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4374 - accuracy: 0.8104 - val_loss: 0.4056 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4359 - accuracy: 0.8076 - val_loss: 0.4054 - val_accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4400 - accuracy: 0.8146 - val_loss: 0.4098 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4353 - accuracy: 0.8090 - val_loss: 0.4024 - val_accuracy: 0.7933\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4350 - accuracy: 0.8118 - val_loss: 0.4058 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4343 - accuracy: 0.8118 - val_loss: 0.4023 - val_accuracy: 0.7933\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4377 - accuracy: 0.8062 - val_loss: 0.4064 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4345 - accuracy: 0.8160 - val_loss: 0.4027 - val_accuracy: 0.7933\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4327 - accuracy: 0.8090 - val_loss: 0.4043 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4348 - accuracy: 0.8160 - val_loss: 0.4072 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4339 - accuracy: 0.8118 - val_loss: 0.4035 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4330 - accuracy: 0.8146 - val_loss: 0.4054 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4342 - accuracy: 0.8202 - val_loss: 0.4030 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4349 - accuracy: 0.8076 - val_loss: 0.4009 - val_accuracy: 0.7933\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4353 - accuracy: 0.8132 - val_loss: 0.4032 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4323 - accuracy: 0.8118 - val_loss: 0.4040 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4325 - accuracy: 0.8118 - val_loss: 0.4009 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 79us/step - loss: 0.4362 - accuracy: 0.8076 - val_loss: 0.4062 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.87 - 0s 82us/step - loss: 0.4377 - accuracy: 0.8146 - val_loss: 0.4021 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4350 - accuracy: 0.8160 - val_loss: 0.3982 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4334 - accuracy: 0.8104 - val_loss: 0.4036 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4339 - accuracy: 0.8118 - val_loss: 0.3998 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4313 - accuracy: 0.8090 - val_loss: 0.4023 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4353 - accuracy: 0.8160 - val_loss: 0.4051 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4366 - accuracy: 0.8118 - val_loss: 0.4003 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4335 - accuracy: 0.8104 - val_loss: 0.4021 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4309 - accuracy: 0.8104 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4315 - accuracy: 0.8174 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4307 - accuracy: 0.8062 - val_loss: 0.3985 - val_accuracy: 0.8212\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4353 - accuracy: 0.8090 - val_loss: 0.4088 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4356 - accuracy: 0.8202 - val_loss: 0.4014 - val_accuracy: 0.7989\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4347 - accuracy: 0.8090 - val_loss: 0.3989 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4305 - accuracy: 0.8118 - val_loss: 0.3998 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4299 - accuracy: 0.8076 - val_loss: 0.3977 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4321 - accuracy: 0.8132 - val_loss: 0.4000 - val_accuracy: 0.8045\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4290 - accuracy: 0.8090 - val_loss: 0.4058 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4295 - accuracy: 0.8202 - val_loss: 0.4011 - val_accuracy: 0.8101\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4319 - accuracy: 0.8070\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4308 - accuracy: 0.8070\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4308 - accuracy: 0.8070\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4300 - accuracy: 0.8053\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4287 - accuracy: 0.8035\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4291 - accuracy: 0.8105\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4276 - accuracy: 0.8053\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4292 - accuracy: 0.8070\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4301 - accuracy: 0.7982\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4271 - accuracy: 0.8035\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4267 - accuracy: 0.8035\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4260 - accuracy: 0.8053\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4266 - accuracy: 0.8035\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4257 - accuracy: 0.8035\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4276 - accuracy: 0.8035\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4266 - accuracy: 0.8105\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4256 - accuracy: 0.8018\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4277 - accuracy: 0.8158\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4251 - accuracy: 0.8070\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4247 - accuracy: 0.8035\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4261 - accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4251 - accuracy: 0.8105\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4264 - accuracy: 0.8018\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4244 - accuracy: 0.8175\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4247 - accuracy: 0.8035\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4257 - accuracy: 0.8070\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4244 - accuracy: 0.8035\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4222 - accuracy: 0.8035\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4230 - accuracy: 0.8175\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4241 - accuracy: 0.8070\n",
      "142/142 [==============================] - 0s 78us/step\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 577us/step - loss: 0.6648 - accuracy: 0.6250 - val_loss: 0.6164 - val_accuracy: 0.7039\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6310 - accuracy: 0.6433 - val_loss: 0.5917 - val_accuracy: 0.6927\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.6092 - accuracy: 0.6882 - val_loss: 0.5727 - val_accuracy: 0.7095\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5921 - accuracy: 0.7008 - val_loss: 0.5515 - val_accuracy: 0.7095\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5750 - accuracy: 0.6952 - val_loss: 0.5350 - val_accuracy: 0.7095\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.5603 - accuracy: 0.7093 - val_loss: 0.5181 - val_accuracy: 0.6983\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5468 - accuracy: 0.7107 - val_loss: 0.5014 - val_accuracy: 0.7095\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.5352 - accuracy: 0.7149 - val_loss: 0.4895 - val_accuracy: 0.7095\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 100us/step - loss: 0.5197 - accuracy: 0.7275 - val_loss: 0.4743 - val_accuracy: 0.7598\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.5110 - accuracy: 0.7458 - val_loss: 0.4630 - val_accuracy: 0.7709\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.5033 - accuracy: 0.7640 - val_loss: 0.4542 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4959 - accuracy: 0.7626 - val_loss: 0.4479 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4896 - accuracy: 0.7711 - val_loss: 0.4431 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4834 - accuracy: 0.7725 - val_loss: 0.4376 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4779 - accuracy: 0.7753 - val_loss: 0.4377 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4735 - accuracy: 0.7753 - val_loss: 0.4326 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4716 - accuracy: 0.7781 - val_loss: 0.4310 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4673 - accuracy: 0.7823 - val_loss: 0.4299 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4645 - accuracy: 0.7879 - val_loss: 0.4288 - val_accuracy: 0.7709\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4661 - accuracy: 0.7935 - val_loss: 0.4287 - val_accuracy: 0.7709\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4600 - accuracy: 0.7879 - val_loss: 0.4277 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4590 - accuracy: 0.7949 - val_loss: 0.4262 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4575 - accuracy: 0.7935 - val_loss: 0.4313 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4551 - accuracy: 0.7879 - val_loss: 0.4288 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4527 - accuracy: 0.7949 - val_loss: 0.4266 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4515 - accuracy: 0.7978 - val_loss: 0.4246 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4506 - accuracy: 0.7963 - val_loss: 0.4251 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4478 - accuracy: 0.7963 - val_loss: 0.4216 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4460 - accuracy: 0.7978 - val_loss: 0.4252 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4474 - accuracy: 0.7978 - val_loss: 0.4211 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4457 - accuracy: 0.7978 - val_loss: 0.4198 - val_accuracy: 0.7821\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4455 - accuracy: 0.7992 - val_loss: 0.4229 - val_accuracy: 0.7877\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4446 - accuracy: 0.7978 - val_loss: 0.4205 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4430 - accuracy: 0.7992 - val_loss: 0.4236 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4424 - accuracy: 0.8006 - val_loss: 0.4195 - val_accuracy: 0.7877\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4401 - accuracy: 0.7978 - val_loss: 0.4191 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4411 - accuracy: 0.7992 - val_loss: 0.4181 - val_accuracy: 0.7989\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4448 - accuracy: 0.8048 - val_loss: 0.4258 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4389 - accuracy: 0.7978 - val_loss: 0.4198 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4418 - accuracy: 0.8006 - val_loss: 0.4183 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4363 - accuracy: 0.8006 - val_loss: 0.4183 - val_accuracy: 0.8045\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4371 - accuracy: 0.7978 - val_loss: 0.4182 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4368 - accuracy: 0.8034 - val_loss: 0.4186 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4401 - accuracy: 0.8076 - val_loss: 0.4203 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4369 - accuracy: 0.8104 - val_loss: 0.4187 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4354 - accuracy: 0.8020 - val_loss: 0.4176 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.4339 - accuracy: 0.8062 - val_loss: 0.4162 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4342 - accuracy: 0.8146 - val_loss: 0.4180 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4356 - accuracy: 0.8090 - val_loss: 0.4178 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4373 - accuracy: 0.8146 - val_loss: 0.4204 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4320 - accuracy: 0.8104 - val_loss: 0.4168 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4330 - accuracy: 0.8090 - val_loss: 0.4174 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4337 - accuracy: 0.8090 - val_loss: 0.4198 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4333 - accuracy: 0.8118 - val_loss: 0.4156 - val_accuracy: 0.8045\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4355 - accuracy: 0.8076 - val_loss: 0.4191 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4304 - accuracy: 0.8146 - val_loss: 0.4164 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4310 - accuracy: 0.8146 - val_loss: 0.4145 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4307 - accuracy: 0.8118 - val_loss: 0.4170 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4306 - accuracy: 0.8160 - val_loss: 0.4171 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4308 - accuracy: 0.8202 - val_loss: 0.4141 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4308 - accuracy: 0.8132 - val_loss: 0.4143 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4302 - accuracy: 0.8146 - val_loss: 0.4149 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4333 - accuracy: 0.8132 - val_loss: 0.4152 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4317 - accuracy: 0.8216 - val_loss: 0.4149 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 116us/step - loss: 0.4278 - accuracy: 0.8202 - val_loss: 0.4150 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4286 - accuracy: 0.8160 - val_loss: 0.4158 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4288 - accuracy: 0.8188 - val_loss: 0.4160 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4274 - accuracy: 0.8174 - val_loss: 0.4151 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4284 - accuracy: 0.8188 - val_loss: 0.4157 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4276 - accuracy: 0.8174 - val_loss: 0.4128 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4279 - accuracy: 0.8216 - val_loss: 0.4176 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4287 - accuracy: 0.8160 - val_loss: 0.4142 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4256 - accuracy: 0.8174 - val_loss: 0.4130 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4284 - accuracy: 0.8160 - val_loss: 0.4125 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4269 - accuracy: 0.8160 - val_loss: 0.4126 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4267 - accuracy: 0.8174 - val_loss: 0.4130 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4264 - accuracy: 0.8287 - val_loss: 0.4184 - val_accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4310 - accuracy: 0.8160 - val_loss: 0.4115 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4256 - accuracy: 0.8202 - val_loss: 0.4102 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4235 - accuracy: 0.8202 - val_loss: 0.4127 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4236 - accuracy: 0.8202 - val_loss: 0.4109 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4238 - accuracy: 0.8244 - val_loss: 0.4082 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4225 - accuracy: 0.8230 - val_loss: 0.4105 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4239 - accuracy: 0.8188 - val_loss: 0.4085 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4225 - accuracy: 0.8160 - val_loss: 0.4084 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4215 - accuracy: 0.8272 - val_loss: 0.4133 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4245 - accuracy: 0.8216 - val_loss: 0.4084 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4227 - accuracy: 0.8287 - val_loss: 0.4143 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4242 - accuracy: 0.8244 - val_loss: 0.4105 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4215 - accuracy: 0.8244 - val_loss: 0.4078 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4208 - accuracy: 0.8216 - val_loss: 0.4132 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4210 - accuracy: 0.8230 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4204 - accuracy: 0.8244 - val_loss: 0.4093 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4216 - accuracy: 0.8272 - val_loss: 0.4114 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4214 - accuracy: 0.8244 - val_loss: 0.4067 - val_accuracy: 0.8045\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4205 - accuracy: 0.8244 - val_loss: 0.4103 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4200 - accuracy: 0.8244 - val_loss: 0.4071 - val_accuracy: 0.8045\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4204 - accuracy: 0.8230 - val_loss: 0.4073 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4182 - accuracy: 0.8244 - val_loss: 0.4075 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4235 - accuracy: 0.8244 - val_loss: 0.4096 - val_accuracy: 0.8101\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4208 - accuracy: 0.8228\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4189 - accuracy: 0.8211\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4195 - accuracy: 0.8211\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4192 - accuracy: 0.8211\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4186 - accuracy: 0.8228\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4185 - accuracy: 0.8228\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4179 - accuracy: 0.8246\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4174 - accuracy: 0.8211\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4174 - accuracy: 0.8246\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4201 - accuracy: 0.8211\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.4185 - accuracy: 0.8263\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4196 - accuracy: 0.8246\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 94us/step - loss: 0.4167 - accuracy: 0.8228\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4188 - accuracy: 0.8281\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4198 - accuracy: 0.8158\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4163 - accuracy: 0.8211\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4181 - accuracy: 0.8263\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4181 - accuracy: 0.8263\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4149 - accuracy: 0.8228\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4152 - accuracy: 0.8246\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4152 - accuracy: 0.8246\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4150 - accuracy: 0.8211\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 104us/step - loss: 0.4160 - accuracy: 0.8263\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4184 - accuracy: 0.8281\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4187 - accuracy: 0.8211\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4155 - accuracy: 0.8246\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4142 - accuracy: 0.8246\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4146 - accuracy: 0.8246\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4142 - accuracy: 0.8246\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 64us/step - loss: 0.4148 - accuracy: 0.8246\n",
      "142/142 [==============================] - 0s 69us/step\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 880us/step - loss: 0.9574 - accuracy: 0.3834 - val_loss: 0.8254 - val_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.7641 - accuracy: 0.3834 - val_loss: 0.7159 - val_accuracy: 0.3966\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6938 - accuracy: 0.4508 - val_loss: 0.6689 - val_accuracy: 0.7374\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6627 - accuracy: 0.7346 - val_loss: 0.6520 - val_accuracy: 0.7709\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6518 - accuracy: 0.7556 - val_loss: 0.6390 - val_accuracy: 0.7877\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6415 - accuracy: 0.7556 - val_loss: 0.6268 - val_accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6319 - accuracy: 0.7612 - val_loss: 0.6151 - val_accuracy: 0.7877\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6209 - accuracy: 0.7683 - val_loss: 0.6032 - val_accuracy: 0.7989\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6097 - accuracy: 0.7683 - val_loss: 0.5887 - val_accuracy: 0.7989\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.5981 - accuracy: 0.7654 - val_loss: 0.5756 - val_accuracy: 0.8045\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.5841 - accuracy: 0.7711 - val_loss: 0.5590 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.5680 - accuracy: 0.7711 - val_loss: 0.5414 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.5517 - accuracy: 0.7753 - val_loss: 0.5237 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.5379 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5208 - accuracy: 0.7767 - val_loss: 0.4880 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.5058 - accuracy: 0.7851 - val_loss: 0.4708 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4917 - accuracy: 0.7893 - val_loss: 0.4563 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4826 - accuracy: 0.7893 - val_loss: 0.4473 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4752 - accuracy: 0.7851 - val_loss: 0.4366 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4706 - accuracy: 0.7893 - val_loss: 0.4321 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4660 - accuracy: 0.7879 - val_loss: 0.4291 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4642 - accuracy: 0.7879 - val_loss: 0.4240 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4211 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4596 - accuracy: 0.7865 - val_loss: 0.4204 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4229 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4586 - accuracy: 0.7907 - val_loss: 0.4169 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4540 - accuracy: 0.7907 - val_loss: 0.4178 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4527 - accuracy: 0.7921 - val_loss: 0.4158 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4538 - accuracy: 0.7963 - val_loss: 0.4179 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.4170 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4517 - accuracy: 0.7935 - val_loss: 0.4162 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4477 - accuracy: 0.7949 - val_loss: 0.4146 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4497 - accuracy: 0.7907 - val_loss: 0.4129 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4466 - accuracy: 0.7963 - val_loss: 0.4118 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4507 - accuracy: 0.7978 - val_loss: 0.4118 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4464 - accuracy: 0.7992 - val_loss: 0.4110 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4443 - accuracy: 0.7978 - val_loss: 0.4110 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4443 - accuracy: 0.8006 - val_loss: 0.4108 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4437 - accuracy: 0.8006 - val_loss: 0.4091 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4441 - accuracy: 0.7963 - val_loss: 0.4092 - val_accuracy: 0.8045\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4430 - accuracy: 0.8048 - val_loss: 0.4115 - val_accuracy: 0.8045\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4433 - accuracy: 0.8006 - val_loss: 0.4090 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4409 - accuracy: 0.8062 - val_loss: 0.4108 - val_accuracy: 0.7765\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4460 - accuracy: 0.8048 - val_loss: 0.4073 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4412 - accuracy: 0.8034 - val_loss: 0.4056 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4406 - accuracy: 0.8034 - val_loss: 0.4069 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4399 - accuracy: 0.8048 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4383 - accuracy: 0.8076 - val_loss: 0.4033 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4388 - accuracy: 0.8034 - val_loss: 0.4014 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 87us/step - loss: 0.4425 - accuracy: 0.8048 - val_loss: 0.4027 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4377 - accuracy: 0.8048 - val_loss: 0.4038 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4396 - accuracy: 0.8118 - val_loss: 0.4050 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4363 - accuracy: 0.8090 - val_loss: 0.4038 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4378 - accuracy: 0.8076 - val_loss: 0.4023 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4357 - accuracy: 0.8076 - val_loss: 0.4009 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4354 - accuracy: 0.8104 - val_loss: 0.4001 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4364 - accuracy: 0.8076 - val_loss: 0.4011 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4372 - accuracy: 0.8076 - val_loss: 0.4029 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4411 - accuracy: 0.8132 - val_loss: 0.4006 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4352 - accuracy: 0.8118 - val_loss: 0.4029 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4359 - accuracy: 0.8104 - val_loss: 0.4011 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4342 - accuracy: 0.8104 - val_loss: 0.3985 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4356 - accuracy: 0.8146 - val_loss: 0.4007 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4334 - accuracy: 0.8160 - val_loss: 0.4006 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4335 - accuracy: 0.8118 - val_loss: 0.3956 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4322 - accuracy: 0.8132 - val_loss: 0.3954 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4323 - accuracy: 0.8132 - val_loss: 0.3961 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4320 - accuracy: 0.8132 - val_loss: 0.3985 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4324 - accuracy: 0.8160 - val_loss: 0.3957 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4317 - accuracy: 0.8174 - val_loss: 0.3966 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4319 - accuracy: 0.8118 - val_loss: 0.3962 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4314 - accuracy: 0.8174 - val_loss: 0.3957 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4308 - accuracy: 0.8188 - val_loss: 0.3956 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4313 - accuracy: 0.8146 - val_loss: 0.3966 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4316 - accuracy: 0.8132 - val_loss: 0.3942 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4306 - accuracy: 0.8160 - val_loss: 0.3959 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4301 - accuracy: 0.8132 - val_loss: 0.3952 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4302 - accuracy: 0.8188 - val_loss: 0.3951 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4294 - accuracy: 0.8174 - val_loss: 0.3951 - val_accuracy: 0.7989\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4293 - accuracy: 0.8132 - val_loss: 0.3943 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4290 - accuracy: 0.8174 - val_loss: 0.3957 - val_accuracy: 0.7933\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.3942 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4282 - accuracy: 0.8216 - val_loss: 0.3940 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4286 - accuracy: 0.8174 - val_loss: 0.3935 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4285 - accuracy: 0.8146 - val_loss: 0.3940 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4285 - accuracy: 0.8188 - val_loss: 0.3916 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4313 - accuracy: 0.8090 - val_loss: 0.3974 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4321 - accuracy: 0.8216 - val_loss: 0.3937 - val_accuracy: 0.7933\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4266 - accuracy: 0.8160 - val_loss: 0.3918 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4286 - accuracy: 0.8202 - val_loss: 0.3955 - val_accuracy: 0.7933\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4296 - accuracy: 0.8160 - val_loss: 0.3895 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4298 - accuracy: 0.8146 - val_loss: 0.3919 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4298 - accuracy: 0.8202 - val_loss: 0.3921 - val_accuracy: 0.7933\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4268 - accuracy: 0.8146 - val_loss: 0.3966 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4267 - accuracy: 0.8230 - val_loss: 0.3892 - val_accuracy: 0.7989\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4273 - accuracy: 0.8160 - val_loss: 0.3927 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4274 - accuracy: 0.8174 - val_loss: 0.3933 - val_accuracy: 0.7989\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4260 - accuracy: 0.8160 - val_loss: 0.3883 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4260 - accuracy: 0.8202 - val_loss: 0.3888 - val_accuracy: 0.7989\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4288 - accuracy: 0.8160 - val_loss: 0.3918 - val_accuracy: 0.7989\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4293 - accuracy: 0.8193\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4231 - accuracy: 0.8281\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.4230 - accuracy: 0.8298\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4254 - accuracy: 0.8316\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 94us/step - loss: 0.4244 - accuracy: 0.8263\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4220 - accuracy: 0.8298\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4249 - accuracy: 0.8263\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 79us/step - loss: 0.4243 - accuracy: 0.8316\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4217 - accuracy: 0.8281\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4224 - accuracy: 0.8298\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4217 - accuracy: 0.8281\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4213 - accuracy: 0.8281\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4215 - accuracy: 0.8281\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.4227 - accuracy: 0.8298\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 142us/step - loss: 0.4202 - accuracy: 0.8298\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4209 - accuracy: 0.8298\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4200 - accuracy: 0.8298\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 111us/step - loss: 0.4238 - accuracy: 0.8298\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4236 - accuracy: 0.8246\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 171us/step - loss: 0.4246 - accuracy: 0.8281\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 185us/step - loss: 0.4227 - accuracy: 0.8246\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 182us/step - loss: 0.4206 - accuracy: 0.8316\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 208us/step - loss: 0.4196 - accuracy: 0.8316\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4191 - accuracy: 0.8316\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 98us/step - loss: 0.4184 - accuracy: 0.8298\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4199 - accuracy: 0.8333\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4191 - accuracy: 0.8263\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4182 - accuracy: 0.8281\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4184 - accuracy: 0.8316\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4186 - accuracy: 0.8316\n",
      "142/142 [==============================] - 0s 57us/step\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 691us/step - loss: 0.6987 - accuracy: 0.4986 - val_loss: 0.6732 - val_accuracy: 0.6425\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6707 - accuracy: 0.6166 - val_loss: 0.6562 - val_accuracy: 0.6648\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6554 - accuracy: 0.6250 - val_loss: 0.6417 - val_accuracy: 0.6816\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6445 - accuracy: 0.6489 - val_loss: 0.6313 - val_accuracy: 0.6816\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6371 - accuracy: 0.6587 - val_loss: 0.6259 - val_accuracy: 0.6760\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6315 - accuracy: 0.6475 - val_loss: 0.6201 - val_accuracy: 0.6648\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.6252 - accuracy: 0.6531 - val_loss: 0.6121 - val_accuracy: 0.6760\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6168 - accuracy: 0.6489 - val_loss: 0.6034 - val_accuracy: 0.6816\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6044 - accuracy: 0.6489 - val_loss: 0.5885 - val_accuracy: 0.6760\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.5895 - accuracy: 0.6643 - val_loss: 0.5728 - val_accuracy: 0.7207\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.5719 - accuracy: 0.7177 - val_loss: 0.5480 - val_accuracy: 0.7765\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5496 - accuracy: 0.7683 - val_loss: 0.5184 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.5287 - accuracy: 0.7739 - val_loss: 0.4991 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.5117 - accuracy: 0.7725 - val_loss: 0.4756 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5008 - accuracy: 0.7795 - val_loss: 0.4648 - val_accuracy: 0.7989\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4916 - accuracy: 0.7921 - val_loss: 0.4533 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4886 - accuracy: 0.7809 - val_loss: 0.4502 - val_accuracy: 0.7989\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4850 - accuracy: 0.7879 - val_loss: 0.4425 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4805 - accuracy: 0.7837 - val_loss: 0.4471 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4802 - accuracy: 0.7949 - val_loss: 0.4370 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4739 - accuracy: 0.7879 - val_loss: 0.4335 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4720 - accuracy: 0.7879 - val_loss: 0.4318 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4711 - accuracy: 0.7879 - val_loss: 0.4304 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4697 - accuracy: 0.7879 - val_loss: 0.4285 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4670 - accuracy: 0.7921 - val_loss: 0.4277 - val_accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4653 - accuracy: 0.7907 - val_loss: 0.4253 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4639 - accuracy: 0.7921 - val_loss: 0.4240 - val_accuracy: 0.8045\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4627 - accuracy: 0.7935 - val_loss: 0.4270 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4263 - val_accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4594 - accuracy: 0.7935 - val_loss: 0.4242 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4576 - accuracy: 0.7949 - val_loss: 0.4234 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4560 - accuracy: 0.7893 - val_loss: 0.4241 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4558 - accuracy: 0.7879 - val_loss: 0.4245 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 85us/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.4246 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4559 - accuracy: 0.7978 - val_loss: 0.4223 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4527 - accuracy: 0.7879 - val_loss: 0.4222 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4521 - accuracy: 0.7921 - val_loss: 0.4202 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4511 - accuracy: 0.7963 - val_loss: 0.4208 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4523 - accuracy: 0.7992 - val_loss: 0.4222 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4513 - accuracy: 0.7963 - val_loss: 0.4222 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4477 - accuracy: 0.7907 - val_loss: 0.4218 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4476 - accuracy: 0.8048 - val_loss: 0.4224 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4460 - accuracy: 0.7992 - val_loss: 0.4246 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4470 - accuracy: 0.7992 - val_loss: 0.4223 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4454 - accuracy: 0.7978 - val_loss: 0.4192 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4439 - accuracy: 0.7963 - val_loss: 0.4225 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4441 - accuracy: 0.8020 - val_loss: 0.4216 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4452 - accuracy: 0.7963 - val_loss: 0.4223 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4428 - accuracy: 0.8048 - val_loss: 0.4190 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4420 - accuracy: 0.8048 - val_loss: 0.4194 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4419 - accuracy: 0.8104 - val_loss: 0.4207 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4385 - accuracy: 0.8090 - val_loss: 0.4191 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4416 - accuracy: 0.8104 - val_loss: 0.4187 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4390 - accuracy: 0.8146 - val_loss: 0.4185 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4368 - accuracy: 0.8160 - val_loss: 0.4180 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4367 - accuracy: 0.8174 - val_loss: 0.4167 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4378 - accuracy: 0.8132 - val_loss: 0.4206 - val_accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4369 - accuracy: 0.8188 - val_loss: 0.4193 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4359 - accuracy: 0.8188 - val_loss: 0.4194 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4372 - accuracy: 0.8132 - val_loss: 0.4170 - val_accuracy: 0.7933\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4347 - accuracy: 0.8146 - val_loss: 0.4152 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4342 - accuracy: 0.8174 - val_loss: 0.4195 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4347 - accuracy: 0.8216 - val_loss: 0.4182 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4349 - accuracy: 0.8160 - val_loss: 0.4160 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4318 - accuracy: 0.8202 - val_loss: 0.4173 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4317 - accuracy: 0.8188 - val_loss: 0.4158 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4317 - accuracy: 0.8188 - val_loss: 0.4159 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4327 - accuracy: 0.8202 - val_loss: 0.4144 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4333 - accuracy: 0.8132 - val_loss: 0.4189 - val_accuracy: 0.7877\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4327 - accuracy: 0.8244 - val_loss: 0.4150 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.4292 - accuracy: 0.8216 - val_loss: 0.4137 - val_accuracy: 0.7989\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.4296 - accuracy: 0.8174 - val_loss: 0.4143 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4291 - accuracy: 0.8202 - val_loss: 0.4152 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4288 - accuracy: 0.8244 - val_loss: 0.4144 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4301 - accuracy: 0.8174 - val_loss: 0.4133 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4303 - accuracy: 0.8188 - val_loss: 0.4171 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4295 - accuracy: 0.8301 - val_loss: 0.4162 - val_accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4301 - accuracy: 0.8132 - val_loss: 0.4179 - val_accuracy: 0.7989\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4309 - accuracy: 0.8258 - val_loss: 0.4188 - val_accuracy: 0.7933\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4315 - accuracy: 0.8216 - val_loss: 0.4169 - val_accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4275 - accuracy: 0.8244 - val_loss: 0.4162 - val_accuracy: 0.7989\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4297 - accuracy: 0.8216 - val_loss: 0.4186 - val_accuracy: 0.7933\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4266 - accuracy: 0.8301 - val_loss: 0.4125 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4271 - accuracy: 0.8244 - val_loss: 0.4163 - val_accuracy: 0.7933\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4261 - accuracy: 0.8230 - val_loss: 0.4156 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4261 - accuracy: 0.8244 - val_loss: 0.4154 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4288 - accuracy: 0.8244 - val_loss: 0.4137 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4253 - accuracy: 0.8230 - val_loss: 0.4140 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4239 - accuracy: 0.8272 - val_loss: 0.4178 - val_accuracy: 0.7989\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 88us/step - loss: 0.4239 - accuracy: 0.8301 - val_loss: 0.4140 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4261 - accuracy: 0.8258 - val_loss: 0.4166 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4236 - accuracy: 0.8230 - val_loss: 0.4141 - val_accuracy: 0.8045\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4244 - accuracy: 0.8272 - val_loss: 0.4155 - val_accuracy: 0.7989\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4247 - accuracy: 0.8244 - val_loss: 0.4177 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4225 - accuracy: 0.8272 - val_loss: 0.4134 - val_accuracy: 0.7989\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4269 - accuracy: 0.8132 - val_loss: 0.4218 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4246 - accuracy: 0.8287 - val_loss: 0.4146 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4237 - accuracy: 0.8188 - val_loss: 0.4146 - val_accuracy: 0.7989\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4207 - accuracy: 0.8287 - val_loss: 0.4114 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4232 - accuracy: 0.8272 - val_loss: 0.4150 - val_accuracy: 0.7989\n",
      "Epoch 1/60\n",
      "569/569 [==============================] - 0s 98us/step - loss: 0.4029 - accuracy: 0.8366\n",
      "Epoch 2/60\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4025 - accuracy: 0.8436\n",
      "Epoch 3/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4013 - accuracy: 0.8348\n",
      "Epoch 4/60\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.4030 - accuracy: 0.8348\n",
      "Epoch 5/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4014 - accuracy: 0.8383\n",
      "Epoch 6/60\n",
      "569/569 [==============================] - 0s 93us/step - loss: 0.3991 - accuracy: 0.8401\n",
      "Epoch 7/60\n",
      "569/569 [==============================] - 0s 92us/step - loss: 0.3994 - accuracy: 0.8418\n",
      "Epoch 8/60\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4004 - accuracy: 0.8418\n",
      "Epoch 9/60\n",
      "569/569 [==============================] - 0s 111us/step - loss: 0.3961 - accuracy: 0.8401\n",
      "Epoch 10/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.3978 - accuracy: 0.8418\n",
      "Epoch 11/60\n",
      "569/569 [==============================] - 0s 109us/step - loss: 0.3977 - accuracy: 0.8401\n",
      "Epoch 12/60\n",
      "569/569 [==============================] - 0s 93us/step - loss: 0.3961 - accuracy: 0.8436\n",
      "Epoch 13/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.3945 - accuracy: 0.8418\n",
      "Epoch 14/60\n",
      "569/569 [==============================] - 0s 90us/step - loss: 0.3977 - accuracy: 0.8418\n",
      "Epoch 15/60\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.3961 - accuracy: 0.8383\n",
      "Epoch 16/60\n",
      "569/569 [==============================] - 0s 97us/step - loss: 0.3933 - accuracy: 0.8418\n",
      "Epoch 17/60\n",
      "569/569 [==============================] - 0s 94us/step - loss: 0.3930 - accuracy: 0.8418\n",
      "Epoch 18/60\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.3931 - accuracy: 0.8436\n",
      "Epoch 19/60\n",
      "569/569 [==============================] - 0s 90us/step - loss: 0.3937 - accuracy: 0.8436\n",
      "Epoch 20/60\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.3934 - accuracy: 0.8453\n",
      "Epoch 21/60\n",
      "569/569 [==============================] - 0s 103us/step - loss: 0.3951 - accuracy: 0.8295\n",
      "Epoch 22/60\n",
      "569/569 [==============================] - 0s 110us/step - loss: 0.3975 - accuracy: 0.8471\n",
      "Epoch 23/60\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.3921 - accuracy: 0.8418\n",
      "Epoch 24/60\n",
      "569/569 [==============================] - 0s 93us/step - loss: 0.3914 - accuracy: 0.8383\n",
      "Epoch 25/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.3908 - accuracy: 0.8418\n",
      "Epoch 26/60\n",
      "569/569 [==============================] - 0s 76us/step - loss: 0.3922 - accuracy: 0.8401\n",
      "Epoch 27/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.3922 - accuracy: 0.8471\n",
      "Epoch 28/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.3910 - accuracy: 0.8348\n",
      "Epoch 29/60\n",
      "569/569 [==============================] - 0s 100us/step - loss: 0.3908 - accuracy: 0.8436\n",
      "Epoch 30/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.3900 - accuracy: 0.8471\n",
      "Epoch 31/60\n",
      "569/569 [==============================] - 0s 88us/step - loss: 0.3894 - accuracy: 0.8436\n",
      "Epoch 32/60\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.3910 - accuracy: 0.8366\n",
      "Epoch 33/60\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.3916 - accuracy: 0.8453\n",
      "Epoch 34/60\n",
      "569/569 [==============================] - 0s 91us/step - loss: 0.3915 - accuracy: 0.8453\n",
      "Epoch 35/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.3894 - accuracy: 0.8418\n",
      "Epoch 36/60\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.3882 - accuracy: 0.8401\n",
      "Epoch 37/60\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.3879 - accuracy: 0.8418\n",
      "Epoch 38/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.3881 - accuracy: 0.8418\n",
      "Epoch 39/60\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.3891 - accuracy: 0.8366\n",
      "Epoch 40/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.3890 - accuracy: 0.8471\n",
      "Epoch 41/60\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.3879 - accuracy: 0.8401\n",
      "Epoch 42/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.3880 - accuracy: 0.8436\n",
      "Epoch 43/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.3876 - accuracy: 0.8418\n",
      "Epoch 44/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.3876 - accuracy: 0.8401\n",
      "Epoch 45/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.3864 - accuracy: 0.8471\n",
      "Epoch 46/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.3868 - accuracy: 0.8436\n",
      "Epoch 47/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.3931 - accuracy: 0.8436\n",
      "Epoch 48/60\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.3922 - accuracy: 0.8295\n",
      "Epoch 49/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.3878 - accuracy: 0.8436\n",
      "Epoch 50/60\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.3865 - accuracy: 0.8366\n",
      "Epoch 51/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.3862 - accuracy: 0.8453\n",
      "Epoch 52/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.3873 - accuracy: 0.8313\n",
      "Epoch 53/60\n",
      "569/569 [==============================] - 0s 68us/step - loss: 0.3877 - accuracy: 0.8489\n",
      "Epoch 54/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.3849 - accuracy: 0.8418\n",
      "Epoch 55/60\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.3876 - accuracy: 0.8471\n",
      "Epoch 56/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.3867 - accuracy: 0.8330\n",
      "Epoch 57/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.3863 - accuracy: 0.8471\n",
      "Epoch 58/60\n",
      "569/569 [==============================] - 0s 76us/step - loss: 0.3866 - accuracy: 0.8348\n",
      "Epoch 59/60\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.3856 - accuracy: 0.8453\n",
      "Epoch 60/60\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.3848 - accuracy: 0.8436\n",
      "143/143 [==============================] - 0s 74us/step\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 503us/step - loss: 0.6792 - accuracy: 0.6166 - val_loss: 0.6838 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.6595 - accuracy: 0.6166 - val_loss: 0.6644 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.6443 - accuracy: 0.6166 - val_loss: 0.6456 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6282 - accuracy: 0.6166 - val_loss: 0.6201 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6086 - accuracy: 0.6166 - val_loss: 0.5906 - val_accuracy: 0.6201\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5875 - accuracy: 0.6587 - val_loss: 0.5663 - val_accuracy: 0.7151\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5691 - accuracy: 0.7317 - val_loss: 0.5436 - val_accuracy: 0.7654\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.5557 - accuracy: 0.7584 - val_loss: 0.5242 - val_accuracy: 0.7486\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.5409 - accuracy: 0.7514 - val_loss: 0.5084 - val_accuracy: 0.7486\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.5311 - accuracy: 0.7584 - val_loss: 0.4976 - val_accuracy: 0.7765\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.5196 - accuracy: 0.7683 - val_loss: 0.4831 - val_accuracy: 0.7765\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5066 - accuracy: 0.7725 - val_loss: 0.4671 - val_accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4964 - accuracy: 0.7823 - val_loss: 0.4579 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4896 - accuracy: 0.7879 - val_loss: 0.4506 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4849 - accuracy: 0.7795 - val_loss: 0.4430 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4807 - accuracy: 0.7795 - val_loss: 0.4401 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4781 - accuracy: 0.7823 - val_loss: 0.4377 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4750 - accuracy: 0.7795 - val_loss: 0.4356 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4742 - accuracy: 0.7823 - val_loss: 0.4350 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4720 - accuracy: 0.7795 - val_loss: 0.4319 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4684 - accuracy: 0.7837 - val_loss: 0.4324 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4685 - accuracy: 0.7851 - val_loss: 0.4336 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4683 - accuracy: 0.7823 - val_loss: 0.4311 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4652 - accuracy: 0.7823 - val_loss: 0.4295 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4641 - accuracy: 0.7851 - val_loss: 0.4258 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4249 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4603 - accuracy: 0.7837 - val_loss: 0.4238 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4580 - accuracy: 0.7851 - val_loss: 0.4234 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.4248 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4573 - accuracy: 0.7837 - val_loss: 0.4227 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.4212 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4542 - accuracy: 0.7851 - val_loss: 0.4200 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4535 - accuracy: 0.7893 - val_loss: 0.4192 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4544 - accuracy: 0.7921 - val_loss: 0.4200 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4512 - accuracy: 0.7893 - val_loss: 0.4189 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4516 - accuracy: 0.7921 - val_loss: 0.4174 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4502 - accuracy: 0.7921 - val_loss: 0.4185 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4505 - accuracy: 0.7935 - val_loss: 0.4188 - val_accuracy: 0.7877\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4513 - accuracy: 0.7992 - val_loss: 0.4175 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4502 - accuracy: 0.7992 - val_loss: 0.4168 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4518 - accuracy: 0.7992 - val_loss: 0.4174 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4513 - accuracy: 0.7963 - val_loss: 0.4164 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4471 - accuracy: 0.8006 - val_loss: 0.4147 - val_accuracy: 0.7989\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4460 - accuracy: 0.8020 - val_loss: 0.4146 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4484 - accuracy: 0.8034 - val_loss: 0.4140 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4454 - accuracy: 0.8048 - val_loss: 0.4122 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4468 - accuracy: 0.8048 - val_loss: 0.4110 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.81 - 0s 70us/step - loss: 0.4437 - accuracy: 0.8034 - val_loss: 0.4115 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4425 - accuracy: 0.8048 - val_loss: 0.4099 - val_accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4442 - accuracy: 0.8048 - val_loss: 0.4103 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4457 - accuracy: 0.8062 - val_loss: 0.4101 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4420 - accuracy: 0.8062 - val_loss: 0.4097 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4415 - accuracy: 0.8076 - val_loss: 0.4085 - val_accuracy: 0.8101\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4415 - accuracy: 0.8062 - val_loss: 0.4095 - val_accuracy: 0.8045\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4415 - accuracy: 0.8090 - val_loss: 0.4053 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4444 - accuracy: 0.8076 - val_loss: 0.4080 - val_accuracy: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4410 - accuracy: 0.8034 - val_loss: 0.4105 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4394 - accuracy: 0.8034 - val_loss: 0.4077 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5154 - accuracy: 0.68 - 0s 78us/step - loss: 0.4398 - accuracy: 0.8076 - val_loss: 0.4060 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4386 - accuracy: 0.8048 - val_loss: 0.4064 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4391 - accuracy: 0.8062 - val_loss: 0.4063 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4390 - accuracy: 0.8118 - val_loss: 0.4070 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4390 - accuracy: 0.8020 - val_loss: 0.4058 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4370 - accuracy: 0.8048 - val_loss: 0.4052 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4375 - accuracy: 0.8104 - val_loss: 0.4054 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4376 - accuracy: 0.8104 - val_loss: 0.4044 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4389 - accuracy: 0.8034 - val_loss: 0.4061 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4373 - accuracy: 0.8104 - val_loss: 0.4016 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4363 - accuracy: 0.8034 - val_loss: 0.4039 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4352 - accuracy: 0.8062 - val_loss: 0.4037 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4356 - accuracy: 0.8076 - val_loss: 0.4053 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4360 - accuracy: 0.8076 - val_loss: 0.4063 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4368 - accuracy: 0.8076 - val_loss: 0.4033 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4355 - accuracy: 0.8118 - val_loss: 0.4040 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4358 - accuracy: 0.8118 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4345 - accuracy: 0.8076 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4362 - accuracy: 0.8132 - val_loss: 0.4016 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4359 - accuracy: 0.8076 - val_loss: 0.4048 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4345 - accuracy: 0.8062 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4353 - accuracy: 0.8146 - val_loss: 0.4040 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4339 - accuracy: 0.8048 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4365 - accuracy: 0.8062 - val_loss: 0.4032 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4356 - accuracy: 0.8062 - val_loss: 0.4026 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4327 - accuracy: 0.8118 - val_loss: 0.4021 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4334 - accuracy: 0.8062 - val_loss: 0.4040 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4324 - accuracy: 0.8090 - val_loss: 0.4032 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4316 - accuracy: 0.8090 - val_loss: 0.4006 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4313 - accuracy: 0.8076 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4350 - accuracy: 0.8090 - val_loss: 0.4028 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4337 - accuracy: 0.8090 - val_loss: 0.4004 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4313 - accuracy: 0.8118 - val_loss: 0.4016 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4308 - accuracy: 0.8076 - val_loss: 0.4000 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4301 - accuracy: 0.8104 - val_loss: 0.3987 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4336 - accuracy: 0.8146 - val_loss: 0.4015 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4305 - accuracy: 0.8104 - val_loss: 0.4044 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4311 - accuracy: 0.8132 - val_loss: 0.3997 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4296 - accuracy: 0.8104 - val_loss: 0.3998 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4299 - accuracy: 0.8132 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4305 - accuracy: 0.8118 - val_loss: 0.4000 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4297 - accuracy: 0.8118 - val_loss: 0.3997 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4400 - accuracy: 0.8084\n",
      "Epoch 2/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4396 - accuracy: 0.8137\n",
      "Epoch 3/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4404 - accuracy: 0.8067\n",
      "Epoch 4/60\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4379 - accuracy: 0.8084\n",
      "Epoch 5/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4385 - accuracy: 0.8102\n",
      "Epoch 6/60\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4393 - accuracy: 0.8049\n",
      "Epoch 7/60\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4404 - accuracy: 0.8032\n",
      "Epoch 8/60\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4386 - accuracy: 0.8067\n",
      "Epoch 9/60\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4382 - accuracy: 0.8102\n",
      "Epoch 10/60\n",
      "569/569 [==============================] - 0s 74us/step - loss: 0.4415 - accuracy: 0.8049\n",
      "Epoch 11/60\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.4409 - accuracy: 0.8102\n",
      "Epoch 12/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4375 - accuracy: 0.8084\n",
      "Epoch 13/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4369 - accuracy: 0.8084\n",
      "Epoch 14/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4373 - accuracy: 0.8102\n",
      "Epoch 15/60\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.4373 - accuracy: 0.8102\n",
      "Epoch 16/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4386 - accuracy: 0.8102\n",
      "Epoch 17/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4387 - accuracy: 0.8137\n",
      "Epoch 18/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 91us/step - loss: 0.4389 - accuracy: 0.8137\n",
      "Epoch 19/60\n",
      "569/569 [==============================] - 0s 85us/step - loss: 0.4367 - accuracy: 0.8084\n",
      "Epoch 20/60\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.4382 - accuracy: 0.8120\n",
      "Epoch 21/60\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4363 - accuracy: 0.8084\n",
      "Epoch 22/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4365 - accuracy: 0.8102\n",
      "Epoch 23/60\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4367 - accuracy: 0.8120\n",
      "Epoch 24/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4362 - accuracy: 0.8102\n",
      "Epoch 25/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4362 - accuracy: 0.8084\n",
      "Epoch 26/60\n",
      "569/569 [==============================] - 0s 82us/step - loss: 0.4356 - accuracy: 0.8137\n",
      "Epoch 27/60\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4360 - accuracy: 0.8102\n",
      "Epoch 28/60\n",
      "569/569 [==============================] - 0s 91us/step - loss: 0.4352 - accuracy: 0.8102\n",
      "Epoch 29/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4362 - accuracy: 0.8102\n",
      "Epoch 30/60\n",
      "569/569 [==============================] - 0s 68us/step - loss: 0.4357 - accuracy: 0.8084\n",
      "Epoch 31/60\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4354 - accuracy: 0.8102\n",
      "Epoch 32/60\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4366 - accuracy: 0.8137\n",
      "Epoch 33/60\n",
      "569/569 [==============================] - 0s 100us/step - loss: 0.4355 - accuracy: 0.8102\n",
      "Epoch 34/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4355 - accuracy: 0.8084\n",
      "Epoch 35/60\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4363 - accuracy: 0.8120\n",
      "Epoch 36/60\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4351 - accuracy: 0.8120\n",
      "Epoch 37/60\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4345 - accuracy: 0.8120\n",
      "Epoch 38/60\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4347 - accuracy: 0.8155\n",
      "Epoch 39/60\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.4339 - accuracy: 0.8120\n",
      "Epoch 40/60\n",
      "569/569 [==============================] - 0s 82us/step - loss: 0.4340 - accuracy: 0.8084\n",
      "Epoch 41/60\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.4345 - accuracy: 0.8084\n",
      "Epoch 42/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4343 - accuracy: 0.8102\n",
      "Epoch 43/60\n",
      "569/569 [==============================] - 0s 93us/step - loss: 0.4344 - accuracy: 0.8137\n",
      "Epoch 44/60\n",
      "569/569 [==============================] - 0s 82us/step - loss: 0.4363 - accuracy: 0.8120\n",
      "Epoch 45/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4348 - accuracy: 0.8102\n",
      "Epoch 46/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4365 - accuracy: 0.8067\n",
      "Epoch 47/60\n",
      "569/569 [==============================] - 0s 74us/step - loss: 0.4327 - accuracy: 0.8137\n",
      "Epoch 48/60\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4336 - accuracy: 0.8102\n",
      "Epoch 49/60\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4338 - accuracy: 0.8120\n",
      "Epoch 50/60\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4342 - accuracy: 0.8084\n",
      "Epoch 51/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4339 - accuracy: 0.8137\n",
      "Epoch 52/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4335 - accuracy: 0.8102\n",
      "Epoch 53/60\n",
      "569/569 [==============================] - 0s 88us/step - loss: 0.4324 - accuracy: 0.8155\n",
      "Epoch 54/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4343 - accuracy: 0.8137\n",
      "Epoch 55/60\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.4338 - accuracy: 0.8120\n",
      "Epoch 56/60\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4333 - accuracy: 0.8084\n",
      "Epoch 57/60\n",
      "569/569 [==============================] - 0s 70us/step - loss: 0.4319 - accuracy: 0.8172\n",
      "Epoch 58/60\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4322 - accuracy: 0.8137\n",
      "Epoch 59/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4382 - accuracy: 0.8137\n",
      "Epoch 60/60\n",
      "569/569 [==============================] - 0s 82us/step - loss: 0.4322 - accuracy: 0.8137\n",
      "143/143 [==============================] - 0s 63us/step\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 534us/step - loss: 0.6845 - accuracy: 0.5927 - val_loss: 0.6816 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6742 - accuracy: 0.6166 - val_loss: 0.6718 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6639 - accuracy: 0.6180 - val_loss: 0.6601 - val_accuracy: 0.6313\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6529 - accuracy: 0.6433 - val_loss: 0.6456 - val_accuracy: 0.6760\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6392 - accuracy: 0.6657 - val_loss: 0.6240 - val_accuracy: 0.6872\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.6175 - accuracy: 0.6685 - val_loss: 0.5895 - val_accuracy: 0.7095\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5894 - accuracy: 0.6924 - val_loss: 0.5504 - val_accuracy: 0.7263\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5594 - accuracy: 0.7219 - val_loss: 0.5178 - val_accuracy: 0.7542\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5376 - accuracy: 0.7640 - val_loss: 0.4865 - val_accuracy: 0.7765\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5147 - accuracy: 0.7711 - val_loss: 0.4715 - val_accuracy: 0.7765\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5017 - accuracy: 0.7823 - val_loss: 0.4624 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4938 - accuracy: 0.7851 - val_loss: 0.4542 - val_accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4885 - accuracy: 0.7935 - val_loss: 0.4487 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4831 - accuracy: 0.7907 - val_loss: 0.4434 - val_accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4797 - accuracy: 0.7907 - val_loss: 0.4431 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.4404 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4767 - accuracy: 0.7949 - val_loss: 0.4406 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4716 - accuracy: 0.7907 - val_loss: 0.4379 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4700 - accuracy: 0.7921 - val_loss: 0.4350 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 72us/step - loss: 0.4680 - accuracy: 0.7921 - val_loss: 0.4362 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4668 - accuracy: 0.7935 - val_loss: 0.4312 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4648 - accuracy: 0.7893 - val_loss: 0.4326 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4632 - accuracy: 0.7893 - val_loss: 0.4297 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4614 - accuracy: 0.7921 - val_loss: 0.4293 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4596 - accuracy: 0.7893 - val_loss: 0.4272 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4597 - accuracy: 0.7921 - val_loss: 0.4298 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4585 - accuracy: 0.7921 - val_loss: 0.4245 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4616 - accuracy: 0.7921 - val_loss: 0.4246 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4584 - accuracy: 0.7949 - val_loss: 0.4234 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4546 - accuracy: 0.7949 - val_loss: 0.4223 - val_accuracy: 0.7765\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4524 - accuracy: 0.7949 - val_loss: 0.4208 - val_accuracy: 0.7709\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4527 - accuracy: 0.7907 - val_loss: 0.4212 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4501 - accuracy: 0.7963 - val_loss: 0.4190 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4523 - accuracy: 0.7935 - val_loss: 0.4165 - val_accuracy: 0.7765\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4517 - accuracy: 0.7963 - val_loss: 0.4198 - val_accuracy: 0.7877\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4482 - accuracy: 0.7949 - val_loss: 0.4154 - val_accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4490 - accuracy: 0.7978 - val_loss: 0.4143 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4470 - accuracy: 0.7978 - val_loss: 0.4167 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4463 - accuracy: 0.8006 - val_loss: 0.4131 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4470 - accuracy: 0.8006 - val_loss: 0.4136 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4469 - accuracy: 0.8034 - val_loss: 0.4104 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4474 - accuracy: 0.8020 - val_loss: 0.4087 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4464 - accuracy: 0.8062 - val_loss: 0.4157 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4463 - accuracy: 0.8048 - val_loss: 0.4091 - val_accuracy: 0.7877\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4425 - accuracy: 0.8104 - val_loss: 0.4107 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4427 - accuracy: 0.8062 - val_loss: 0.4079 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4421 - accuracy: 0.8048 - val_loss: 0.4096 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4424 - accuracy: 0.8076 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4412 - accuracy: 0.8062 - val_loss: 0.4057 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4439 - accuracy: 0.8104 - val_loss: 0.4119 - val_accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4411 - accuracy: 0.8090 - val_loss: 0.4061 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4439 - accuracy: 0.8048 - val_loss: 0.4045 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4392 - accuracy: 0.8132 - val_loss: 0.4043 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4402 - accuracy: 0.8104 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4389 - accuracy: 0.8118 - val_loss: 0.4031 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4377 - accuracy: 0.8118 - val_loss: 0.4018 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4390 - accuracy: 0.8118 - val_loss: 0.4011 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4389 - accuracy: 0.8146 - val_loss: 0.4018 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4384 - accuracy: 0.8118 - val_loss: 0.4015 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4371 - accuracy: 0.8132 - val_loss: 0.4038 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4386 - accuracy: 0.8090 - val_loss: 0.4019 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4385 - accuracy: 0.8118 - val_loss: 0.4037 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4356 - accuracy: 0.8076 - val_loss: 0.4018 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4409 - accuracy: 0.8174 - val_loss: 0.4012 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4360 - accuracy: 0.8090 - val_loss: 0.4009 - val_accuracy: 0.7989\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4354 - accuracy: 0.8146 - val_loss: 0.4010 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4368 - accuracy: 0.8076 - val_loss: 0.4023 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4354 - accuracy: 0.8146 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.4048 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4356 - accuracy: 0.8132 - val_loss: 0.3997 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4370 - accuracy: 0.8174 - val_loss: 0.4008 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4402 - accuracy: 0.8160 - val_loss: 0.4048 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4370 - accuracy: 0.8132 - val_loss: 0.3963 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4341 - accuracy: 0.8146 - val_loss: 0.4022 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4342 - accuracy: 0.8174 - val_loss: 0.4013 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 81us/step - loss: 0.4332 - accuracy: 0.8174 - val_loss: 0.3992 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4351 - accuracy: 0.8146 - val_loss: 0.4022 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4356 - accuracy: 0.8174 - val_loss: 0.3981 - val_accuracy: 0.7989\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4337 - accuracy: 0.8174 - val_loss: 0.3981 - val_accuracy: 0.8045\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4348 - accuracy: 0.8146 - val_loss: 0.4003 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4335 - accuracy: 0.8160 - val_loss: 0.4022 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4333 - accuracy: 0.8188 - val_loss: 0.3985 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4324 - accuracy: 0.8160 - val_loss: 0.3986 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4344 - accuracy: 0.8174 - val_loss: 0.3952 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4330 - accuracy: 0.8160 - val_loss: 0.4007 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4318 - accuracy: 0.8174 - val_loss: 0.3966 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4336 - accuracy: 0.8188 - val_loss: 0.3979 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4318 - accuracy: 0.8174 - val_loss: 0.3981 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4317 - accuracy: 0.8160 - val_loss: 0.3949 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4302 - accuracy: 0.8174 - val_loss: 0.3976 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4302 - accuracy: 0.8188 - val_loss: 0.3989 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4325 - accuracy: 0.8174 - val_loss: 0.3995 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4357 - accuracy: 0.8146 - val_loss: 0.3988 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4329 - accuracy: 0.8202 - val_loss: 0.3996 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4292 - accuracy: 0.8188 - val_loss: 0.4011 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4322 - accuracy: 0.8202 - val_loss: 0.4011 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4291 - accuracy: 0.8188 - val_loss: 0.3967 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4302 - accuracy: 0.8146 - val_loss: 0.3963 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4298 - accuracy: 0.8188 - val_loss: 0.3984 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4303 - accuracy: 0.8174 - val_loss: 0.3980 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4336 - accuracy: 0.8158\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4304 - accuracy: 0.8140\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4303 - accuracy: 0.8175\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4297 - accuracy: 0.8105\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4284 - accuracy: 0.8175\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4281 - accuracy: 0.8158\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4295 - accuracy: 0.8123\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4304 - accuracy: 0.8070\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4297 - accuracy: 0.8158\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4293 - accuracy: 0.8140\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4289 - accuracy: 0.8123\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4268 - accuracy: 0.8123\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4262 - accuracy: 0.8140\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4263 - accuracy: 0.8123\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4290 - accuracy: 0.8140\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4289 - accuracy: 0.8070\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4259 - accuracy: 0.8105\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4278 - accuracy: 0.8053\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4273 - accuracy: 0.8158\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4269 - accuracy: 0.8140\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4260 - accuracy: 0.8105\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4256 - accuracy: 0.8105\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4263 - accuracy: 0.8158\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4269 - accuracy: 0.8070\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4257 - accuracy: 0.8158\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4263 - accuracy: 0.8123\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4254 - accuracy: 0.8105\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4259 - accuracy: 0.8105\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4303 - accuracy: 0.8123\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4264 - accuracy: 0.8193\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4265 - accuracy: 0.8140\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4258 - accuracy: 0.8053\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4237 - accuracy: 0.8140\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4254 - accuracy: 0.8088\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4245 - accuracy: 0.8175\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4245 - accuracy: 0.8088\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4240 - accuracy: 0.8158\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4270 - accuracy: 0.8158\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4229 - accuracy: 0.8140\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.4231 - accuracy: 0.8105\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4245 - accuracy: 0.8105\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4255 - accuracy: 0.8140\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4236 - accuracy: 0.8105\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4235 - accuracy: 0.8158\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4229 - accuracy: 0.8070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4229 - accuracy: 0.8140\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4239 - accuracy: 0.8088\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4235 - accuracy: 0.8088\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4243 - accuracy: 0.8105\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4263 - accuracy: 0.8123\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4274 - accuracy: 0.8088\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4246 - accuracy: 0.8053\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4216 - accuracy: 0.8175\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4221 - accuracy: 0.8140\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4223 - accuracy: 0.8123\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4244 - accuracy: 0.8070\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4226 - accuracy: 0.8123\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4215 - accuracy: 0.8105\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4212 - accuracy: 0.8088\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4233 - accuracy: 0.8070\n",
      "142/142 [==============================] - 0s 111us/step\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 531us/step - loss: 0.6837 - accuracy: 0.6166 - val_loss: 0.6716 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6544 - accuracy: 0.6166 - val_loss: 0.6371 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6227 - accuracy: 0.6320 - val_loss: 0.6078 - val_accuracy: 0.6648\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6015 - accuracy: 0.6742 - val_loss: 0.5856 - val_accuracy: 0.7095\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.5820 - accuracy: 0.7233 - val_loss: 0.5604 - val_accuracy: 0.7430\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5610 - accuracy: 0.7669 - val_loss: 0.5368 - val_accuracy: 0.7542\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5428 - accuracy: 0.7626 - val_loss: 0.5148 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.5243 - accuracy: 0.7823 - val_loss: 0.4927 - val_accuracy: 0.7765\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.5095 - accuracy: 0.7823 - val_loss: 0.4746 - val_accuracy: 0.7821\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.5004 - accuracy: 0.7907 - val_loss: 0.4606 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4890 - accuracy: 0.7865 - val_loss: 0.4485 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4810 - accuracy: 0.7851 - val_loss: 0.4414 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4757 - accuracy: 0.7851 - val_loss: 0.4337 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4789 - accuracy: 0.7893 - val_loss: 0.4309 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4677 - accuracy: 0.7851 - val_loss: 0.4259 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4671 - accuracy: 0.7837 - val_loss: 0.4219 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4623 - accuracy: 0.7879 - val_loss: 0.4206 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4596 - accuracy: 0.7865 - val_loss: 0.4155 - val_accuracy: 0.7989\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4618 - accuracy: 0.7935 - val_loss: 0.4157 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4562 - accuracy: 0.7921 - val_loss: 0.4117 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4559 - accuracy: 0.7893 - val_loss: 0.4116 - val_accuracy: 0.8045\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4528 - accuracy: 0.8006 - val_loss: 0.4078 - val_accuracy: 0.8045\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4529 - accuracy: 0.7978 - val_loss: 0.4039 - val_accuracy: 0.8045\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4529 - accuracy: 0.7949 - val_loss: 0.4103 - val_accuracy: 0.8045\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4508 - accuracy: 0.8006 - val_loss: 0.4024 - val_accuracy: 0.8045\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4472 - accuracy: 0.7978 - val_loss: 0.3999 - val_accuracy: 0.8045\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4467 - accuracy: 0.8006 - val_loss: 0.3989 - val_accuracy: 0.8101\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4456 - accuracy: 0.7963 - val_loss: 0.3966 - val_accuracy: 0.8101\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4460 - accuracy: 0.8006 - val_loss: 0.3963 - val_accuracy: 0.8045\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4449 - accuracy: 0.8090 - val_loss: 0.3977 - val_accuracy: 0.8101\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4482 - accuracy: 0.8020 - val_loss: 0.3961 - val_accuracy: 0.8045\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4421 - accuracy: 0.8104 - val_loss: 0.3932 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4404 - accuracy: 0.8118 - val_loss: 0.3926 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4395 - accuracy: 0.8118 - val_loss: 0.3906 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4407 - accuracy: 0.8090 - val_loss: 0.3896 - val_accuracy: 0.8101\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4386 - accuracy: 0.8146 - val_loss: 0.3917 - val_accuracy: 0.8101\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4377 - accuracy: 0.8146 - val_loss: 0.3894 - val_accuracy: 0.8045\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4371 - accuracy: 0.8104 - val_loss: 0.3879 - val_accuracy: 0.8156\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4404 - accuracy: 0.8104 - val_loss: 0.3869 - val_accuracy: 0.8156\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 82us/step - loss: 0.4376 - accuracy: 0.8132 - val_loss: 0.3962 - val_accuracy: 0.8156\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4427 - accuracy: 0.8132 - val_loss: 0.3896 - val_accuracy: 0.8101\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4358 - accuracy: 0.8160 - val_loss: 0.3876 - val_accuracy: 0.8101\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4346 - accuracy: 0.8146 - val_loss: 0.3876 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4349 - accuracy: 0.8146 - val_loss: 0.3881 - val_accuracy: 0.8156\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4369 - accuracy: 0.8090 - val_loss: 0.3869 - val_accuracy: 0.8156\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4330 - accuracy: 0.8160 - val_loss: 0.3894 - val_accuracy: 0.8101\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4341 - accuracy: 0.8160 - val_loss: 0.3862 - val_accuracy: 0.8156\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4319 - accuracy: 0.8174 - val_loss: 0.3862 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4351 - accuracy: 0.8174 - val_loss: 0.3863 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4316 - accuracy: 0.8160 - val_loss: 0.3856 - val_accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4311 - accuracy: 0.8132 - val_loss: 0.3840 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4319 - accuracy: 0.8202 - val_loss: 0.3834 - val_accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4308 - accuracy: 0.8160 - val_loss: 0.3837 - val_accuracy: 0.8156\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4305 - accuracy: 0.8188 - val_loss: 0.3840 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4294 - accuracy: 0.8118 - val_loss: 0.3836 - val_accuracy: 0.8156\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4306 - accuracy: 0.8188 - val_loss: 0.3847 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4287 - accuracy: 0.8104 - val_loss: 0.3877 - val_accuracy: 0.8156\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4334 - accuracy: 0.8160 - val_loss: 0.3829 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4283 - accuracy: 0.8174 - val_loss: 0.3847 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4283 - accuracy: 0.8188 - val_loss: 0.3843 - val_accuracy: 0.8156\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4280 - accuracy: 0.8160 - val_loss: 0.3832 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4306 - accuracy: 0.8188 - val_loss: 0.3827 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4304 - accuracy: 0.8104 - val_loss: 0.3819 - val_accuracy: 0.8156\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4311 - accuracy: 0.8202 - val_loss: 0.3815 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4275 - accuracy: 0.8174 - val_loss: 0.3809 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4294 - accuracy: 0.8160 - val_loss: 0.3799 - val_accuracy: 0.8156\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4290 - accuracy: 0.8230 - val_loss: 0.3816 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4322 - accuracy: 0.8048 - val_loss: 0.3807 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4259 - accuracy: 0.8230 - val_loss: 0.3839 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4278 - accuracy: 0.8174 - val_loss: 0.3800 - val_accuracy: 0.8212\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4257 - accuracy: 0.8188 - val_loss: 0.3811 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4247 - accuracy: 0.8160 - val_loss: 0.3792 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4257 - accuracy: 0.8174 - val_loss: 0.3809 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4315 - accuracy: 0.8174 - val_loss: 0.3828 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4253 - accuracy: 0.8146 - val_loss: 0.3782 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4245 - accuracy: 0.8132 - val_loss: 0.3789 - val_accuracy: 0.8156\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4231 - accuracy: 0.8188 - val_loss: 0.3807 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4268 - accuracy: 0.8146 - val_loss: 0.3784 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4254 - accuracy: 0.8174 - val_loss: 0.3809 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4221 - accuracy: 0.8230 - val_loss: 0.3815 - val_accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4259 - accuracy: 0.8202 - val_loss: 0.3803 - val_accuracy: 0.8212\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4241 - accuracy: 0.8146 - val_loss: 0.3838 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4253 - accuracy: 0.8244 - val_loss: 0.3827 - val_accuracy: 0.8212\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4215 - accuracy: 0.8132 - val_loss: 0.3828 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4233 - accuracy: 0.8230 - val_loss: 0.3823 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4223 - accuracy: 0.8160 - val_loss: 0.3810 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4230 - accuracy: 0.8188 - val_loss: 0.3829 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.71 - 0s 80us/step - loss: 0.4220 - accuracy: 0.8230 - val_loss: 0.3812 - val_accuracy: 0.8268\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4220 - accuracy: 0.8216 - val_loss: 0.3836 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4224 - accuracy: 0.8174 - val_loss: 0.3799 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4231 - accuracy: 0.8216 - val_loss: 0.3860 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4234 - accuracy: 0.8174 - val_loss: 0.3790 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4212 - accuracy: 0.8216 - val_loss: 0.3805 - val_accuracy: 0.8268\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4211 - accuracy: 0.8146 - val_loss: 0.3812 - val_accuracy: 0.8212\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4196 - accuracy: 0.8230 - val_loss: 0.3832 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 82us/step - loss: 0.4266 - accuracy: 0.8132 - val_loss: 0.3826 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4208 - accuracy: 0.8216 - val_loss: 0.3825 - val_accuracy: 0.8212\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4191 - accuracy: 0.8216 - val_loss: 0.3815 - val_accuracy: 0.8212\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4187 - accuracy: 0.8188 - val_loss: 0.3815 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4201 - accuracy: 0.8188 - val_loss: 0.3806 - val_accuracy: 0.8156\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4232 - accuracy: 0.8193\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4235 - accuracy: 0.8193\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4232 - accuracy: 0.8193\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4256 - accuracy: 0.8211\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4258 - accuracy: 0.8140\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4223 - accuracy: 0.8193\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4209 - accuracy: 0.8158\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4212 - accuracy: 0.8175\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4207 - accuracy: 0.8158\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4204 - accuracy: 0.8211\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4297 - accuracy: 0.8158\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4279 - accuracy: 0.8193\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4209 - accuracy: 0.8158\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4230 - accuracy: 0.8175\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4223 - accuracy: 0.8140\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4198 - accuracy: 0.8211\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4202 - accuracy: 0.8158\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4199 - accuracy: 0.8228\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4206 - accuracy: 0.8193\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4205 - accuracy: 0.8228\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4194 - accuracy: 0.8140\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4189 - accuracy: 0.8158\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4201 - accuracy: 0.8228\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4203 - accuracy: 0.8158\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 112us/step - loss: 0.4196 - accuracy: 0.8140\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4177 - accuracy: 0.8193\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4208 - accuracy: 0.8211\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4208 - accuracy: 0.8140\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4189 - accuracy: 0.8193\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4207 - accuracy: 0.8158\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 162us/step - loss: 0.4175 - accuracy: 0.8175\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 154us/step - loss: 0.4165 - accuracy: 0.8246\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 187us/step - loss: 0.4177 - accuracy: 0.8246\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 219us/step - loss: 0.4165 - accuracy: 0.8140\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 169us/step - loss: 0.4174 - accuracy: 0.8228\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4171 - accuracy: 0.8158\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4169 - accuracy: 0.8193\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.4169 - accuracy: 0.8228\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 153us/step - loss: 0.4161 - accuracy: 0.8228\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4170 - accuracy: 0.8193\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 140us/step - loss: 0.4158 - accuracy: 0.8228\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 249us/step - loss: 0.4163 - accuracy: 0.8228\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4166 - accuracy: 0.8193\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.4149 - accuracy: 0.8211\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 192us/step - loss: 0.4144 - accuracy: 0.8228\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4157 - accuracy: 0.8175\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4166 - accuracy: 0.8263\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4161 - accuracy: 0.8175\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 220us/step - loss: 0.4146 - accuracy: 0.8193\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 203us/step - loss: 0.4147 - accuracy: 0.8211\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 156us/step - loss: 0.4147 - accuracy: 0.8158\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 298us/step - loss: 0.4144 - accuracy: 0.8246\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 133us/step - loss: 0.4126 - accuracy: 0.8228\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4150 - accuracy: 0.8211\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.4145 - accuracy: 0.8228\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.4146 - accuracy: 0.8211\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4147 - accuracy: 0.8211\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 134us/step - loss: 0.4136 - accuracy: 0.8193\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.4131 - accuracy: 0.8211\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.4122 - accuracy: 0.8228\n",
      "142/142 [==============================] - 0s 92us/step\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 926us/step - loss: 0.6580 - accuracy: 0.6264 - val_loss: 0.6400 - val_accuracy: 0.6816\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6247 - accuracy: 0.7135 - val_loss: 0.6084 - val_accuracy: 0.7207\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 209us/step - loss: 0.5981 - accuracy: 0.7275 - val_loss: 0.5792 - val_accuracy: 0.7374\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.5695 - accuracy: 0.7444 - val_loss: 0.5457 - val_accuracy: 0.7598\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5429 - accuracy: 0.7612 - val_loss: 0.5148 - val_accuracy: 0.7598\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.5218 - accuracy: 0.7823 - val_loss: 0.4864 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.5057 - accuracy: 0.7879 - val_loss: 0.4710 - val_accuracy: 0.7877\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.4959 - accuracy: 0.7921 - val_loss: 0.4554 - val_accuracy: 0.7765\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.4897 - accuracy: 0.7879 - val_loss: 0.4459 - val_accuracy: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4833 - accuracy: 0.7921 - val_loss: 0.4408 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4816 - accuracy: 0.7851 - val_loss: 0.4373 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4794 - accuracy: 0.7837 - val_loss: 0.4384 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4825 - accuracy: 0.7823 - val_loss: 0.4315 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4735 - accuracy: 0.7865 - val_loss: 0.4286 - val_accuracy: 0.7989\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4742 - accuracy: 0.7851 - val_loss: 0.4257 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4707 - accuracy: 0.7809 - val_loss: 0.4296 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4708 - accuracy: 0.7865 - val_loss: 0.4255 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4676 - accuracy: 0.7823 - val_loss: 0.4293 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4673 - accuracy: 0.7879 - val_loss: 0.4228 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4683 - accuracy: 0.7809 - val_loss: 0.4205 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.77 - 0s 119us/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4191 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4686 - accuracy: 0.7907 - val_loss: 0.4162 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4637 - accuracy: 0.7809 - val_loss: 0.4160 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 198us/step - loss: 0.4645 - accuracy: 0.7893 - val_loss: 0.4133 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4620 - accuracy: 0.7823 - val_loss: 0.4145 - val_accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 175us/step - loss: 0.4597 - accuracy: 0.7935 - val_loss: 0.4116 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.4593 - accuracy: 0.7893 - val_loss: 0.4112 - val_accuracy: 0.7989\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4573 - accuracy: 0.7935 - val_loss: 0.4088 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4556 - accuracy: 0.7907 - val_loss: 0.4120 - val_accuracy: 0.8101\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4557 - accuracy: 0.7949 - val_loss: 0.4062 - val_accuracy: 0.8101\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4547 - accuracy: 0.7921 - val_loss: 0.4082 - val_accuracy: 0.8156\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4542 - accuracy: 0.7992 - val_loss: 0.4049 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4569 - accuracy: 0.7963 - val_loss: 0.4079 - val_accuracy: 0.8156\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4517 - accuracy: 0.7963 - val_loss: 0.4065 - val_accuracy: 0.8156\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4508 - accuracy: 0.7978 - val_loss: 0.4064 - val_accuracy: 0.8101\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4508 - accuracy: 0.7949 - val_loss: 0.4079 - val_accuracy: 0.8156\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4506 - accuracy: 0.7978 - val_loss: 0.4053 - val_accuracy: 0.8156\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4505 - accuracy: 0.7992 - val_loss: 0.4052 - val_accuracy: 0.8101\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4487 - accuracy: 0.7921 - val_loss: 0.4077 - val_accuracy: 0.8156\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4477 - accuracy: 0.8020 - val_loss: 0.4054 - val_accuracy: 0.8156\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4465 - accuracy: 0.7949 - val_loss: 0.4069 - val_accuracy: 0.8156\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4481 - accuracy: 0.7992 - val_loss: 0.4047 - val_accuracy: 0.8101\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4448 - accuracy: 0.7935 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4465 - accuracy: 0.7992 - val_loss: 0.4035 - val_accuracy: 0.8101\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.79 - 0s 116us/step - loss: 0.4429 - accuracy: 0.7992 - val_loss: 0.4054 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4435 - accuracy: 0.7949 - val_loss: 0.4035 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4438 - accuracy: 0.8034 - val_loss: 0.3998 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4424 - accuracy: 0.8062 - val_loss: 0.3995 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4389 - accuracy: 0.8104 - val_loss: 0.3999 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.4404 - accuracy: 0.8076 - val_loss: 0.4026 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4350 - accuracy: 0.8090 - val_loss: 0.3992 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4347 - accuracy: 0.8090 - val_loss: 0.3980 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.4350 - accuracy: 0.8062 - val_loss: 0.4015 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4325 - accuracy: 0.8146 - val_loss: 0.3983 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4368 - accuracy: 0.8118 - val_loss: 0.4068 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4302 - accuracy: 0.8146 - val_loss: 0.4006 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4334 - accuracy: 0.8202 - val_loss: 0.4034 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4321 - accuracy: 0.8160 - val_loss: 0.3992 - val_accuracy: 0.8045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.4303 - accuracy: 0.8174 - val_loss: 0.4007 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4306 - accuracy: 0.8146 - val_loss: 0.4000 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4308 - accuracy: 0.8202 - val_loss: 0.3971 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4288 - accuracy: 0.8216 - val_loss: 0.4027 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4321 - accuracy: 0.8104 - val_loss: 0.3990 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4282 - accuracy: 0.8188 - val_loss: 0.3996 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4258 - accuracy: 0.8202 - val_loss: 0.4025 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 199us/step - loss: 0.4276 - accuracy: 0.8244 - val_loss: 0.3963 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4283 - accuracy: 0.8188 - val_loss: 0.3975 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.4239 - accuracy: 0.8230 - val_loss: 0.4048 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4291 - accuracy: 0.8258 - val_loss: 0.3969 - val_accuracy: 0.8156\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4247 - accuracy: 0.8216 - val_loss: 0.3965 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4238 - accuracy: 0.8174 - val_loss: 0.3977 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4285 - accuracy: 0.8258 - val_loss: 0.3964 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 272us/step - loss: 0.4308 - accuracy: 0.8230 - val_loss: 0.3964 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4258 - accuracy: 0.8188 - val_loss: 0.3988 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4213 - accuracy: 0.8272 - val_loss: 0.3957 - val_accuracy: 0.8268\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4220 - accuracy: 0.8216 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4284 - accuracy: 0.8287 - val_loss: 0.3973 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4225 - accuracy: 0.8230 - val_loss: 0.3980 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4217 - accuracy: 0.8244 - val_loss: 0.3947 - val_accuracy: 0.8212\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4216 - accuracy: 0.8244 - val_loss: 0.3946 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4214 - accuracy: 0.8230 - val_loss: 0.3936 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4192 - accuracy: 0.8230 - val_loss: 0.3972 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4259 - accuracy: 0.8202 - val_loss: 0.3954 - val_accuracy: 0.8212\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4194 - accuracy: 0.8216 - val_loss: 0.3944 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4209 - accuracy: 0.8146 - val_loss: 0.4039 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4286 - accuracy: 0.8258 - val_loss: 0.3982 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4249 - accuracy: 0.8188 - val_loss: 0.3962 - val_accuracy: 0.8268\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4206 - accuracy: 0.8230 - val_loss: 0.3935 - val_accuracy: 0.8212\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4177 - accuracy: 0.8230 - val_loss: 0.3954 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4177 - accuracy: 0.8216 - val_loss: 0.3928 - val_accuracy: 0.8212\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4180 - accuracy: 0.8202 - val_loss: 0.3926 - val_accuracy: 0.8212\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4170 - accuracy: 0.8244 - val_loss: 0.3950 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4208 - accuracy: 0.8216 - val_loss: 0.4004 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4224 - accuracy: 0.8230 - val_loss: 0.3963 - val_accuracy: 0.8268\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 196us/step - loss: 0.4160 - accuracy: 0.8258 - val_loss: 0.3959 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4196 - accuracy: 0.8244 - val_loss: 0.3927 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4155 - accuracy: 0.8230 - val_loss: 0.3925 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4154 - accuracy: 0.8202 - val_loss: 0.3941 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4144 - accuracy: 0.8258 - val_loss: 0.3938 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4160 - accuracy: 0.8216 - val_loss: 0.3912 - val_accuracy: 0.8156\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.4135 - accuracy: 0.8298\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.4117 - accuracy: 0.8263\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4117 - accuracy: 0.8246\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4116 - accuracy: 0.8281\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4129 - accuracy: 0.8316\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.4099 - accuracy: 0.8263\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.83 - 0s 108us/step - loss: 0.4125 - accuracy: 0.8298\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4084 - accuracy: 0.8316\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 100us/step - loss: 0.4099 - accuracy: 0.8263\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4069 - accuracy: 0.8263\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4062 - accuracy: 0.8281\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4055 - accuracy: 0.8263\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.4064 - accuracy: 0.8316\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4054 - accuracy: 0.8281\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4055 - accuracy: 0.8281\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4057 - accuracy: 0.8281\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4047 - accuracy: 0.8228\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4056 - accuracy: 0.8351\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4049 - accuracy: 0.8298\n",
      "Epoch 20/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 53us/step - loss: 0.4060 - accuracy: 0.8316\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4044 - accuracy: 0.8281\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4027 - accuracy: 0.8351\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.4056 - accuracy: 0.8263\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4061 - accuracy: 0.8298\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4056 - accuracy: 0.8351\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4007 - accuracy: 0.8333\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4014 - accuracy: 0.8333\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.4044 - accuracy: 0.8298\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4024 - accuracy: 0.8351\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4022 - accuracy: 0.8263\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4010 - accuracy: 0.8281\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4022 - accuracy: 0.8298\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.3998 - accuracy: 0.8263\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.3996 - accuracy: 0.8333\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4000 - accuracy: 0.8281\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.4003 - accuracy: 0.8333\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 99us/step - loss: 0.3990 - accuracy: 0.8298\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.3999 - accuracy: 0.8263\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 106us/step - loss: 0.4000 - accuracy: 0.8333\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.3984 - accuracy: 0.8281\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.3985 - accuracy: 0.8281\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.3971 - accuracy: 0.8281\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.3988 - accuracy: 0.8281\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.3985 - accuracy: 0.8316\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4008 - accuracy: 0.8281\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.3974 - accuracy: 0.8316\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.3982 - accuracy: 0.8316\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.3983 - accuracy: 0.8298\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.3996 - accuracy: 0.8333\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4016 - accuracy: 0.8368\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.3999 - accuracy: 0.8316\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.3978 - accuracy: 0.8316\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.3980 - accuracy: 0.8281\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 113us/step - loss: 0.3957 - accuracy: 0.8316\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.3983 - accuracy: 0.8298\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.3993 - accuracy: 0.8298\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.3994 - accuracy: 0.8404\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 112us/step - loss: 0.3985 - accuracy: 0.8298\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.3973 - accuracy: 0.8333\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.3952 - accuracy: 0.8333\n",
      "142/142 [==============================] - 0s 47us/step\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.6624 - accuracy: 0.6166 - val_loss: 0.6496 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.78 - 0s 91us/step - loss: 0.6486 - accuracy: 0.6166 - val_loss: 0.6386 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.6437 - accuracy: 0.6166 - val_loss: 0.6277 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 311us/step - loss: 0.6274 - accuracy: 0.6250 - val_loss: 0.6064 - val_accuracy: 0.6648\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6160 - accuracy: 0.6503 - val_loss: 0.5882 - val_accuracy: 0.6872\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6018 - accuracy: 0.6728 - val_loss: 0.5692 - val_accuracy: 0.7095\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.5880 - accuracy: 0.7051 - val_loss: 0.5525 - val_accuracy: 0.7207\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.5765 - accuracy: 0.7107 - val_loss: 0.5357 - val_accuracy: 0.7374\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 177us/step - loss: 0.5651 - accuracy: 0.7191 - val_loss: 0.5216 - val_accuracy: 0.7486\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 299us/step - loss: 0.5546 - accuracy: 0.7331 - val_loss: 0.5069 - val_accuracy: 0.7709\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 229us/step - loss: 0.5454 - accuracy: 0.7416 - val_loss: 0.4980 - val_accuracy: 0.7486\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 177us/step - loss: 0.5384 - accuracy: 0.7416 - val_loss: 0.4837 - val_accuracy: 0.7598\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5276 - accuracy: 0.7388 - val_loss: 0.4726 - val_accuracy: 0.7598\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.5168 - accuracy: 0.7570 - val_loss: 0.4652 - val_accuracy: 0.7654\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 487us/step - loss: 0.5070 - accuracy: 0.7683 - val_loss: 0.4543 - val_accuracy: 0.8045\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4993 - accuracy: 0.7711 - val_loss: 0.4481 - val_accuracy: 0.8101\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4927 - accuracy: 0.7767 - val_loss: 0.4394 - val_accuracy: 0.8268\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4878 - accuracy: 0.7767 - val_loss: 0.4337 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4832 - accuracy: 0.7795 - val_loss: 0.4276 - val_accuracy: 0.8101\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4777 - accuracy: 0.7795 - val_loss: 0.4252 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 132us/step - loss: 0.4749 - accuracy: 0.7739 - val_loss: 0.4210 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 197us/step - loss: 0.4731 - accuracy: 0.7823 - val_loss: 0.4169 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 245us/step - loss: 0.4684 - accuracy: 0.7767 - val_loss: 0.4153 - val_accuracy: 0.7821\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 311us/step - loss: 0.4676 - accuracy: 0.7851 - val_loss: 0.4137 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 338us/step - loss: 0.4643 - accuracy: 0.7851 - val_loss: 0.4107 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4635 - accuracy: 0.7907 - val_loss: 0.4125 - val_accuracy: 0.7821\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 192us/step - loss: 0.4613 - accuracy: 0.7879 - val_loss: 0.4127 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 429us/step - loss: 0.4607 - accuracy: 0.7879 - val_loss: 0.4092 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 278us/step - loss: 0.4580 - accuracy: 0.7921 - val_loss: 0.4095 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4560 - accuracy: 0.7879 - val_loss: 0.4090 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.4079 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4555 - accuracy: 0.7879 - val_loss: 0.4071 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.4543 - accuracy: 0.7879 - val_loss: 0.4077 - val_accuracy: 0.8045\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4512 - accuracy: 0.7921 - val_loss: 0.4078 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.80 - 0s 215us/step - loss: 0.4516 - accuracy: 0.7893 - val_loss: 0.4052 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 165us/step - loss: 0.4504 - accuracy: 0.7949 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 304us/step - loss: 0.4480 - accuracy: 0.7949 - val_loss: 0.4049 - val_accuracy: 0.8045\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4485 - accuracy: 0.8006 - val_loss: 0.4014 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 303us/step - loss: 0.4466 - accuracy: 0.7907 - val_loss: 0.4014 - val_accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.4462 - accuracy: 0.7921 - val_loss: 0.4019 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.4464 - accuracy: 0.7921 - val_loss: 0.4034 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4461 - accuracy: 0.7935 - val_loss: 0.4011 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4436 - accuracy: 0.7963 - val_loss: 0.4014 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4451 - accuracy: 0.7992 - val_loss: 0.4022 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4430 - accuracy: 0.7978 - val_loss: 0.4028 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4468 - accuracy: 0.8034 - val_loss: 0.4010 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4429 - accuracy: 0.8034 - val_loss: 0.4029 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4400 - accuracy: 0.8062 - val_loss: 0.3995 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4397 - accuracy: 0.8048 - val_loss: 0.3995 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4402 - accuracy: 0.8034 - val_loss: 0.4011 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4389 - accuracy: 0.8048 - val_loss: 0.4019 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4423 - accuracy: 0.8048 - val_loss: 0.3987 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4408 - accuracy: 0.8104 - val_loss: 0.3985 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4386 - accuracy: 0.8076 - val_loss: 0.3974 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4397 - accuracy: 0.8076 - val_loss: 0.4002 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.4370 - accuracy: 0.8132 - val_loss: 0.3977 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4380 - accuracy: 0.8076 - val_loss: 0.3923 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4379 - accuracy: 0.8076 - val_loss: 0.3934 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4351 - accuracy: 0.8132 - val_loss: 0.3990 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4378 - accuracy: 0.8090 - val_loss: 0.3968 - val_accuracy: 0.8156\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4367 - accuracy: 0.8160 - val_loss: 0.3966 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4350 - accuracy: 0.8118 - val_loss: 0.3966 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4352 - accuracy: 0.8160 - val_loss: 0.3972 - val_accuracy: 0.8156\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4342 - accuracy: 0.8202 - val_loss: 0.3948 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4361 - accuracy: 0.8090 - val_loss: 0.4015 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4392 - accuracy: 0.8216 - val_loss: 0.3967 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.80 - 0s 125us/step - loss: 0.4332 - accuracy: 0.8174 - val_loss: 0.3974 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4332 - accuracy: 0.8118 - val_loss: 0.4006 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4340 - accuracy: 0.8216 - val_loss: 0.3991 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4333 - accuracy: 0.8104 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4327 - accuracy: 0.8244 - val_loss: 0.3992 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4350 - accuracy: 0.8090 - val_loss: 0.4028 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4331 - accuracy: 0.8174 - val_loss: 0.3970 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4321 - accuracy: 0.8216 - val_loss: 0.4011 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4326 - accuracy: 0.8160 - val_loss: 0.3986 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 153us/step - loss: 0.4310 - accuracy: 0.8230 - val_loss: 0.3961 - val_accuracy: 0.8156\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4307 - accuracy: 0.8188 - val_loss: 0.3982 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4314 - accuracy: 0.8160 - val_loss: 0.3974 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4341 - accuracy: 0.8202 - val_loss: 0.4002 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4300 - accuracy: 0.8216 - val_loss: 0.3960 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4328 - accuracy: 0.8174 - val_loss: 0.3960 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4305 - accuracy: 0.8230 - val_loss: 0.3975 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4325 - accuracy: 0.8146 - val_loss: 0.3970 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.4298 - accuracy: 0.8188 - val_loss: 0.3982 - val_accuracy: 0.8212\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 172us/step - loss: 0.4307 - accuracy: 0.8174 - val_loss: 0.3978 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4333 - accuracy: 0.8062 - val_loss: 0.4096 - val_accuracy: 0.8212\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4315 - accuracy: 0.8216 - val_loss: 0.3970 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4283 - accuracy: 0.8132 - val_loss: 0.4032 - val_accuracy: 0.8212\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 199us/step - loss: 0.4405 - accuracy: 0.8174 - val_loss: 0.4007 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4277 - accuracy: 0.8244 - val_loss: 0.3980 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4273 - accuracy: 0.8301 - val_loss: 0.3957 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4283 - accuracy: 0.8160 - val_loss: 0.3967 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 214us/step - loss: 0.4277 - accuracy: 0.8230 - val_loss: 0.3990 - val_accuracy: 0.8212\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4273 - accuracy: 0.8244 - val_loss: 0.3976 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4277 - accuracy: 0.8202 - val_loss: 0.3993 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4286 - accuracy: 0.8160 - val_loss: 0.3992 - val_accuracy: 0.8268\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4279 - accuracy: 0.8188 - val_loss: 0.3952 - val_accuracy: 0.8212\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4269 - accuracy: 0.8230 - val_loss: 0.3994 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4269 - accuracy: 0.8230 - val_loss: 0.3942 - val_accuracy: 0.8268\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4259 - accuracy: 0.8287 - val_loss: 0.3975 - val_accuracy: 0.8156\n",
      "Epoch 1/90\n",
      "569/569 [==============================] - 0s 119us/step - loss: 0.4096 - accuracy: 0.8348\n",
      "Epoch 2/90\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.4083 - accuracy: 0.8295\n",
      "Epoch 3/90\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.4080 - accuracy: 0.8313\n",
      "Epoch 4/90\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.4073 - accuracy: 0.8313\n",
      "Epoch 5/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4071 - accuracy: 0.8260\n",
      "Epoch 6/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4067 - accuracy: 0.8348\n",
      "Epoch 7/90\n",
      "569/569 [==============================] - 0s 196us/step - loss: 0.4063 - accuracy: 0.8260\n",
      "Epoch 8/90\n",
      "569/569 [==============================] - 0s 93us/step - loss: 0.4096 - accuracy: 0.8243\n",
      "Epoch 9/90\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4049 - accuracy: 0.8278\n",
      "Epoch 10/90\n",
      "569/569 [==============================] - 0s 105us/step - loss: 0.4062 - accuracy: 0.8243\n",
      "Epoch 11/90\n",
      "569/569 [==============================] - 0s 169us/step - loss: 0.4058 - accuracy: 0.8243\n",
      "Epoch 12/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4054 - accuracy: 0.8260\n",
      "Epoch 13/90\n",
      "569/569 [==============================] - 0s 115us/step - loss: 0.4072 - accuracy: 0.8295\n",
      "Epoch 14/90\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4041 - accuracy: 0.8260\n",
      "Epoch 15/90\n",
      "569/569 [==============================] - 0s 154us/step - loss: 0.4052 - accuracy: 0.8295\n",
      "Epoch 16/90\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4055 - accuracy: 0.8260\n",
      "Epoch 17/90\n",
      "569/569 [==============================] - 0s 286us/step - loss: 0.4063 - accuracy: 0.8278\n",
      "Epoch 18/90\n",
      "569/569 [==============================] - 0s 187us/step - loss: 0.4046 - accuracy: 0.8278\n",
      "Epoch 19/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4032 - accuracy: 0.8260\n",
      "Epoch 20/90\n",
      "569/569 [==============================] - 0s 121us/step - loss: 0.4037 - accuracy: 0.8243\n",
      "Epoch 21/90\n",
      "569/569 [==============================] - 0s 96us/step - loss: 0.4067 - accuracy: 0.8330\n",
      "Epoch 22/90\n",
      "569/569 [==============================] - 0s 93us/step - loss: 0.4035 - accuracy: 0.8260\n",
      "Epoch 23/90\n",
      "569/569 [==============================] - 0s 100us/step - loss: 0.4021 - accuracy: 0.8313\n",
      "Epoch 24/90\n",
      "569/569 [==============================] - 0s 92us/step - loss: 0.4049 - accuracy: 0.8278\n",
      "Epoch 25/90\n",
      "569/569 [==============================] - 0s 97us/step - loss: 0.4034 - accuracy: 0.8278\n",
      "Epoch 26/90\n",
      "569/569 [==============================] - 0s 90us/step - loss: 0.4030 - accuracy: 0.8243\n",
      "Epoch 27/90\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.4017 - accuracy: 0.8243\n",
      "Epoch 28/90\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4015 - accuracy: 0.8243\n",
      "Epoch 29/90\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4037 - accuracy: 0.8225\n",
      "Epoch 30/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4012 - accuracy: 0.8278\n",
      "Epoch 31/90\n",
      "569/569 [==============================] - 0s 91us/step - loss: 0.4006 - accuracy: 0.8348\n",
      "Epoch 32/90\n",
      "569/569 [==============================] - 0s 94us/step - loss: 0.4015 - accuracy: 0.8278\n",
      "Epoch 33/90\n",
      "569/569 [==============================] - 0s 121us/step - loss: 0.4016 - accuracy: 0.8260\n",
      "Epoch 34/90\n",
      "569/569 [==============================] - 0s 96us/step - loss: 0.4004 - accuracy: 0.8295\n",
      "Epoch 35/90\n",
      "569/569 [==============================] - 0s 117us/step - loss: 0.3995 - accuracy: 0.8295\n",
      "Epoch 36/90\n",
      "569/569 [==============================] - 0s 316us/step - loss: 0.4006 - accuracy: 0.8278\n",
      "Epoch 37/90\n",
      "569/569 [==============================] - 0s 236us/step - loss: 0.3992 - accuracy: 0.8278\n",
      "Epoch 38/90\n",
      "569/569 [==============================] - 0s 128us/step - loss: 0.4005 - accuracy: 0.8260\n",
      "Epoch 39/90\n",
      "569/569 [==============================] - 0s 157us/step - loss: 0.3981 - accuracy: 0.8278\n",
      "Epoch 40/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4007 - accuracy: 0.8243\n",
      "Epoch 41/90\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.3998 - accuracy: 0.8278\n",
      "Epoch 42/90\n",
      "569/569 [==============================] - 0s 222us/step - loss: 0.4040 - accuracy: 0.8260\n",
      "Epoch 43/90\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4018 - accuracy: 0.8330\n",
      "Epoch 44/90\n",
      "569/569 [==============================] - 0s 109us/step - loss: 0.3985 - accuracy: 0.8278\n",
      "Epoch 45/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 83us/step - loss: 0.3990 - accuracy: 0.8243\n",
      "Epoch 46/90\n",
      "569/569 [==============================] - 0s 117us/step - loss: 0.3956 - accuracy: 0.8278\n",
      "Epoch 47/90\n",
      "569/569 [==============================] - 0s 111us/step - loss: 0.3990 - accuracy: 0.8295\n",
      "Epoch 48/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.3989 - accuracy: 0.8243\n",
      "Epoch 49/90\n",
      "569/569 [==============================] - 0s 82us/step - loss: 0.3981 - accuracy: 0.8295\n",
      "Epoch 50/90\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.3974 - accuracy: 0.8243\n",
      "Epoch 51/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.3965 - accuracy: 0.8313\n",
      "Epoch 52/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.3963 - accuracy: 0.8313\n",
      "Epoch 53/90\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.3959 - accuracy: 0.8260\n",
      "Epoch 54/90\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.3956 - accuracy: 0.8348\n",
      "Epoch 55/90\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.3971 - accuracy: 0.8330\n",
      "Epoch 56/90\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.3965 - accuracy: 0.8225\n",
      "Epoch 57/90\n",
      "569/569 [==============================] - 0s 88us/step - loss: 0.3964 - accuracy: 0.8295\n",
      "Epoch 58/90\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.3938 - accuracy: 0.8295\n",
      "Epoch 59/90\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.3945 - accuracy: 0.8295\n",
      "Epoch 60/90\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.3943 - accuracy: 0.8330\n",
      "Epoch 61/90\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.3940 - accuracy: 0.8330\n",
      "Epoch 62/90\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.3932 - accuracy: 0.8295\n",
      "Epoch 63/90\n",
      "569/569 [==============================] - 0s 134us/step - loss: 0.3950 - accuracy: 0.8278\n",
      "Epoch 64/90\n",
      "569/569 [==============================] - 0s 349us/step - loss: 0.3948 - accuracy: 0.8295\n",
      "Epoch 65/90\n",
      "569/569 [==============================] - 0s 193us/step - loss: 0.3937 - accuracy: 0.8260\n",
      "Epoch 66/90\n",
      "569/569 [==============================] - 0s 231us/step - loss: 0.3928 - accuracy: 0.8313\n",
      "Epoch 67/90\n",
      "569/569 [==============================] - 0s 207us/step - loss: 0.3952 - accuracy: 0.8295\n",
      "Epoch 68/90\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.3951 - accuracy: 0.8295\n",
      "Epoch 69/90\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.3940 - accuracy: 0.8295\n",
      "Epoch 70/90\n",
      "569/569 [==============================] - 0s 97us/step - loss: 0.3928 - accuracy: 0.8295\n",
      "Epoch 71/90\n",
      "569/569 [==============================] - 0s 175us/step - loss: 0.3922 - accuracy: 0.8295\n",
      "Epoch 72/90\n",
      "569/569 [==============================] - 0s 177us/step - loss: 0.3913 - accuracy: 0.8313\n",
      "Epoch 73/90\n",
      "569/569 [==============================] - 0s 143us/step - loss: 0.3916 - accuracy: 0.8330\n",
      "Epoch 74/90\n",
      "569/569 [==============================] - 0s 178us/step - loss: 0.3930 - accuracy: 0.8330\n",
      "Epoch 75/90\n",
      "569/569 [==============================] - 0s 197us/step - loss: 0.3926 - accuracy: 0.8295\n",
      "Epoch 76/90\n",
      "569/569 [==============================] - 0s 386us/step - loss: 0.3933 - accuracy: 0.8313\n",
      "Epoch 77/90\n",
      "569/569 [==============================] - 0s 314us/step - loss: 0.3916 - accuracy: 0.8313\n",
      "Epoch 78/90\n",
      "569/569 [==============================] - 0s 207us/step - loss: 0.3911 - accuracy: 0.82780s - loss: 0.3625 - accuracy: 0.85 - ETA: 0s - loss: 0.3888 - accuracy: 0.83\n",
      "Epoch 79/90\n",
      "569/569 [==============================] - 0s 348us/step - loss: 0.3906 - accuracy: 0.8295\n",
      "Epoch 80/90\n",
      "569/569 [==============================] - 0s 231us/step - loss: 0.3933 - accuracy: 0.8295\n",
      "Epoch 81/90\n",
      "569/569 [==============================] - 0s 137us/step - loss: 0.3937 - accuracy: 0.8313\n",
      "Epoch 82/90\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.3920 - accuracy: 0.8348\n",
      "Epoch 83/90\n",
      "569/569 [==============================] - 0s 291us/step - loss: 0.3919 - accuracy: 0.8278\n",
      "Epoch 84/90\n",
      "569/569 [==============================] - 0s 537us/step - loss: 0.3916 - accuracy: 0.8330\n",
      "Epoch 85/90\n",
      "569/569 [==============================] - 0s 283us/step - loss: 0.3934 - accuracy: 0.8313\n",
      "Epoch 86/90\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.3924 - accuracy: 0.8348\n",
      "Epoch 87/90\n",
      "569/569 [==============================] - 0s 215us/step - loss: 0.3911 - accuracy: 0.8348\n",
      "Epoch 88/90\n",
      "569/569 [==============================] - 0s 151us/step - loss: 0.3891 - accuracy: 0.8330\n",
      "Epoch 89/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.3920 - accuracy: 0.8260\n",
      "Epoch 90/90\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.3913 - accuracy: 0.8243\n",
      "143/143 [==============================] - 0s 128us/step\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 815us/step - loss: 0.6833 - accuracy: 0.5478 - val_loss: 0.6652 - val_accuracy: 0.6257\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6598 - accuracy: 0.6180 - val_loss: 0.6441 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6482 - accuracy: 0.6166 - val_loss: 0.6338 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6370 - accuracy: 0.6166 - val_loss: 0.6223 - val_accuracy: 0.6201\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6277 - accuracy: 0.6264 - val_loss: 0.6091 - val_accuracy: 0.6369\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6178 - accuracy: 0.6475 - val_loss: 0.5985 - val_accuracy: 0.6648\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6064 - accuracy: 0.6601 - val_loss: 0.5845 - val_accuracy: 0.6872\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.5962 - accuracy: 0.6910 - val_loss: 0.5716 - val_accuracy: 0.7263\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5815 - accuracy: 0.6784 - val_loss: 0.5541 - val_accuracy: 0.7318\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.5653 - accuracy: 0.7219 - val_loss: 0.5288 - val_accuracy: 0.7430\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5478 - accuracy: 0.7472 - val_loss: 0.5105 - val_accuracy: 0.7430\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.5323 - accuracy: 0.7556 - val_loss: 0.4907 - val_accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.5201 - accuracy: 0.7640 - val_loss: 0.4752 - val_accuracy: 0.7989\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.5072 - accuracy: 0.7683 - val_loss: 0.4628 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4979 - accuracy: 0.7781 - val_loss: 0.4543 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4903 - accuracy: 0.7809 - val_loss: 0.4430 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4828 - accuracy: 0.7809 - val_loss: 0.4380 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4770 - accuracy: 0.7823 - val_loss: 0.4322 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4722 - accuracy: 0.7795 - val_loss: 0.4281 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.4254 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4680 - accuracy: 0.7907 - val_loss: 0.4256 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4643 - accuracy: 0.7963 - val_loss: 0.4249 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4601 - accuracy: 0.7865 - val_loss: 0.4208 - val_accuracy: 0.7821\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4605 - accuracy: 0.7879 - val_loss: 0.4192 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4556 - accuracy: 0.7907 - val_loss: 0.4177 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4531 - accuracy: 0.7921 - val_loss: 0.4150 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4519 - accuracy: 0.7893 - val_loss: 0.4134 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4526 - accuracy: 0.7907 - val_loss: 0.4126 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4492 - accuracy: 0.7978 - val_loss: 0.4105 - val_accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4487 - accuracy: 0.7963 - val_loss: 0.4094 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4475 - accuracy: 0.7935 - val_loss: 0.4092 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4460 - accuracy: 0.7978 - val_loss: 0.4072 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4454 - accuracy: 0.8006 - val_loss: 0.4096 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4432 - accuracy: 0.8020 - val_loss: 0.4082 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4428 - accuracy: 0.8062 - val_loss: 0.4118 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4409 - accuracy: 0.8048 - val_loss: 0.4045 - val_accuracy: 0.8045\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4412 - accuracy: 0.8006 - val_loss: 0.4080 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4399 - accuracy: 0.8090 - val_loss: 0.4050 - val_accuracy: 0.8045\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4448 - accuracy: 0.8048 - val_loss: 0.4102 - val_accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4379 - accuracy: 0.8104 - val_loss: 0.4045 - val_accuracy: 0.8045\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4387 - accuracy: 0.8076 - val_loss: 0.4067 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4360 - accuracy: 0.8104 - val_loss: 0.4032 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4356 - accuracy: 0.8104 - val_loss: 0.4025 - val_accuracy: 0.7989\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4364 - accuracy: 0.8090 - val_loss: 0.4038 - val_accuracy: 0.8101\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4358 - accuracy: 0.8146 - val_loss: 0.4016 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4368 - accuracy: 0.8146 - val_loss: 0.4058 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4350 - accuracy: 0.8160 - val_loss: 0.4013 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4348 - accuracy: 0.8090 - val_loss: 0.4032 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4349 - accuracy: 0.8160 - val_loss: 0.4012 - val_accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4326 - accuracy: 0.8132 - val_loss: 0.4025 - val_accuracy: 0.8156\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4331 - accuracy: 0.8188 - val_loss: 0.4004 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4318 - accuracy: 0.8174 - val_loss: 0.4004 - val_accuracy: 0.8212\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4318 - accuracy: 0.8146 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4309 - accuracy: 0.8202 - val_loss: 0.4023 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4344 - accuracy: 0.8076 - val_loss: 0.4052 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4320 - accuracy: 0.8216 - val_loss: 0.4015 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4301 - accuracy: 0.8146 - val_loss: 0.3985 - val_accuracy: 0.8156\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4305 - accuracy: 0.8188 - val_loss: 0.3981 - val_accuracy: 0.8156\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4294 - accuracy: 0.8160 - val_loss: 0.3997 - val_accuracy: 0.8212\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4292 - accuracy: 0.8174 - val_loss: 0.3984 - val_accuracy: 0.8212\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 185us/step - loss: 0.4283 - accuracy: 0.8174 - val_loss: 0.3989 - val_accuracy: 0.8212\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4300 - accuracy: 0.8188 - val_loss: 0.3975 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4287 - accuracy: 0.8188 - val_loss: 0.4017 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4286 - accuracy: 0.8202 - val_loss: 0.3987 - val_accuracy: 0.8156\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4300 - accuracy: 0.8174 - val_loss: 0.4035 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4294 - accuracy: 0.8188 - val_loss: 0.3999 - val_accuracy: 0.8212\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4272 - accuracy: 0.8174 - val_loss: 0.3970 - val_accuracy: 0.8156\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4290 - accuracy: 0.8216 - val_loss: 0.4018 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4272 - accuracy: 0.8216 - val_loss: 0.4013 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.82 - 0s 130us/step - loss: 0.4271 - accuracy: 0.8174 - val_loss: 0.3997 - val_accuracy: 0.8212\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4283 - accuracy: 0.8216 - val_loss: 0.3994 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4265 - accuracy: 0.8216 - val_loss: 0.3977 - val_accuracy: 0.8212\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4276 - accuracy: 0.8202 - val_loss: 0.3986 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4260 - accuracy: 0.8216 - val_loss: 0.3984 - val_accuracy: 0.8212\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4260 - accuracy: 0.8216 - val_loss: 0.3994 - val_accuracy: 0.8212\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4277 - accuracy: 0.8216 - val_loss: 0.3980 - val_accuracy: 0.8212\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4273 - accuracy: 0.8174 - val_loss: 0.3984 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4254 - accuracy: 0.8230 - val_loss: 0.3966 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4287 - accuracy: 0.8146 - val_loss: 0.4030 - val_accuracy: 0.8212\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4268 - accuracy: 0.8216 - val_loss: 0.3946 - val_accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4243 - accuracy: 0.8216 - val_loss: 0.4005 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4236 - accuracy: 0.8188 - val_loss: 0.3959 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4235 - accuracy: 0.8160 - val_loss: 0.3976 - val_accuracy: 0.8212\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4237 - accuracy: 0.8216 - val_loss: 0.3983 - val_accuracy: 0.8212\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4228 - accuracy: 0.8202 - val_loss: 0.3953 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4238 - accuracy: 0.8202 - val_loss: 0.3994 - val_accuracy: 0.8212\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.81 - 0s 129us/step - loss: 0.4231 - accuracy: 0.8202 - val_loss: 0.3977 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4222 - accuracy: 0.8244 - val_loss: 0.3999 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4245 - accuracy: 0.8202 - val_loss: 0.3965 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4238 - accuracy: 0.8216 - val_loss: 0.3961 - val_accuracy: 0.8212\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4229 - accuracy: 0.8244 - val_loss: 0.3962 - val_accuracy: 0.8212\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4250 - accuracy: 0.8244 - val_loss: 0.4007 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4257 - accuracy: 0.8230 - val_loss: 0.3982 - val_accuracy: 0.8268\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4241 - accuracy: 0.8118 - val_loss: 0.4032 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4248 - accuracy: 0.8258 - val_loss: 0.3967 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4219 - accuracy: 0.8216 - val_loss: 0.3973 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4219 - accuracy: 0.8216 - val_loss: 0.4019 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.4248 - accuracy: 0.8244 - val_loss: 0.3945 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.4218 - accuracy: 0.8202 - val_loss: 0.3998 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4217 - accuracy: 0.8244 - val_loss: 0.3943 - val_accuracy: 0.8156\n",
      "Epoch 1/90\n",
      "569/569 [==============================] - 0s 149us/step - loss: 0.4347 - accuracy: 0.8190\n",
      "Epoch 2/90\n",
      "569/569 [==============================] - 0s 126us/step - loss: 0.4345 - accuracy: 0.8155\n",
      "Epoch 3/90\n",
      "569/569 [==============================] - 0s 188us/step - loss: 0.4330 - accuracy: 0.8207\n",
      "Epoch 4/90\n",
      "569/569 [==============================] - 0s 118us/step - loss: 0.4348 - accuracy: 0.8225\n",
      "Epoch 5/90\n",
      "569/569 [==============================] - 0s 92us/step - loss: 0.4327 - accuracy: 0.8225\n",
      "Epoch 6/90\n",
      "569/569 [==============================] - 0s 119us/step - loss: 0.4355 - accuracy: 0.8137\n",
      "Epoch 7/90\n",
      "569/569 [==============================] - 0s 111us/step - loss: 0.4320 - accuracy: 0.8207\n",
      "Epoch 8/90\n",
      "569/569 [==============================] - 0s 148us/step - loss: 0.4324 - accuracy: 0.8207\n",
      "Epoch 9/90\n",
      "569/569 [==============================] - 0s 134us/step - loss: 0.4334 - accuracy: 0.8207\n",
      "Epoch 10/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4341 - accuracy: 0.8172\n",
      "Epoch 11/90\n",
      "569/569 [==============================] - 0s 174us/step - loss: 0.4314 - accuracy: 0.8172\n",
      "Epoch 12/90\n",
      "569/569 [==============================] - 0s 168us/step - loss: 0.4348 - accuracy: 0.8225\n",
      "Epoch 13/90\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.81 - 0s 114us/step - loss: 0.4308 - accuracy: 0.8190\n",
      "Epoch 14/90\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.4307 - accuracy: 0.8225\n",
      "Epoch 15/90\n",
      "569/569 [==============================] - 0s 144us/step - loss: 0.4324 - accuracy: 0.8172\n",
      "Epoch 16/90\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4301 - accuracy: 0.8172\n",
      "Epoch 17/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4304 - accuracy: 0.8190\n",
      "Epoch 18/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.4299 - accuracy: 0.8190\n",
      "Epoch 19/90\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4295 - accuracy: 0.8190\n",
      "Epoch 20/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4302 - accuracy: 0.8137\n",
      "Epoch 21/90\n",
      "569/569 [==============================] - 0s 160us/step - loss: 0.4303 - accuracy: 0.8190\n",
      "Epoch 22/90\n",
      "569/569 [==============================] - 0s 113us/step - loss: 0.4324 - accuracy: 0.8190\n",
      "Epoch 23/90\n",
      "569/569 [==============================] - 0s 135us/step - loss: 0.4337 - accuracy: 0.8243\n",
      "Epoch 24/90\n",
      "569/569 [==============================] - 0s 167us/step - loss: 0.4351 - accuracy: 0.8067\n",
      "Epoch 25/90\n",
      "569/569 [==============================] - 0s 98us/step - loss: 0.4321 - accuracy: 0.8260\n",
      "Epoch 26/90\n",
      "569/569 [==============================] - 0s 156us/step - loss: 0.4316 - accuracy: 0.8120\n",
      "Epoch 27/90\n",
      "569/569 [==============================] - 0s 141us/step - loss: 0.4294 - accuracy: 0.8225\n",
      "Epoch 28/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4293 - accuracy: 0.8155\n",
      "Epoch 29/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4297 - accuracy: 0.8225\n",
      "Epoch 30/90\n",
      "569/569 [==============================] - 0s 146us/step - loss: 0.4356 - accuracy: 0.8102\n",
      "Epoch 31/90\n",
      "569/569 [==============================] - 0s 108us/step - loss: 0.4332 - accuracy: 0.8260\n",
      "Epoch 32/90\n",
      "569/569 [==============================] - 0s 112us/step - loss: 0.4306 - accuracy: 0.8137\n",
      "Epoch 33/90\n",
      "569/569 [==============================] - 0s 255us/step - loss: 0.4281 - accuracy: 0.8190\n",
      "Epoch 34/90\n",
      "569/569 [==============================] - 0s 169us/step - loss: 0.4283 - accuracy: 0.8207\n",
      "Epoch 35/90\n",
      "569/569 [==============================] - 0s 202us/step - loss: 0.4278 - accuracy: 0.8155\n",
      "Epoch 36/90\n",
      "569/569 [==============================] - 0s 668us/step - loss: 0.4288 - accuracy: 0.8243\n",
      "Epoch 37/90\n",
      " 32/569 [>.............................] - ETA: 0s - loss: 0.3506 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.121339). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 385us/step - loss: 0.4287 - accuracy: 0.8084\n",
      "Epoch 38/90\n",
      "569/569 [==============================] - 0s 107us/step - loss: 0.4286 - accuracy: 0.8207\n",
      "Epoch 39/90\n",
      "569/569 [==============================] - 0s 162us/step - loss: 0.4267 - accuracy: 0.8207\n",
      "Epoch 40/90\n",
      "569/569 [==============================] - 0s 171us/step - loss: 0.4269 - accuracy: 0.8243\n",
      "Epoch 41/90\n",
      "569/569 [==============================] - 0s 161us/step - loss: 0.4276 - accuracy: 0.8172\n",
      "Epoch 42/90\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4258 - accuracy: 0.8207\n",
      "Epoch 43/90\n",
      "569/569 [==============================] - 0s 97us/step - loss: 0.4261 - accuracy: 0.8278\n",
      "Epoch 44/90\n",
      "569/569 [==============================] - 0s 96us/step - loss: 0.4271 - accuracy: 0.8172\n",
      "Epoch 45/90\n",
      "569/569 [==============================] - 0s 103us/step - loss: 0.4260 - accuracy: 0.8225\n",
      "Epoch 46/90\n",
      "569/569 [==============================] - 0s 119us/step - loss: 0.4261 - accuracy: 0.8243\n",
      "Epoch 47/90\n",
      "569/569 [==============================] - 0s 92us/step - loss: 0.4261 - accuracy: 0.8225\n",
      "Epoch 48/90\n",
      "569/569 [==============================] - 0s 111us/step - loss: 0.4250 - accuracy: 0.8172\n",
      "Epoch 49/90\n",
      "569/569 [==============================] - 0s 147us/step - loss: 0.4274 - accuracy: 0.8278\n",
      "Epoch 50/90\n",
      "569/569 [==============================] - 0s 116us/step - loss: 0.4262 - accuracy: 0.8102\n",
      "Epoch 51/90\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.4257 - accuracy: 0.8260\n",
      "Epoch 52/90\n",
      "569/569 [==============================] - 0s 130us/step - loss: 0.4262 - accuracy: 0.8155\n",
      "Epoch 53/90\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4263 - accuracy: 0.8278\n",
      "Epoch 54/90\n",
      "569/569 [==============================] - 0s 120us/step - loss: 0.4321 - accuracy: 0.8102\n",
      "Epoch 55/90\n",
      "569/569 [==============================] - 0s 101us/step - loss: 0.4278 - accuracy: 0.8260\n",
      "Epoch 56/90\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.4262 - accuracy: 0.8172\n",
      "Epoch 57/90\n",
      "569/569 [==============================] - 0s 138us/step - loss: 0.4232 - accuracy: 0.8260\n",
      "Epoch 58/90\n",
      "569/569 [==============================] - 0s 85us/step - loss: 0.4243 - accuracy: 0.8225\n",
      "Epoch 59/90\n",
      "569/569 [==============================] - 0s 85us/step - loss: 0.4280 - accuracy: 0.8225\n",
      "Epoch 60/90\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.4240 - accuracy: 0.8207\n",
      "Epoch 61/90\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.4282 - accuracy: 0.8260\n",
      "Epoch 62/90\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4239 - accuracy: 0.8243\n",
      "Epoch 63/90\n",
      "569/569 [==============================] - 0s 100us/step - loss: 0.4228 - accuracy: 0.8172\n",
      "Epoch 64/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4280 - accuracy: 0.8260\n",
      "Epoch 65/90\n",
      "569/569 [==============================] - 0s 131us/step - loss: 0.4230 - accuracy: 0.81720s - loss: 0.4286 - accuracy: 0.81\n",
      "Epoch 66/90\n",
      "569/569 [==============================] - 0s 92us/step - loss: 0.4265 - accuracy: 0.8260\n",
      "Epoch 67/90\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4254 - accuracy: 0.8137\n",
      "Epoch 68/90\n",
      "569/569 [==============================] - 0s 132us/step - loss: 0.4230 - accuracy: 0.8260\n",
      "Epoch 69/90\n",
      "569/569 [==============================] - 0s 113us/step - loss: 0.4234 - accuracy: 0.8190\n",
      "Epoch 70/90\n",
      "569/569 [==============================] - 0s 142us/step - loss: 0.4231 - accuracy: 0.8243\n",
      "Epoch 71/90\n",
      "569/569 [==============================] - 0s 82us/step - loss: 0.4222 - accuracy: 0.8190\n",
      "Epoch 72/90\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4236 - accuracy: 0.8260\n",
      "Epoch 73/90\n",
      "569/569 [==============================] - 0s 90us/step - loss: 0.4226 - accuracy: 0.8102\n",
      "Epoch 74/90\n",
      "569/569 [==============================] - 0s 90us/step - loss: 0.4212 - accuracy: 0.8243\n",
      "Epoch 75/90\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.4222 - accuracy: 0.8295\n",
      "Epoch 76/90\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4224 - accuracy: 0.8155\n",
      "Epoch 77/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4220 - accuracy: 0.8225\n",
      "Epoch 78/90\n",
      "569/569 [==============================] - 0s 88us/step - loss: 0.4218 - accuracy: 0.8278\n",
      "Epoch 79/90\n",
      "569/569 [==============================] - 0s 107us/step - loss: 0.4218 - accuracy: 0.8190\n",
      "Epoch 80/90\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.4219 - accuracy: 0.8243\n",
      "Epoch 81/90\n",
      "569/569 [==============================] - 0s 113us/step - loss: 0.4282 - accuracy: 0.8260\n",
      "Epoch 82/90\n",
      "569/569 [==============================] - 0s 87us/step - loss: 0.4222 - accuracy: 0.8084\n",
      "Epoch 83/90\n",
      "569/569 [==============================] - 0s 121us/step - loss: 0.4237 - accuracy: 0.8278\n",
      "Epoch 84/90\n",
      "569/569 [==============================] - 0s 111us/step - loss: 0.4215 - accuracy: 0.8120\n",
      "Epoch 85/90\n",
      "569/569 [==============================] - 0s 92us/step - loss: 0.4204 - accuracy: 0.8260\n",
      "Epoch 86/90\n",
      "569/569 [==============================] - 0s 109us/step - loss: 0.4229 - accuracy: 0.8190\n",
      "Epoch 87/90\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4200 - accuracy: 0.8260\n",
      "Epoch 88/90\n",
      "569/569 [==============================] - 0s 123us/step - loss: 0.4221 - accuracy: 0.8190\n",
      "Epoch 89/90\n",
      "569/569 [==============================] - 0s 116us/step - loss: 0.4202 - accuracy: 0.8225\n",
      "Epoch 90/90\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4204 - accuracy: 0.8295\n",
      "143/143 [==============================] - 0s 131us/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 959us/step - loss: 0.6669 - accuracy: 0.6166 - val_loss: 0.6575 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6469 - accuracy: 0.6166 - val_loss: 0.6337 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6323 - accuracy: 0.6166 - val_loss: 0.6179 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6211 - accuracy: 0.6166 - val_loss: 0.6043 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6103 - accuracy: 0.6180 - val_loss: 0.5917 - val_accuracy: 0.6257\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.5985 - accuracy: 0.6489 - val_loss: 0.5767 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5874 - accuracy: 0.6671 - val_loss: 0.5627 - val_accuracy: 0.7039\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.5739 - accuracy: 0.6924 - val_loss: 0.5490 - val_accuracy: 0.6927\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.5614 - accuracy: 0.7135 - val_loss: 0.5333 - val_accuracy: 0.7263\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 192us/step - loss: 0.5492 - accuracy: 0.7444 - val_loss: 0.5193 - val_accuracy: 0.7486\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.5383 - accuracy: 0.7458 - val_loss: 0.5065 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 127us/step - loss: 0.5280 - accuracy: 0.7584 - val_loss: 0.4942 - val_accuracy: 0.7765\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.5177 - accuracy: 0.7823 - val_loss: 0.4823 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5096 - accuracy: 0.7781 - val_loss: 0.4735 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4995 - accuracy: 0.7921 - val_loss: 0.4640 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4950 - accuracy: 0.7865 - val_loss: 0.4579 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 219us/step - loss: 0.4906 - accuracy: 0.7893 - val_loss: 0.4508 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4836 - accuracy: 0.7907 - val_loss: 0.4492 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4813 - accuracy: 0.7935 - val_loss: 0.4456 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4779 - accuracy: 0.7921 - val_loss: 0.4460 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4744 - accuracy: 0.7935 - val_loss: 0.4418 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 179us/step - loss: 0.4724 - accuracy: 0.7907 - val_loss: 0.4368 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4678 - accuracy: 0.7935 - val_loss: 0.4371 - val_accuracy: 0.7821\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4695 - accuracy: 0.7935 - val_loss: 0.4333 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4644 - accuracy: 0.7921 - val_loss: 0.4285 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4608 - accuracy: 0.7935 - val_loss: 0.4310 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4613 - accuracy: 0.7963 - val_loss: 0.4319 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4620 - accuracy: 0.7893 - val_loss: 0.4304 - val_accuracy: 0.7765\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 230us/step - loss: 0.4601 - accuracy: 0.7949 - val_loss: 0.4264 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 324us/step - loss: 0.4579 - accuracy: 0.7978 - val_loss: 0.4260 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 264us/step - loss: 0.4545 - accuracy: 0.7963 - val_loss: 0.4230 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.4559 - accuracy: 0.7879 - val_loss: 0.4206 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 213us/step - loss: 0.4525 - accuracy: 0.7978 - val_loss: 0.4187 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.4550 - accuracy: 0.7978 - val_loss: 0.4172 - val_accuracy: 0.7765\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 168us/step - loss: 0.4511 - accuracy: 0.7949 - val_loss: 0.4167 - val_accuracy: 0.7709\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 252us/step - loss: 0.4482 - accuracy: 0.7992 - val_loss: 0.4147 - val_accuracy: 0.7765\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.4463 - accuracy: 0.7978 - val_loss: 0.4151 - val_accuracy: 0.7765\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 200us/step - loss: 0.4452 - accuracy: 0.8020 - val_loss: 0.4139 - val_accuracy: 0.7877\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4461 - accuracy: 0.7949 - val_loss: 0.4147 - val_accuracy: 0.7877\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.4444 - accuracy: 0.8034 - val_loss: 0.4173 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4435 - accuracy: 0.8048 - val_loss: 0.4131 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 237us/step - loss: 0.4430 - accuracy: 0.8048 - val_loss: 0.4111 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 235us/step - loss: 0.4436 - accuracy: 0.8048 - val_loss: 0.4112 - val_accuracy: 0.7989\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4391 - accuracy: 0.8020 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4407 - accuracy: 0.8062 - val_loss: 0.4107 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4387 - accuracy: 0.8034 - val_loss: 0.4097 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4383 - accuracy: 0.8048 - val_loss: 0.4102 - val_accuracy: 0.8101\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4385 - accuracy: 0.8132 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4371 - accuracy: 0.8076 - val_loss: 0.4060 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 194us/step - loss: 0.4353 - accuracy: 0.8062 - val_loss: 0.4084 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4346 - accuracy: 0.8174 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4348 - accuracy: 0.8104 - val_loss: 0.4051 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4385 - accuracy: 0.8132 - val_loss: 0.4065 - val_accuracy: 0.8101\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4376 - accuracy: 0.8188 - val_loss: 0.4152 - val_accuracy: 0.8212\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4344 - accuracy: 0.8146 - val_loss: 0.4074 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4324 - accuracy: 0.8174 - val_loss: 0.4059 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4302 - accuracy: 0.8174 - val_loss: 0.4063 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4332 - accuracy: 0.8118 - val_loss: 0.4079 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4296 - accuracy: 0.8160 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4313 - accuracy: 0.8216 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4285 - accuracy: 0.8202 - val_loss: 0.4020 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4268 - accuracy: 0.8202 - val_loss: 0.4017 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4255 - accuracy: 0.8188 - val_loss: 0.4015 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4251 - accuracy: 0.8230 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4240 - accuracy: 0.8202 - val_loss: 0.4018 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4233 - accuracy: 0.8216 - val_loss: 0.4025 - val_accuracy: 0.8156\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4233 - accuracy: 0.8174 - val_loss: 0.4013 - val_accuracy: 0.8156\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 115us/step - loss: 0.4257 - accuracy: 0.8216 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4228 - accuracy: 0.8188 - val_loss: 0.4022 - val_accuracy: 0.8212\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4256 - accuracy: 0.8202 - val_loss: 0.3988 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4215 - accuracy: 0.8202 - val_loss: 0.3983 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4224 - accuracy: 0.8160 - val_loss: 0.4033 - val_accuracy: 0.8212\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4298 - accuracy: 0.8230 - val_loss: 0.4000 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4205 - accuracy: 0.8216 - val_loss: 0.3968 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4193 - accuracy: 0.8216 - val_loss: 0.3980 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4202 - accuracy: 0.8216 - val_loss: 0.3968 - val_accuracy: 0.8156\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4215 - accuracy: 0.8230 - val_loss: 0.3980 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4194 - accuracy: 0.8202 - val_loss: 0.3975 - val_accuracy: 0.8212\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4190 - accuracy: 0.8216 - val_loss: 0.3976 - val_accuracy: 0.8212\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4200 - accuracy: 0.8216 - val_loss: 0.3953 - val_accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4192 - accuracy: 0.8230 - val_loss: 0.3965 - val_accuracy: 0.8212\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4179 - accuracy: 0.8188 - val_loss: 0.4006 - val_accuracy: 0.8212\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4198 - accuracy: 0.8258 - val_loss: 0.3997 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4264 - accuracy: 0.8146 - val_loss: 0.4100 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4273 - accuracy: 0.8188 - val_loss: 0.3932 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4168 - accuracy: 0.8272 - val_loss: 0.3974 - val_accuracy: 0.8212\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4169 - accuracy: 0.8272 - val_loss: 0.3974 - val_accuracy: 0.8212\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4174 - accuracy: 0.8272 - val_loss: 0.3975 - val_accuracy: 0.8212\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4232 - accuracy: 0.8230 - val_loss: 0.4018 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4164 - accuracy: 0.8272 - val_loss: 0.3946 - val_accuracy: 0.8212\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4184 - accuracy: 0.8160 - val_loss: 0.3995 - val_accuracy: 0.8268\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4177 - accuracy: 0.8287 - val_loss: 0.3986 - val_accuracy: 0.8212\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4154 - accuracy: 0.8272 - val_loss: 0.3962 - val_accuracy: 0.8212\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4205 - accuracy: 0.8244 - val_loss: 0.3943 - val_accuracy: 0.8268\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4159 - accuracy: 0.8258 - val_loss: 0.3939 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4155 - accuracy: 0.8258 - val_loss: 0.3937 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4190 - accuracy: 0.8188 - val_loss: 0.3988 - val_accuracy: 0.8268\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4166 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8212\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4189 - accuracy: 0.8315 - val_loss: 0.3967 - val_accuracy: 0.8268\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4199 - accuracy: 0.8244 - val_loss: 0.3992 - val_accuracy: 0.8268\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 115us/step - loss: 0.4122 - accuracy: 0.8228\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.4114 - accuracy: 0.8193\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 113us/step - loss: 0.4111 - accuracy: 0.8246\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 160us/step - loss: 0.4129 - accuracy: 0.8211\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4114 - accuracy: 0.8158\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4098 - accuracy: 0.8246\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 113us/step - loss: 0.4163 - accuracy: 0.8211\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 99us/step - loss: 0.4204 - accuracy: 0.8228\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4098 - accuracy: 0.8246\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4089 - accuracy: 0.8246\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.4087 - accuracy: 0.8211\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4095 - accuracy: 0.8211\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4096 - accuracy: 0.8175\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 106us/step - loss: 0.4083 - accuracy: 0.8211\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4092 - accuracy: 0.8228\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4076 - accuracy: 0.8158\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.4084 - accuracy: 0.8281\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4076 - accuracy: 0.8158\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.81 - 0s 109us/step - loss: 0.4065 - accuracy: 0.8211\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 99us/step - loss: 0.4068 - accuracy: 0.8228\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4069 - accuracy: 0.8298\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 94us/step - loss: 0.4097 - accuracy: 0.8123\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4060 - accuracy: 0.8246\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4062 - accuracy: 0.8193\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4063 - accuracy: 0.8281\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4054 - accuracy: 0.8211\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4054 - accuracy: 0.8193\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.4052 - accuracy: 0.8228\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4047 - accuracy: 0.8281\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4069 - accuracy: 0.8228\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4048 - accuracy: 0.8333\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4067 - accuracy: 0.8193\n",
      "Epoch 33/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 82us/step - loss: 0.4036 - accuracy: 0.8263\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4042 - accuracy: 0.8211\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 100us/step - loss: 0.4045 - accuracy: 0.8298\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4043 - accuracy: 0.8246\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.4054 - accuracy: 0.8228\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4047 - accuracy: 0.8246\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4055 - accuracy: 0.8246\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4011 - accuracy: 0.8263\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4037 - accuracy: 0.8193\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4038 - accuracy: 0.8281\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4035 - accuracy: 0.8281\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4038 - accuracy: 0.8263\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 94us/step - loss: 0.4031 - accuracy: 0.8211\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 98us/step - loss: 0.4017 - accuracy: 0.8246\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4023 - accuracy: 0.8263\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4037 - accuracy: 0.8211\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.4027 - accuracy: 0.8211\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4010 - accuracy: 0.8263\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4040 - accuracy: 0.8246\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 100us/step - loss: 0.4051 - accuracy: 0.8263\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4020 - accuracy: 0.8228\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4019 - accuracy: 0.8263\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4023 - accuracy: 0.8246\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4005 - accuracy: 0.8211\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.4022 - accuracy: 0.8281\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.82 - 0s 107us/step - loss: 0.4012 - accuracy: 0.8281\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.3997 - accuracy: 0.8246\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4000 - accuracy: 0.8298\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 113us/step - loss: 0.3995 - accuracy: 0.8246\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4018 - accuracy: 0.8263\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.3980 - accuracy: 0.8263\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 107us/step - loss: 0.3996 - accuracy: 0.8211\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.3992 - accuracy: 0.8281\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4015 - accuracy: 0.8228\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4010 - accuracy: 0.8316\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 110us/step - loss: 0.3984 - accuracy: 0.8246\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4041 - accuracy: 0.8281\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.3989 - accuracy: 0.8246\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.3978 - accuracy: 0.8298\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.3986 - accuracy: 0.8246\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 100us/step - loss: 0.3978 - accuracy: 0.8281\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 121us/step - loss: 0.3972 - accuracy: 0.8228\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 121us/step - loss: 0.3974 - accuracy: 0.8281\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.3980 - accuracy: 0.8298\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.3971 - accuracy: 0.8281\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.3980 - accuracy: 0.8316\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 112us/step - loss: 0.3986 - accuracy: 0.8246\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.3999 - accuracy: 0.8281\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.3982 - accuracy: 0.8333\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 98us/step - loss: 0.3963 - accuracy: 0.8263\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.3970 - accuracy: 0.8263\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.3996 - accuracy: 0.8333\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.82 - 0s 108us/step - loss: 0.3957 - accuracy: 0.8298\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 109us/step - loss: 0.3958 - accuracy: 0.8298\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 99us/step - loss: 0.3949 - accuracy: 0.8263\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.3978 - accuracy: 0.8298\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4010 - accuracy: 0.8281\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 98us/step - loss: 0.3961 - accuracy: 0.8281\n",
      "142/142 [==============================] - 0s 79us/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 1ms/step - loss: 0.9154 - accuracy: 0.3834 - val_loss: 0.8204 - val_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.7753 - accuracy: 0.3834 - val_loss: 0.7359 - val_accuracy: 0.3855\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.7178 - accuracy: 0.3792 - val_loss: 0.6928 - val_accuracy: 0.4358\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6869 - accuracy: 0.5435 - val_loss: 0.6641 - val_accuracy: 0.6983\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6657 - accuracy: 0.6587 - val_loss: 0.6477 - val_accuracy: 0.6872\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6513 - accuracy: 0.6587 - val_loss: 0.6334 - val_accuracy: 0.6872\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6398 - accuracy: 0.6601 - val_loss: 0.6114 - val_accuracy: 0.7095\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6195 - accuracy: 0.6924 - val_loss: 0.5850 - val_accuracy: 0.7374\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 118us/step - loss: 0.5932 - accuracy: 0.7360 - val_loss: 0.5556 - val_accuracy: 0.7654\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.5637 - accuracy: 0.7711 - val_loss: 0.5292 - val_accuracy: 0.7430\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.5387 - accuracy: 0.7711 - val_loss: 0.5018 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.5142 - accuracy: 0.7767 - val_loss: 0.4763 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4967 - accuracy: 0.7879 - val_loss: 0.4618 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 173us/step - loss: 0.4849 - accuracy: 0.7907 - val_loss: 0.4534 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.4810 - accuracy: 0.7935 - val_loss: 0.4491 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4747 - accuracy: 0.7935 - val_loss: 0.4447 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4726 - accuracy: 0.7893 - val_loss: 0.4410 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4703 - accuracy: 0.7907 - val_loss: 0.4379 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4672 - accuracy: 0.7907 - val_loss: 0.4357 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4655 - accuracy: 0.7921 - val_loss: 0.4339 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4634 - accuracy: 0.7907 - val_loss: 0.4329 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4632 - accuracy: 0.7949 - val_loss: 0.4293 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.4621 - accuracy: 0.7992 - val_loss: 0.4314 - val_accuracy: 0.7821\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4605 - accuracy: 0.7963 - val_loss: 0.4263 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.4578 - accuracy: 0.7978 - val_loss: 0.4259 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4562 - accuracy: 0.7963 - val_loss: 0.4242 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4553 - accuracy: 0.7992 - val_loss: 0.4231 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4568 - accuracy: 0.7978 - val_loss: 0.4211 - val_accuracy: 0.7933\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4522 - accuracy: 0.8034 - val_loss: 0.4238 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4521 - accuracy: 0.7978 - val_loss: 0.4185 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4514 - accuracy: 0.7978 - val_loss: 0.4168 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4496 - accuracy: 0.8062 - val_loss: 0.4208 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4483 - accuracy: 0.8034 - val_loss: 0.4142 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4533 - accuracy: 0.8006 - val_loss: 0.4195 - val_accuracy: 0.7765\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4509 - accuracy: 0.8020 - val_loss: 0.4141 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4485 - accuracy: 0.8048 - val_loss: 0.4110 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4460 - accuracy: 0.8048 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4455 - accuracy: 0.8048 - val_loss: 0.4165 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4483 - accuracy: 0.8090 - val_loss: 0.4097 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4444 - accuracy: 0.7992 - val_loss: 0.4103 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4437 - accuracy: 0.8076 - val_loss: 0.4113 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4446 - accuracy: 0.8062 - val_loss: 0.4152 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4422 - accuracy: 0.8090 - val_loss: 0.4076 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4410 - accuracy: 0.8090 - val_loss: 0.4077 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4417 - accuracy: 0.8076 - val_loss: 0.4070 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4419 - accuracy: 0.8118 - val_loss: 0.4076 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4399 - accuracy: 0.8090 - val_loss: 0.4047 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4396 - accuracy: 0.8062 - val_loss: 0.4042 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4385 - accuracy: 0.8076 - val_loss: 0.4041 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4382 - accuracy: 0.8062 - val_loss: 0.4031 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4372 - accuracy: 0.8104 - val_loss: 0.4026 - val_accuracy: 0.7933\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4372 - accuracy: 0.8104 - val_loss: 0.4008 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4368 - accuracy: 0.8090 - val_loss: 0.4013 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4418 - accuracy: 0.8076 - val_loss: 0.4059 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4376 - accuracy: 0.8104 - val_loss: 0.4015 - val_accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4390 - accuracy: 0.8104 - val_loss: 0.4000 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4352 - accuracy: 0.8076 - val_loss: 0.4006 - val_accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4346 - accuracy: 0.8076 - val_loss: 0.3987 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4376 - accuracy: 0.8104 - val_loss: 0.3984 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4342 - accuracy: 0.8132 - val_loss: 0.4040 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.4329 - accuracy: 0.8104 - val_loss: 0.3966 - val_accuracy: 0.7933\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4339 - accuracy: 0.8104 - val_loss: 0.4012 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4333 - accuracy: 0.8104 - val_loss: 0.3977 - val_accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4329 - accuracy: 0.8090 - val_loss: 0.3977 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 182us/step - loss: 0.4335 - accuracy: 0.8076 - val_loss: 0.3957 - val_accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.4327 - accuracy: 0.8090 - val_loss: 0.4003 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4319 - accuracy: 0.8132 - val_loss: 0.3968 - val_accuracy: 0.7933\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4337 - accuracy: 0.8132 - val_loss: 0.3969 - val_accuracy: 0.7933\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4333 - accuracy: 0.8118 - val_loss: 0.3984 - val_accuracy: 0.7933\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4334 - accuracy: 0.8146 - val_loss: 0.3969 - val_accuracy: 0.7933\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4328 - accuracy: 0.8104 - val_loss: 0.3992 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 189us/step - loss: 0.4315 - accuracy: 0.8104 - val_loss: 0.3977 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 420us/step - loss: 0.4312 - accuracy: 0.8090 - val_loss: 0.3977 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 234us/step - loss: 0.4320 - accuracy: 0.8118 - val_loss: 0.3942 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 224us/step - loss: 0.4305 - accuracy: 0.8118 - val_loss: 0.3947 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 214us/step - loss: 0.4318 - accuracy: 0.8146 - val_loss: 0.3989 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.4350 - accuracy: 0.8076 - val_loss: 0.4048 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4323 - accuracy: 0.8188 - val_loss: 0.3941 - val_accuracy: 0.7989\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 184us/step - loss: 0.4331 - accuracy: 0.8104 - val_loss: 0.4038 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 223us/step - loss: 0.4317 - accuracy: 0.8090 - val_loss: 0.3934 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 210us/step - loss: 0.4296 - accuracy: 0.8118 - val_loss: 0.3934 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 288us/step - loss: 0.4298 - accuracy: 0.8174 - val_loss: 0.3905 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.4280 - accuracy: 0.8118 - val_loss: 0.3941 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 313us/step - loss: 0.4284 - accuracy: 0.8146 - val_loss: 0.3929 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4289 - accuracy: 0.8146 - val_loss: 0.3930 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.4276 - accuracy: 0.8118 - val_loss: 0.3934 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 190us/step - loss: 0.4283 - accuracy: 0.8132 - val_loss: 0.3908 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4318 - accuracy: 0.8104 - val_loss: 0.3919 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.82 - 0s 155us/step - loss: 0.4281 - accuracy: 0.8104 - val_loss: 0.3923 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4311 - accuracy: 0.8104 - val_loss: 0.3894 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4293 - accuracy: 0.8160 - val_loss: 0.3912 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.4271 - accuracy: 0.8118 - val_loss: 0.3940 - val_accuracy: 0.8045\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4305 - accuracy: 0.8132 - val_loss: 0.3962 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4295 - accuracy: 0.8118 - val_loss: 0.3920 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 208us/step - loss: 0.4262 - accuracy: 0.8146 - val_loss: 0.3915 - val_accuracy: 0.8045\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4265 - accuracy: 0.8118 - val_loss: 0.3926 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4296 - accuracy: 0.8174 - val_loss: 0.3891 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4260 - accuracy: 0.8104 - val_loss: 0.3929 - val_accuracy: 0.8045\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4259 - accuracy: 0.8160 - val_loss: 0.3921 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4260 - accuracy: 0.8160 - val_loss: 0.3917 - val_accuracy: 0.8045\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 111us/step - loss: 0.4244 - accuracy: 0.8123\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 107us/step - loss: 0.4254 - accuracy: 0.8140\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4232 - accuracy: 0.8140\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 130us/step - loss: 0.4237 - accuracy: 0.8140\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 200us/step - loss: 0.4231 - accuracy: 0.8158\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 200us/step - loss: 0.4241 - accuracy: 0.8158\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4227 - accuracy: 0.8175\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4219 - accuracy: 0.8193\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 119us/step - loss: 0.4210 - accuracy: 0.8175\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 103us/step - loss: 0.4221 - accuracy: 0.8158\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4209 - accuracy: 0.8158\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4211 - accuracy: 0.8158\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4223 - accuracy: 0.8158\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4206 - accuracy: 0.8175\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4212 - accuracy: 0.8158\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 169us/step - loss: 0.4206 - accuracy: 0.8175\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4202 - accuracy: 0.8175\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4211 - accuracy: 0.8211\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.4184 - accuracy: 0.8175\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4194 - accuracy: 0.8193\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4183 - accuracy: 0.8158\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4192 - accuracy: 0.8140\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 109us/step - loss: 0.4191 - accuracy: 0.8158\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.4188 - accuracy: 0.8193\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 113us/step - loss: 0.4192 - accuracy: 0.8158\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4191 - accuracy: 0.8175\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 163us/step - loss: 0.4179 - accuracy: 0.8211\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 148us/step - loss: 0.4181 - accuracy: 0.8193\n",
      "Epoch 29/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 76us/step - loss: 0.4174 - accuracy: 0.8175\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 109us/step - loss: 0.4179 - accuracy: 0.8158\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.4178 - accuracy: 0.8193\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4196 - accuracy: 0.8193\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4198 - accuracy: 0.8193\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4179 - accuracy: 0.8158\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 103us/step - loss: 0.4186 - accuracy: 0.8158\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 110us/step - loss: 0.4171 - accuracy: 0.8158\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4165 - accuracy: 0.8211\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4171 - accuracy: 0.8193\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4203 - accuracy: 0.8193\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4181 - accuracy: 0.8193\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4155 - accuracy: 0.8175\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4186 - accuracy: 0.8193\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4178 - accuracy: 0.8175\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4196 - accuracy: 0.8123\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 94us/step - loss: 0.4202 - accuracy: 0.8228\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4157 - accuracy: 0.8175\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4160 - accuracy: 0.8175\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4145 - accuracy: 0.8175\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 114us/step - loss: 0.4153 - accuracy: 0.8193\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 104us/step - loss: 0.4172 - accuracy: 0.8175\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 112us/step - loss: 0.4165 - accuracy: 0.8211\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.4151 - accuracy: 0.8175\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4149 - accuracy: 0.8175\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 104us/step - loss: 0.4139 - accuracy: 0.8175\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.4147 - accuracy: 0.82110s - loss: 0.4147 - accuracy: 0.82\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4147 - accuracy: 0.8158\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4138 - accuracy: 0.8193\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4172 - accuracy: 0.8175\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4158 - accuracy: 0.8158\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.4154 - accuracy: 0.8211\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4152 - accuracy: 0.8193\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4170 - accuracy: 0.8211\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4143 - accuracy: 0.8211\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4135 - accuracy: 0.8193\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4132 - accuracy: 0.8158\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.4135 - accuracy: 0.8193\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4122 - accuracy: 0.8211\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4126 - accuracy: 0.8193\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4116 - accuracy: 0.8175\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.4143 - accuracy: 0.8175\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4127 - accuracy: 0.8175\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.4128 - accuracy: 0.8193\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4123 - accuracy: 0.8175\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4137 - accuracy: 0.8193\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 104us/step - loss: 0.4123 - accuracy: 0.8175\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 111us/step - loss: 0.4122 - accuracy: 0.8158\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 103us/step - loss: 0.4118 - accuracy: 0.8175\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4126 - accuracy: 0.8175\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4166 - accuracy: 0.8193\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4111 - accuracy: 0.8193\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 182us/step - loss: 0.4099 - accuracy: 0.8175\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4135 - accuracy: 0.8193\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4101 - accuracy: 0.8175\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.4101 - accuracy: 0.8193\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 104us/step - loss: 0.4109 - accuracy: 0.8228\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4117 - accuracy: 0.8193\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4150 - accuracy: 0.8193\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4158 - accuracy: 0.8175\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 112us/step - loss: 0.4123 - accuracy: 0.8246\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 107us/step - loss: 0.4117 - accuracy: 0.8158\n",
      "142/142 [==============================] - 0s 115us/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_159 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 864us/step - loss: 0.6386 - accuracy: 0.6419 - val_loss: 0.6180 - val_accuracy: 0.6704\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6097 - accuracy: 0.6784 - val_loss: 0.5886 - val_accuracy: 0.7151\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5846 - accuracy: 0.7135 - val_loss: 0.5571 - val_accuracy: 0.7207\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5597 - accuracy: 0.7528 - val_loss: 0.5262 - val_accuracy: 0.7598\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5361 - accuracy: 0.7640 - val_loss: 0.4990 - val_accuracy: 0.7821\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.5170 - accuracy: 0.7809 - val_loss: 0.4816 - val_accuracy: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.5072 - accuracy: 0.7823 - val_loss: 0.4691 - val_accuracy: 0.7821\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4964 - accuracy: 0.7851 - val_loss: 0.4614 - val_accuracy: 0.7877\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4909 - accuracy: 0.7837 - val_loss: 0.4518 - val_accuracy: 0.7821\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4860 - accuracy: 0.7851 - val_loss: 0.4513 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4838 - accuracy: 0.7851 - val_loss: 0.4447 - val_accuracy: 0.7765\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4788 - accuracy: 0.7865 - val_loss: 0.4433 - val_accuracy: 0.7765\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4768 - accuracy: 0.7865 - val_loss: 0.4405 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4759 - accuracy: 0.7879 - val_loss: 0.4363 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 241us/step - loss: 0.4726 - accuracy: 0.7823 - val_loss: 0.4341 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 306us/step - loss: 0.4772 - accuracy: 0.7907 - val_loss: 0.4353 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 372us/step - loss: 0.4702 - accuracy: 0.7851 - val_loss: 0.4294 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4684 - accuracy: 0.7921 - val_loss: 0.4266 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4662 - accuracy: 0.7893 - val_loss: 0.4243 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4664 - accuracy: 0.7921 - val_loss: 0.4250 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4660 - accuracy: 0.7921 - val_loss: 0.4238 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4661 - accuracy: 0.7907 - val_loss: 0.4223 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.79 - 0s 122us/step - loss: 0.4613 - accuracy: 0.7921 - val_loss: 0.4222 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4606 - accuracy: 0.7921 - val_loss: 0.4205 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4602 - accuracy: 0.7921 - val_loss: 0.4214 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4600 - accuracy: 0.7949 - val_loss: 0.4177 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4597 - accuracy: 0.7907 - val_loss: 0.4212 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4566 - accuracy: 0.7907 - val_loss: 0.4202 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4551 - accuracy: 0.7949 - val_loss: 0.4213 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4570 - accuracy: 0.7992 - val_loss: 0.4168 - val_accuracy: 0.7709\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4551 - accuracy: 0.7949 - val_loss: 0.4127 - val_accuracy: 0.7821\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4558 - accuracy: 0.7921 - val_loss: 0.4149 - val_accuracy: 0.7877\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4530 - accuracy: 0.7992 - val_loss: 0.4185 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4556 - accuracy: 0.7963 - val_loss: 0.4126 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4525 - accuracy: 0.7949 - val_loss: 0.4114 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.4496 - accuracy: 0.8020 - val_loss: 0.4141 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4491 - accuracy: 0.8020 - val_loss: 0.4101 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4512 - accuracy: 0.7978 - val_loss: 0.4061 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.4502 - accuracy: 0.7992 - val_loss: 0.4089 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.4528 - accuracy: 0.8006 - val_loss: 0.4109 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4454 - accuracy: 0.8076 - val_loss: 0.4083 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4448 - accuracy: 0.8090 - val_loss: 0.4079 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4434 - accuracy: 0.8090 - val_loss: 0.4076 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4428 - accuracy: 0.8062 - val_loss: 0.4014 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4428 - accuracy: 0.8104 - val_loss: 0.4053 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4402 - accuracy: 0.8090 - val_loss: 0.4031 - val_accuracy: 0.7877\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4400 - accuracy: 0.8132 - val_loss: 0.4029 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4366 - accuracy: 0.8146 - val_loss: 0.3994 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4376 - accuracy: 0.8174 - val_loss: 0.3979 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4375 - accuracy: 0.8160 - val_loss: 0.4005 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4375 - accuracy: 0.8090 - val_loss: 0.3989 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4347 - accuracy: 0.8174 - val_loss: 0.4005 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4342 - accuracy: 0.8202 - val_loss: 0.3978 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4324 - accuracy: 0.8188 - val_loss: 0.3984 - val_accuracy: 0.8045\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4324 - accuracy: 0.8188 - val_loss: 0.3925 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4317 - accuracy: 0.8216 - val_loss: 0.3942 - val_accuracy: 0.8156\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4312 - accuracy: 0.8202 - val_loss: 0.3933 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4304 - accuracy: 0.8230 - val_loss: 0.3937 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4290 - accuracy: 0.8244 - val_loss: 0.3922 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.4262 - accuracy: 0.8202 - val_loss: 0.3938 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4297 - accuracy: 0.8244 - val_loss: 0.3938 - val_accuracy: 0.8101\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4245 - accuracy: 0.8160 - val_loss: 0.3916 - val_accuracy: 0.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4240 - accuracy: 0.8244 - val_loss: 0.3918 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4251 - accuracy: 0.8258 - val_loss: 0.3929 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 230us/step - loss: 0.4266 - accuracy: 0.8216 - val_loss: 0.3934 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 246us/step - loss: 0.4235 - accuracy: 0.8258 - val_loss: 0.3914 - val_accuracy: 0.8156\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 196us/step - loss: 0.4223 - accuracy: 0.8272 - val_loss: 0.3923 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4214 - accuracy: 0.8258 - val_loss: 0.3912 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4245 - accuracy: 0.8272 - val_loss: 0.3961 - val_accuracy: 0.8156\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4285 - accuracy: 0.8258 - val_loss: 0.3985 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4223 - accuracy: 0.8216 - val_loss: 0.3869 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.4202 - accuracy: 0.8258 - val_loss: 0.3870 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4196 - accuracy: 0.8174 - val_loss: 0.3909 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4206 - accuracy: 0.8258 - val_loss: 0.3869 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4181 - accuracy: 0.8244 - val_loss: 0.3899 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 190us/step - loss: 0.4163 - accuracy: 0.8272 - val_loss: 0.3889 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4210 - accuracy: 0.8230 - val_loss: 0.3940 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.4206 - accuracy: 0.8287 - val_loss: 0.3853 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.4165 - accuracy: 0.8244 - val_loss: 0.3857 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4213 - accuracy: 0.8230 - val_loss: 0.3853 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4169 - accuracy: 0.8244 - val_loss: 0.3866 - val_accuracy: 0.8212\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4151 - accuracy: 0.8244 - val_loss: 0.3858 - val_accuracy: 0.8212\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4158 - accuracy: 0.8272 - val_loss: 0.3854 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4186 - accuracy: 0.8202 - val_loss: 0.3869 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4152 - accuracy: 0.8258 - val_loss: 0.3883 - val_accuracy: 0.8212\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4136 - accuracy: 0.8258 - val_loss: 0.3836 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4153 - accuracy: 0.8244 - val_loss: 0.3856 - val_accuracy: 0.8212\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4152 - accuracy: 0.8244 - val_loss: 0.3862 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4134 - accuracy: 0.8258 - val_loss: 0.3879 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4133 - accuracy: 0.8258 - val_loss: 0.3860 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4131 - accuracy: 0.8258 - val_loss: 0.3874 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 172us/step - loss: 0.4135 - accuracy: 0.8287 - val_loss: 0.3928 - val_accuracy: 0.8268\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4114 - accuracy: 0.8258 - val_loss: 0.3847 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4111 - accuracy: 0.8244 - val_loss: 0.3867 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.4142 - accuracy: 0.8230 - val_loss: 0.3861 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.4111 - accuracy: 0.8244 - val_loss: 0.3846 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4123 - accuracy: 0.8301 - val_loss: 0.3892 - val_accuracy: 0.8268\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4116 - accuracy: 0.8244 - val_loss: 0.3861 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4158 - accuracy: 0.8272 - val_loss: 0.3918 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4131 - accuracy: 0.8230 - val_loss: 0.3945 - val_accuracy: 0.8268\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 117us/step - loss: 0.4085 - accuracy: 0.8368\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 119us/step - loss: 0.4105 - accuracy: 0.8316\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 118us/step - loss: 0.4107 - accuracy: 0.8333\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 161us/step - loss: 0.4080 - accuracy: 0.8351\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4069 - accuracy: 0.8333\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 123us/step - loss: 0.4067 - accuracy: 0.8351\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.4053 - accuracy: 0.8351\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 126us/step - loss: 0.4044 - accuracy: 0.8333\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 100us/step - loss: 0.4043 - accuracy: 0.8316\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 170us/step - loss: 0.4030 - accuracy: 0.8351\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 239us/step - loss: 0.4040 - accuracy: 0.8351\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 417us/step - loss: 0.4036 - accuracy: 0.8351\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 203us/step - loss: 0.4025 - accuracy: 0.8368\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 262us/step - loss: 0.4050 - accuracy: 0.8404\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 234us/step - loss: 0.4034 - accuracy: 0.8351\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 168us/step - loss: 0.4034 - accuracy: 0.8351\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 103us/step - loss: 0.4063 - accuracy: 0.8316\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 102us/step - loss: 0.4056 - accuracy: 0.8368\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 104us/step - loss: 0.4029 - accuracy: 0.8404\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.4014 - accuracy: 0.8333\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 111us/step - loss: 0.4033 - accuracy: 0.8351\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.4014 - accuracy: 0.8316\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 94us/step - loss: 0.3994 - accuracy: 0.8386\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.4020 - accuracy: 0.8333\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.4019 - accuracy: 0.8368\n",
      "Epoch 26/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 82us/step - loss: 0.4050 - accuracy: 0.8281\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 92us/step - loss: 0.4011 - accuracy: 0.8351\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 127us/step - loss: 0.4004 - accuracy: 0.8333\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.3981 - accuracy: 0.8351\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.3991 - accuracy: 0.8368\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.3981 - accuracy: 0.8368\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.4023 - accuracy: 0.8281\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.3983 - accuracy: 0.8404\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.3980 - accuracy: 0.8333\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.3987 - accuracy: 0.8333\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.3987 - accuracy: 0.8368\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.3983 - accuracy: 0.8368\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.3993 - accuracy: 0.8351\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.3992 - accuracy: 0.8333\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.3974 - accuracy: 0.8333\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.3961 - accuracy: 0.8333\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.3977 - accuracy: 0.8351\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 118us/step - loss: 0.4012 - accuracy: 0.8333\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.3955 - accuracy: 0.8368\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 122us/step - loss: 0.3978 - accuracy: 0.8351\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 121us/step - loss: 0.3962 - accuracy: 0.8316\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 128us/step - loss: 0.3960 - accuracy: 0.8368\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.3958 - accuracy: 0.8333\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 110us/step - loss: 0.3985 - accuracy: 0.8351\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 97us/step - loss: 0.3972 - accuracy: 0.8316\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 124us/step - loss: 0.3959 - accuracy: 0.8333\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.3969 - accuracy: 0.8351\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.3957 - accuracy: 0.8351\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.87 - 0s 74us/step - loss: 0.3966 - accuracy: 0.8298\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.3989 - accuracy: 0.8351\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.3963 - accuracy: 0.8333\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.3946 - accuracy: 0.8298\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.3949 - accuracy: 0.8316\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.3944 - accuracy: 0.8333\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.3958 - accuracy: 0.8316\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.3949 - accuracy: 0.8316\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.3973 - accuracy: 0.8298\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.3949 - accuracy: 0.8263\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.3946 - accuracy: 0.8333\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.3949 - accuracy: 0.8333\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 166us/step - loss: 0.3973 - accuracy: 0.8281\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 147us/step - loss: 0.3981 - accuracy: 0.8298\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.3961 - accuracy: 0.8351\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 158us/step - loss: 0.3930 - accuracy: 0.8316\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.3941 - accuracy: 0.8316\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 90us/step - loss: 0.3955 - accuracy: 0.8351\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.3929 - accuracy: 0.8298\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.3932 - accuracy: 0.8386\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 98us/step - loss: 0.3927 - accuracy: 0.8333\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 96us/step - loss: 0.3928 - accuracy: 0.8316\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 146us/step - loss: 0.3922 - accuracy: 0.83680s - loss: 0.3997 - accuracy: 0.82\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 145us/step - loss: 0.3933 - accuracy: 0.8333\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 102us/step - loss: 0.3919 - accuracy: 0.8316\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.3909 - accuracy: 0.8351\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 89us/step - loss: 0.3923 - accuracy: 0.8333\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.3939 - accuracy: 0.8351\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 116us/step - loss: 0.3905 - accuracy: 0.8316\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 93us/step - loss: 0.3918 - accuracy: 0.8316\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 95us/step - loss: 0.3931 - accuracy: 0.8351\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.3918 - accuracy: 0.8298\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.3941 - accuracy: 0.8263\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.3890 - accuracy: 0.8351\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.3917 - accuracy: 0.8316\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.3909 - accuracy: 0.8281\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 131us/step - loss: 0.3919 - accuracy: 0.8368\n",
      "142/142 [==============================] - 0s 64us/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_163 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 926us/step - loss: 0.6902 - accuracy: 0.5590 - val_loss: 0.6856 - val_accuracy: 0.6313\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 199us/step - loss: 0.6759 - accuracy: 0.6250 - val_loss: 0.6754 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6667 - accuracy: 0.6180 - val_loss: 0.6658 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 116us/step - loss: 0.6567 - accuracy: 0.6166 - val_loss: 0.6564 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6479 - accuracy: 0.6166 - val_loss: 0.6451 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6336 - accuracy: 0.6320 - val_loss: 0.6206 - val_accuracy: 0.6704\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6153 - accuracy: 0.6601 - val_loss: 0.5994 - val_accuracy: 0.7039\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.5953 - accuracy: 0.6812 - val_loss: 0.5773 - val_accuracy: 0.7207\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5761 - accuracy: 0.7163 - val_loss: 0.5540 - val_accuracy: 0.7263\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.5546 - accuracy: 0.7486 - val_loss: 0.5284 - val_accuracy: 0.7486\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.5365 - accuracy: 0.7612 - val_loss: 0.5075 - val_accuracy: 0.7598\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.5175 - accuracy: 0.7865 - val_loss: 0.4889 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.5036 - accuracy: 0.7837 - val_loss: 0.4765 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4975 - accuracy: 0.7907 - val_loss: 0.4695 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4891 - accuracy: 0.7963 - val_loss: 0.4627 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4843 - accuracy: 0.7921 - val_loss: 0.4571 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4805 - accuracy: 0.7921 - val_loss: 0.4532 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4774 - accuracy: 0.7907 - val_loss: 0.4490 - val_accuracy: 0.7765\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4773 - accuracy: 0.7907 - val_loss: 0.4469 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4754 - accuracy: 0.7907 - val_loss: 0.4466 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.4732 - accuracy: 0.7921 - val_loss: 0.4460 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4716 - accuracy: 0.7907 - val_loss: 0.4419 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4725 - accuracy: 0.7879 - val_loss: 0.4405 - val_accuracy: 0.7821\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4694 - accuracy: 0.7921 - val_loss: 0.4413 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4679 - accuracy: 0.7921 - val_loss: 0.4397 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4660 - accuracy: 0.7907 - val_loss: 0.4380 - val_accuracy: 0.7821\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4653 - accuracy: 0.7921 - val_loss: 0.4386 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4648 - accuracy: 0.7907 - val_loss: 0.4376 - val_accuracy: 0.7821\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4689 - accuracy: 0.7935 - val_loss: 0.4364 - val_accuracy: 0.7821\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4641 - accuracy: 0.7907 - val_loss: 0.4359 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4617 - accuracy: 0.7921 - val_loss: 0.4359 - val_accuracy: 0.7821\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4602 - accuracy: 0.7921 - val_loss: 0.4359 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4605 - accuracy: 0.7907 - val_loss: 0.4349 - val_accuracy: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4615 - accuracy: 0.7978 - val_loss: 0.4340 - val_accuracy: 0.7821\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4580 - accuracy: 0.7921 - val_loss: 0.4316 - val_accuracy: 0.7821\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4599 - accuracy: 0.7963 - val_loss: 0.4305 - val_accuracy: 0.7765\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4578 - accuracy: 0.7949 - val_loss: 0.4310 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4569 - accuracy: 0.7935 - val_loss: 0.4286 - val_accuracy: 0.7765\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 165us/step - loss: 0.4548 - accuracy: 0.7963 - val_loss: 0.4279 - val_accuracy: 0.7765\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4553 - accuracy: 0.7992 - val_loss: 0.4264 - val_accuracy: 0.7765\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4538 - accuracy: 0.7907 - val_loss: 0.4244 - val_accuracy: 0.7821\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4514 - accuracy: 0.7949 - val_loss: 0.4233 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4481 - accuracy: 0.8034 - val_loss: 0.4208 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4491 - accuracy: 0.8006 - val_loss: 0.4179 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4453 - accuracy: 0.8006 - val_loss: 0.4178 - val_accuracy: 0.7877\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.4426 - accuracy: 0.8048 - val_loss: 0.4152 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4437 - accuracy: 0.8034 - val_loss: 0.4131 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4420 - accuracy: 0.8076 - val_loss: 0.4150 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4472 - accuracy: 0.8090 - val_loss: 0.4139 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4408 - accuracy: 0.8090 - val_loss: 0.4109 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.4416 - accuracy: 0.8090 - val_loss: 0.4096 - val_accuracy: 0.7933\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4402 - accuracy: 0.8118 - val_loss: 0.4096 - val_accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4392 - accuracy: 0.8104 - val_loss: 0.4093 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4383 - accuracy: 0.8118 - val_loss: 0.4065 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4367 - accuracy: 0.8132 - val_loss: 0.4058 - val_accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 204us/step - loss: 0.4373 - accuracy: 0.8104 - val_loss: 0.4062 - val_accuracy: 0.7933\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 181us/step - loss: 0.4376 - accuracy: 0.8090 - val_loss: 0.4058 - val_accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4353 - accuracy: 0.8132 - val_loss: 0.4059 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4390 - accuracy: 0.8104 - val_loss: 0.4047 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 126us/step - loss: 0.4386 - accuracy: 0.8118 - val_loss: 0.4074 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4341 - accuracy: 0.8160 - val_loss: 0.4027 - val_accuracy: 0.7933\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4348 - accuracy: 0.8160 - val_loss: 0.4009 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4360 - accuracy: 0.8146 - val_loss: 0.4021 - val_accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4343 - accuracy: 0.8146 - val_loss: 0.4005 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4323 - accuracy: 0.8146 - val_loss: 0.3997 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4318 - accuracy: 0.8146 - val_loss: 0.3992 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4327 - accuracy: 0.8146 - val_loss: 0.3977 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4326 - accuracy: 0.8104 - val_loss: 0.3992 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4309 - accuracy: 0.8146 - val_loss: 0.3982 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4318 - accuracy: 0.8132 - val_loss: 0.3991 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4318 - accuracy: 0.8132 - val_loss: 0.3988 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4325 - accuracy: 0.8146 - val_loss: 0.3969 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4294 - accuracy: 0.8146 - val_loss: 0.3975 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4298 - accuracy: 0.8160 - val_loss: 0.3975 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4296 - accuracy: 0.8146 - val_loss: 0.3978 - val_accuracy: 0.8212\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4282 - accuracy: 0.8160 - val_loss: 0.3950 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4286 - accuracy: 0.8146 - val_loss: 0.3982 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4295 - accuracy: 0.8146 - val_loss: 0.3966 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4269 - accuracy: 0.8160 - val_loss: 0.3964 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4275 - accuracy: 0.8174 - val_loss: 0.3944 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4276 - accuracy: 0.8146 - val_loss: 0.3930 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4271 - accuracy: 0.8160 - val_loss: 0.3936 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4265 - accuracy: 0.8174 - val_loss: 0.3925 - val_accuracy: 0.8156\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4258 - accuracy: 0.8160 - val_loss: 0.3934 - val_accuracy: 0.8212\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4279 - accuracy: 0.8188 - val_loss: 0.3947 - val_accuracy: 0.8212\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4259 - accuracy: 0.8174 - val_loss: 0.3929 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4272 - accuracy: 0.8160 - val_loss: 0.3944 - val_accuracy: 0.8212\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4278 - accuracy: 0.8202 - val_loss: 0.3936 - val_accuracy: 0.7989\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4260 - accuracy: 0.8160 - val_loss: 0.3946 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4246 - accuracy: 0.8160 - val_loss: 0.3940 - val_accuracy: 0.8212\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4258 - accuracy: 0.8174 - val_loss: 0.3939 - val_accuracy: 0.8212\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.4249 - accuracy: 0.8202 - val_loss: 0.3924 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4244 - accuracy: 0.8188 - val_loss: 0.3937 - val_accuracy: 0.8212\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4247 - accuracy: 0.8160 - val_loss: 0.3918 - val_accuracy: 0.8212\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4248 - accuracy: 0.8188 - val_loss: 0.3918 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4258 - accuracy: 0.8188 - val_loss: 0.3897 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4313 - accuracy: 0.8118 - val_loss: 0.3950 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4246 - accuracy: 0.8160 - val_loss: 0.3919 - val_accuracy: 0.8212\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4249 - accuracy: 0.8188 - val_loss: 0.3935 - val_accuracy: 0.8212\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4246 - accuracy: 0.8244 - val_loss: 0.3930 - val_accuracy: 0.8212\n",
      "Epoch 1/30\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4091 - accuracy: 0.8225\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4089 - accuracy: 0.8225\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4092 - accuracy: 0.8260\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4080 - accuracy: 0.8278\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4080 - accuracy: 0.8243\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4080 - accuracy: 0.8243\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4072 - accuracy: 0.8243\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4088 - accuracy: 0.8243\n",
      "Epoch 9/30\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4088 - accuracy: 0.8225\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4088 - accuracy: 0.8243\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4074 - accuracy: 0.8260\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4068 - accuracy: 0.8243\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4078 - accuracy: 0.8243\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4081 - accuracy: 0.8243\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4065 - accuracy: 0.8260\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4062 - accuracy: 0.8225\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4064 - accuracy: 0.8225\n",
      "Epoch 18/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4061 - accuracy: 0.8207\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4055 - accuracy: 0.8260\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4067 - accuracy: 0.8260\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4063 - accuracy: 0.8225\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4066 - accuracy: 0.8278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4053 - accuracy: 0.8260\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4048 - accuracy: 0.8207\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4057 - accuracy: 0.8190\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4051 - accuracy: 0.8207\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4048 - accuracy: 0.8207\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4049 - accuracy: 0.8260\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 43us/step - loss: 0.4048 - accuracy: 0.8207\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4045 - accuracy: 0.8207\n",
      "143/143 [==============================] - 0s 40us/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_167 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 534us/step - loss: 0.9358 - accuracy: 0.3834 - val_loss: 0.8200 - val_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.7716 - accuracy: 0.3933 - val_loss: 0.7104 - val_accuracy: 0.4358\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6862 - accuracy: 0.5688 - val_loss: 0.6670 - val_accuracy: 0.7095\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6637 - accuracy: 0.6896 - val_loss: 0.6545 - val_accuracy: 0.7542\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6543 - accuracy: 0.7360 - val_loss: 0.6442 - val_accuracy: 0.7598\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 277us/step - loss: 0.6424 - accuracy: 0.7542 - val_loss: 0.6285 - val_accuracy: 0.7542\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6267 - accuracy: 0.7612 - val_loss: 0.6068 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.6066 - accuracy: 0.7865 - val_loss: 0.5853 - val_accuracy: 0.7765\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.78 - 0s 154us/step - loss: 0.5872 - accuracy: 0.7865 - val_loss: 0.5642 - val_accuracy: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 227us/step - loss: 0.5666 - accuracy: 0.7879 - val_loss: 0.5424 - val_accuracy: 0.7877\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.5487 - accuracy: 0.7851 - val_loss: 0.5195 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.5345 - accuracy: 0.7879 - val_loss: 0.5024 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.5164 - accuracy: 0.7851 - val_loss: 0.4836 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.5034 - accuracy: 0.7893 - val_loss: 0.4689 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4963 - accuracy: 0.7879 - val_loss: 0.4599 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4891 - accuracy: 0.7837 - val_loss: 0.4513 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4858 - accuracy: 0.7809 - val_loss: 0.4474 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4810 - accuracy: 0.7823 - val_loss: 0.4459 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4789 - accuracy: 0.7865 - val_loss: 0.4400 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4770 - accuracy: 0.7823 - val_loss: 0.4392 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4773 - accuracy: 0.7851 - val_loss: 0.4355 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4716 - accuracy: 0.7823 - val_loss: 0.4365 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.4314 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4721 - accuracy: 0.7879 - val_loss: 0.4300 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4675 - accuracy: 0.7879 - val_loss: 0.4276 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.4262 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4651 - accuracy: 0.7978 - val_loss: 0.4259 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4644 - accuracy: 0.7837 - val_loss: 0.4261 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4612 - accuracy: 0.7921 - val_loss: 0.4218 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4596 - accuracy: 0.7893 - val_loss: 0.4191 - val_accuracy: 0.8045\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4594 - accuracy: 0.7963 - val_loss: 0.4212 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4573 - accuracy: 0.7893 - val_loss: 0.4214 - val_accuracy: 0.8101\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4577 - accuracy: 0.7963 - val_loss: 0.4193 - val_accuracy: 0.8101\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4574 - accuracy: 0.7935 - val_loss: 0.4207 - val_accuracy: 0.8101\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4554 - accuracy: 0.7907 - val_loss: 0.4202 - val_accuracy: 0.8101\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4536 - accuracy: 0.7949 - val_loss: 0.4206 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4560 - accuracy: 0.7978 - val_loss: 0.4224 - val_accuracy: 0.8101\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4501 - accuracy: 0.7949 - val_loss: 0.4159 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4494 - accuracy: 0.7921 - val_loss: 0.4161 - val_accuracy: 0.8101\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4521 - accuracy: 0.7978 - val_loss: 0.4161 - val_accuracy: 0.8101\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4507 - accuracy: 0.7935 - val_loss: 0.4146 - val_accuracy: 0.8101\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4529 - accuracy: 0.8020 - val_loss: 0.4129 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4554 - accuracy: 0.7949 - val_loss: 0.4137 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4484 - accuracy: 0.8062 - val_loss: 0.4141 - val_accuracy: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4457 - accuracy: 0.8034 - val_loss: 0.4081 - val_accuracy: 0.8101\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4470 - accuracy: 0.8034 - val_loss: 0.4096 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4444 - accuracy: 0.8076 - val_loss: 0.4088 - val_accuracy: 0.8156\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4426 - accuracy: 0.8076 - val_loss: 0.4064 - val_accuracy: 0.8101\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4395 - accuracy: 0.8146 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4407 - accuracy: 0.8104 - val_loss: 0.4065 - val_accuracy: 0.8156\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4389 - accuracy: 0.8146 - val_loss: 0.4039 - val_accuracy: 0.8212\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4392 - accuracy: 0.8062 - val_loss: 0.4031 - val_accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4422 - accuracy: 0.8090 - val_loss: 0.4034 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4394 - accuracy: 0.8076 - val_loss: 0.4039 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4378 - accuracy: 0.8160 - val_loss: 0.4042 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4358 - accuracy: 0.8174 - val_loss: 0.4041 - val_accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4362 - accuracy: 0.8132 - val_loss: 0.4021 - val_accuracy: 0.8212\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4356 - accuracy: 0.8146 - val_loss: 0.4005 - val_accuracy: 0.8212\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4379 - accuracy: 0.8132 - val_loss: 0.3978 - val_accuracy: 0.8212\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4343 - accuracy: 0.8216 - val_loss: 0.4033 - val_accuracy: 0.8212\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4349 - accuracy: 0.8188 - val_loss: 0.4020 - val_accuracy: 0.8212\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4328 - accuracy: 0.8188 - val_loss: 0.4006 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4375 - accuracy: 0.8076 - val_loss: 0.4033 - val_accuracy: 0.8156\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4338 - accuracy: 0.8160 - val_loss: 0.4025 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4347 - accuracy: 0.8202 - val_loss: 0.4012 - val_accuracy: 0.8212\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4317 - accuracy: 0.8146 - val_loss: 0.3992 - val_accuracy: 0.8212\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4347 - accuracy: 0.8174 - val_loss: 0.4024 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4370 - accuracy: 0.8118 - val_loss: 0.4006 - val_accuracy: 0.8212\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4305 - accuracy: 0.8202 - val_loss: 0.3968 - val_accuracy: 0.8212\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4303 - accuracy: 0.8160 - val_loss: 0.3983 - val_accuracy: 0.8212\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4286 - accuracy: 0.8202 - val_loss: 0.4009 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4305 - accuracy: 0.8174 - val_loss: 0.3982 - val_accuracy: 0.8212\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4286 - accuracy: 0.8216 - val_loss: 0.3998 - val_accuracy: 0.8212\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 190us/step - loss: 0.4281 - accuracy: 0.8216 - val_loss: 0.3970 - val_accuracy: 0.8212\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4295 - accuracy: 0.8188 - val_loss: 0.3976 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4291 - accuracy: 0.8244 - val_loss: 0.3975 - val_accuracy: 0.8212\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4288 - accuracy: 0.8202 - val_loss: 0.3988 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4290 - accuracy: 0.8174 - val_loss: 0.3981 - val_accuracy: 0.8268\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4295 - accuracy: 0.8188 - val_loss: 0.3978 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4264 - accuracy: 0.8202 - val_loss: 0.3980 - val_accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4272 - accuracy: 0.8202 - val_loss: 0.3968 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4275 - accuracy: 0.8230 - val_loss: 0.3980 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4291 - accuracy: 0.8216 - val_loss: 0.3965 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4252 - accuracy: 0.8216 - val_loss: 0.3961 - val_accuracy: 0.8268\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4261 - accuracy: 0.8188 - val_loss: 0.3965 - val_accuracy: 0.8268\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4262 - accuracy: 0.8202 - val_loss: 0.3972 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4308 - accuracy: 0.8132 - val_loss: 0.4088 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4276 - accuracy: 0.8230 - val_loss: 0.3985 - val_accuracy: 0.8156\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4249 - accuracy: 0.8230 - val_loss: 0.3981 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4238 - accuracy: 0.8202 - val_loss: 0.3959 - val_accuracy: 0.8212\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4259 - accuracy: 0.8216 - val_loss: 0.3986 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4244 - accuracy: 0.8188 - val_loss: 0.3949 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4239 - accuracy: 0.8230 - val_loss: 0.3959 - val_accuracy: 0.8212\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4253 - accuracy: 0.8216 - val_loss: 0.3986 - val_accuracy: 0.8212\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4270 - accuracy: 0.8202 - val_loss: 0.3943 - val_accuracy: 0.8156\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4249 - accuracy: 0.8230 - val_loss: 0.3954 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4238 - accuracy: 0.8188 - val_loss: 0.3945 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4234 - accuracy: 0.8174 - val_loss: 0.3959 - val_accuracy: 0.8212\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4253 - accuracy: 0.8202 - val_loss: 0.4013 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4271 - accuracy: 0.8202 - val_loss: 0.3956 - val_accuracy: 0.8268\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 51us/step - loss: 0.4320 - accuracy: 0.8190\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4330 - accuracy: 0.8225\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4310 - accuracy: 0.8172\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4311 - accuracy: 0.8172\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4298 - accuracy: 0.8225\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4334 - accuracy: 0.8067\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4321 - accuracy: 0.8190\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4294 - accuracy: 0.8190\n",
      "Epoch 9/30\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4304 - accuracy: 0.8137\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4292 - accuracy: 0.8225\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4303 - accuracy: 0.8207\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4287 - accuracy: 0.8172\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4287 - accuracy: 0.8207\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4292 - accuracy: 0.8172\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4312 - accuracy: 0.8190\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4298 - accuracy: 0.8207\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4294 - accuracy: 0.8207\n",
      "Epoch 18/30\n",
      "569/569 [==============================] - 0s 95us/step - loss: 0.4290 - accuracy: 0.8190\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4299 - accuracy: 0.8172\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 118us/step - loss: 0.4305 - accuracy: 0.8207\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4299 - accuracy: 0.8137\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4286 - accuracy: 0.8190\n",
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 139us/step - loss: 0.4279 - accuracy: 0.8225\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.75 - 0s 60us/step - loss: 0.4277 - accuracy: 0.8207\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4282 - accuracy: 0.8190\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 191us/step - loss: 0.4284 - accuracy: 0.8225\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 125us/step - loss: 0.4285 - accuracy: 0.8190\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4278 - accuracy: 0.8172\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 112us/step - loss: 0.4276 - accuracy: 0.8190\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4281 - accuracy: 0.8225\n",
      "143/143 [==============================] - 0s 18us/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 654us/step - loss: 0.7872 - accuracy: 0.6166 - val_loss: 0.7370 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.7016 - accuracy: 0.6166 - val_loss: 0.6915 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.6767 - accuracy: 0.6166 - val_loss: 0.6752 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6611 - accuracy: 0.6166 - val_loss: 0.6583 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.6424 - accuracy: 0.6166 - val_loss: 0.6395 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6227 - accuracy: 0.6250 - val_loss: 0.6129 - val_accuracy: 0.6089\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5989 - accuracy: 0.6685 - val_loss: 0.5861 - val_accuracy: 0.6480\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.5790 - accuracy: 0.7163 - val_loss: 0.5613 - val_accuracy: 0.7039\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5618 - accuracy: 0.7331 - val_loss: 0.5388 - val_accuracy: 0.7095\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.5443 - accuracy: 0.7500 - val_loss: 0.5210 - val_accuracy: 0.7318\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.5338 - accuracy: 0.7556 - val_loss: 0.5062 - val_accuracy: 0.7486\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.5236 - accuracy: 0.7598 - val_loss: 0.4916 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5150 - accuracy: 0.7654 - val_loss: 0.4817 - val_accuracy: 0.7654\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.5096 - accuracy: 0.7683 - val_loss: 0.4729 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.5011 - accuracy: 0.7767 - val_loss: 0.4655 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4962 - accuracy: 0.7739 - val_loss: 0.4606 - val_accuracy: 0.7765\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4926 - accuracy: 0.7837 - val_loss: 0.4561 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4892 - accuracy: 0.7809 - val_loss: 0.4519 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4871 - accuracy: 0.7795 - val_loss: 0.4500 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4834 - accuracy: 0.7795 - val_loss: 0.4469 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4835 - accuracy: 0.7795 - val_loss: 0.4445 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4809 - accuracy: 0.7851 - val_loss: 0.4430 - val_accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4787 - accuracy: 0.7809 - val_loss: 0.4415 - val_accuracy: 0.7709\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4757 - accuracy: 0.7823 - val_loss: 0.4395 - val_accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4776 - accuracy: 0.7893 - val_loss: 0.4381 - val_accuracy: 0.7765\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4812 - accuracy: 0.7851 - val_loss: 0.4392 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4730 - accuracy: 0.7879 - val_loss: 0.4353 - val_accuracy: 0.7765\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4718 - accuracy: 0.7767 - val_loss: 0.4336 - val_accuracy: 0.7765\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 109us/step - loss: 0.4752 - accuracy: 0.7893 - val_loss: 0.4314 - val_accuracy: 0.7765\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4707 - accuracy: 0.7781 - val_loss: 0.4338 - val_accuracy: 0.7765\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4674 - accuracy: 0.7907 - val_loss: 0.4293 - val_accuracy: 0.7765\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4283 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4638 - accuracy: 0.7851 - val_loss: 0.4289 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4638 - accuracy: 0.7837 - val_loss: 0.4263 - val_accuracy: 0.7765\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4625 - accuracy: 0.7837 - val_loss: 0.4270 - val_accuracy: 0.7765\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4615 - accuracy: 0.7907 - val_loss: 0.4258 - val_accuracy: 0.7765\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4610 - accuracy: 0.7837 - val_loss: 0.4238 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4587 - accuracy: 0.7879 - val_loss: 0.4226 - val_accuracy: 0.7765\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4580 - accuracy: 0.7879 - val_loss: 0.4227 - val_accuracy: 0.7765\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4585 - accuracy: 0.7893 - val_loss: 0.4207 - val_accuracy: 0.7765\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4600 - accuracy: 0.7865 - val_loss: 0.4206 - val_accuracy: 0.7821\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4549 - accuracy: 0.7879 - val_loss: 0.4184 - val_accuracy: 0.7821\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.4169 - val_accuracy: 0.7765\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4532 - accuracy: 0.7879 - val_loss: 0.4174 - val_accuracy: 0.7821\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4517 - accuracy: 0.7893 - val_loss: 0.4178 - val_accuracy: 0.7821\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4544 - accuracy: 0.7851 - val_loss: 0.4173 - val_accuracy: 0.7877\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4509 - accuracy: 0.7907 - val_loss: 0.4162 - val_accuracy: 0.7821\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4507 - accuracy: 0.7893 - val_loss: 0.4150 - val_accuracy: 0.7765\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4521 - accuracy: 0.7879 - val_loss: 0.4152 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4553 - accuracy: 0.7978 - val_loss: 0.4187 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4604 - accuracy: 0.7963 - val_loss: 0.4171 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4472 - accuracy: 0.7935 - val_loss: 0.4110 - val_accuracy: 0.7821\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4484 - accuracy: 0.7963 - val_loss: 0.4119 - val_accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4455 - accuracy: 0.7935 - val_loss: 0.4120 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4449 - accuracy: 0.7935 - val_loss: 0.4141 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4448 - accuracy: 0.8006 - val_loss: 0.4117 - val_accuracy: 0.7933\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4456 - accuracy: 0.7963 - val_loss: 0.4105 - val_accuracy: 0.7933\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4479 - accuracy: 0.7963 - val_loss: 0.4150 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4425 - accuracy: 0.7949 - val_loss: 0.4090 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4423 - accuracy: 0.7935 - val_loss: 0.4068 - val_accuracy: 0.7933\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4422 - accuracy: 0.7963 - val_loss: 0.4072 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4446 - accuracy: 0.7992 - val_loss: 0.4089 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4438 - accuracy: 0.8020 - val_loss: 0.4052 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4459 - accuracy: 0.7935 - val_loss: 0.4095 - val_accuracy: 0.8045\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4403 - accuracy: 0.8020 - val_loss: 0.4089 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 188us/step - loss: 0.4411 - accuracy: 0.7992 - val_loss: 0.4073 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4423 - accuracy: 0.8006 - val_loss: 0.4075 - val_accuracy: 0.7877\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4422 - accuracy: 0.8006 - val_loss: 0.4066 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4394 - accuracy: 0.7978 - val_loss: 0.4059 - val_accuracy: 0.7933\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4420 - accuracy: 0.7963 - val_loss: 0.4113 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4432 - accuracy: 0.8132 - val_loss: 0.4094 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4397 - accuracy: 0.8048 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4407 - accuracy: 0.8020 - val_loss: 0.4073 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4391 - accuracy: 0.8006 - val_loss: 0.4045 - val_accuracy: 0.7989\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4381 - accuracy: 0.8090 - val_loss: 0.4043 - val_accuracy: 0.7933\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4377 - accuracy: 0.8062 - val_loss: 0.4039 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4380 - accuracy: 0.8090 - val_loss: 0.4066 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4431 - accuracy: 0.8132 - val_loss: 0.4070 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4383 - accuracy: 0.8034 - val_loss: 0.4035 - val_accuracy: 0.8045\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4371 - accuracy: 0.8090 - val_loss: 0.4071 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4364 - accuracy: 0.8076 - val_loss: 0.4035 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4358 - accuracy: 0.8104 - val_loss: 0.4045 - val_accuracy: 0.7989\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4379 - accuracy: 0.8090 - val_loss: 0.4099 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4426 - accuracy: 0.8020 - val_loss: 0.4079 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 113us/step - loss: 0.4372 - accuracy: 0.8188 - val_loss: 0.4054 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4383 - accuracy: 0.8104 - val_loss: 0.4057 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4339 - accuracy: 0.8132 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4352 - accuracy: 0.8132 - val_loss: 0.4049 - val_accuracy: 0.7989\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4356 - accuracy: 0.8062 - val_loss: 0.4018 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4364 - accuracy: 0.8076 - val_loss: 0.4060 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4349 - accuracy: 0.8118 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4334 - accuracy: 0.8188 - val_loss: 0.4055 - val_accuracy: 0.8045\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4382 - accuracy: 0.8202 - val_loss: 0.4047 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4359 - accuracy: 0.8118 - val_loss: 0.4067 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4364 - accuracy: 0.8132 - val_loss: 0.4020 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4343 - accuracy: 0.8132 - val_loss: 0.4036 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4336 - accuracy: 0.8174 - val_loss: 0.4027 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4330 - accuracy: 0.8118 - val_loss: 0.4025 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.4323 - accuracy: 0.8174 - val_loss: 0.4016 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4335 - accuracy: 0.8118 - val_loss: 0.4031 - val_accuracy: 0.8101\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4359 - accuracy: 0.8158\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4320 - accuracy: 0.8123\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4321 - accuracy: 0.8053\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 87us/step - loss: 0.4311 - accuracy: 0.8070\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4303 - accuracy: 0.8140\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4309 - accuracy: 0.8158\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4313 - accuracy: 0.8070\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4307 - accuracy: 0.8193\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4303 - accuracy: 0.8158\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4308 - accuracy: 0.8140\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4298 - accuracy: 0.8140\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4297 - accuracy: 0.8123\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4295 - accuracy: 0.8158\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4290 - accuracy: 0.8140\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4293 - accuracy: 0.8070\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4299 - accuracy: 0.8193\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4285 - accuracy: 0.8158\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4291 - accuracy: 0.8070\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4287 - accuracy: 0.8158\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4283 - accuracy: 0.8193\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4286 - accuracy: 0.8123\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4292 - accuracy: 0.8211\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 109us/step - loss: 0.4281 - accuracy: 0.8105\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4290 - accuracy: 0.8140\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4284 - accuracy: 0.8140\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4275 - accuracy: 0.8175\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4274 - accuracy: 0.8158\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4272 - accuracy: 0.8105\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4272 - accuracy: 0.8175\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4272 - accuracy: 0.8175\n",
      "142/142 [==============================] - 0s 54us/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 548us/step - loss: 0.7419 - accuracy: 0.4087 - val_loss: 0.6635 - val_accuracy: 0.6704\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6686 - accuracy: 0.6166 - val_loss: 0.6357 - val_accuracy: 0.7039\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6434 - accuracy: 0.6573 - val_loss: 0.6110 - val_accuracy: 0.7039\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6189 - accuracy: 0.6826 - val_loss: 0.5830 - val_accuracy: 0.7318\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.5912 - accuracy: 0.7107 - val_loss: 0.5434 - val_accuracy: 0.7486\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.5570 - accuracy: 0.7346 - val_loss: 0.5051 - val_accuracy: 0.7542\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.5300 - accuracy: 0.7458 - val_loss: 0.4793 - val_accuracy: 0.7821\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.5131 - accuracy: 0.7669 - val_loss: 0.4691 - val_accuracy: 0.7821\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.5026 - accuracy: 0.7767 - val_loss: 0.4609 - val_accuracy: 0.7821\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4977 - accuracy: 0.7823 - val_loss: 0.4527 - val_accuracy: 0.7765\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4923 - accuracy: 0.7865 - val_loss: 0.4506 - val_accuracy: 0.7765\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4892 - accuracy: 0.7837 - val_loss: 0.4501 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4888 - accuracy: 0.7907 - val_loss: 0.4448 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4877 - accuracy: 0.7893 - val_loss: 0.4408 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4817 - accuracy: 0.7907 - val_loss: 0.4391 - val_accuracy: 0.7709\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4791 - accuracy: 0.7907 - val_loss: 0.4367 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4770 - accuracy: 0.7893 - val_loss: 0.4355 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4753 - accuracy: 0.7907 - val_loss: 0.4340 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4739 - accuracy: 0.7893 - val_loss: 0.4325 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4723 - accuracy: 0.7921 - val_loss: 0.4307 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4689 - accuracy: 0.7893 - val_loss: 0.4300 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4667 - accuracy: 0.7949 - val_loss: 0.4277 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4648 - accuracy: 0.7907 - val_loss: 0.4263 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4629 - accuracy: 0.7921 - val_loss: 0.4243 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4620 - accuracy: 0.7949 - val_loss: 0.4230 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4597 - accuracy: 0.7893 - val_loss: 0.4221 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4588 - accuracy: 0.7963 - val_loss: 0.4228 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.4580 - accuracy: 0.7992 - val_loss: 0.4219 - val_accuracy: 0.7765\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4562 - accuracy: 0.7978 - val_loss: 0.4173 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.4564 - accuracy: 0.7949 - val_loss: 0.4193 - val_accuracy: 0.7765\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4516 - accuracy: 0.7978 - val_loss: 0.4180 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4528 - accuracy: 0.8020 - val_loss: 0.4175 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4489 - accuracy: 0.7978 - val_loss: 0.4130 - val_accuracy: 0.7821\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4498 - accuracy: 0.7935 - val_loss: 0.4091 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4472 - accuracy: 0.7978 - val_loss: 0.4108 - val_accuracy: 0.7877\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4454 - accuracy: 0.7963 - val_loss: 0.4098 - val_accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4444 - accuracy: 0.8006 - val_loss: 0.4107 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4438 - accuracy: 0.7978 - val_loss: 0.4052 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4438 - accuracy: 0.7992 - val_loss: 0.4081 - val_accuracy: 0.7877\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4449 - accuracy: 0.8006 - val_loss: 0.4068 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4400 - accuracy: 0.8034 - val_loss: 0.4037 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4388 - accuracy: 0.8090 - val_loss: 0.4049 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4397 - accuracy: 0.8006 - val_loss: 0.4048 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4382 - accuracy: 0.8062 - val_loss: 0.4043 - val_accuracy: 0.7877\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4392 - accuracy: 0.8076 - val_loss: 0.4033 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4394 - accuracy: 0.8160 - val_loss: 0.4047 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4386 - accuracy: 0.8062 - val_loss: 0.4027 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4351 - accuracy: 0.8146 - val_loss: 0.4031 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4340 - accuracy: 0.8104 - val_loss: 0.3984 - val_accuracy: 0.7877\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4334 - accuracy: 0.8160 - val_loss: 0.4008 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4333 - accuracy: 0.8132 - val_loss: 0.3995 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4318 - accuracy: 0.8076 - val_loss: 0.3961 - val_accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4350 - accuracy: 0.8118 - val_loss: 0.3972 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4333 - accuracy: 0.8216 - val_loss: 0.3996 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4330 - accuracy: 0.8118 - val_loss: 0.4000 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4325 - accuracy: 0.8132 - val_loss: 0.3966 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4311 - accuracy: 0.8104 - val_loss: 0.3951 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4312 - accuracy: 0.8160 - val_loss: 0.3945 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4280 - accuracy: 0.8188 - val_loss: 0.3953 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4291 - accuracy: 0.8202 - val_loss: 0.3921 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4286 - accuracy: 0.8174 - val_loss: 0.3923 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4275 - accuracy: 0.8146 - val_loss: 0.3923 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4284 - accuracy: 0.8202 - val_loss: 0.3925 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4272 - accuracy: 0.8174 - val_loss: 0.3942 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4263 - accuracy: 0.8160 - val_loss: 0.3915 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4257 - accuracy: 0.8174 - val_loss: 0.3905 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4278 - accuracy: 0.8188 - val_loss: 0.3918 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4297 - accuracy: 0.8104 - val_loss: 0.3923 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4272 - accuracy: 0.8174 - val_loss: 0.3939 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 141us/step - loss: 0.4262 - accuracy: 0.8202 - val_loss: 0.3929 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4275 - accuracy: 0.8244 - val_loss: 0.3897 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4254 - accuracy: 0.8174 - val_loss: 0.3932 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4256 - accuracy: 0.8188 - val_loss: 0.3880 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4250 - accuracy: 0.8202 - val_loss: 0.3875 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 188us/step - loss: 0.4230 - accuracy: 0.8146 - val_loss: 0.3904 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4245 - accuracy: 0.8188 - val_loss: 0.3892 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4241 - accuracy: 0.8174 - val_loss: 0.3864 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4259 - accuracy: 0.8174 - val_loss: 0.3902 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4253 - accuracy: 0.8244 - val_loss: 0.3865 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4244 - accuracy: 0.8118 - val_loss: 0.3916 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4247 - accuracy: 0.8216 - val_loss: 0.3896 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4215 - accuracy: 0.8174 - val_loss: 0.3889 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4246 - accuracy: 0.8244 - val_loss: 0.3885 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4258 - accuracy: 0.8160 - val_loss: 0.3975 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4239 - accuracy: 0.8174 - val_loss: 0.3882 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4216 - accuracy: 0.8244 - val_loss: 0.3896 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4226 - accuracy: 0.8216 - val_loss: 0.3877 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4248 - accuracy: 0.8160 - val_loss: 0.3874 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4209 - accuracy: 0.8202 - val_loss: 0.3875 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4236 - accuracy: 0.8244 - val_loss: 0.3856 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4242 - accuracy: 0.8118 - val_loss: 0.3896 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4216 - accuracy: 0.8258 - val_loss: 0.3876 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4208 - accuracy: 0.8216 - val_loss: 0.3919 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4212 - accuracy: 0.8272 - val_loss: 0.3854 - val_accuracy: 0.8156\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.81 - 0s 116us/step - loss: 0.4209 - accuracy: 0.8188 - val_loss: 0.3880 - val_accuracy: 0.8045\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4190 - accuracy: 0.8202 - val_loss: 0.3839 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4198 - accuracy: 0.8216 - val_loss: 0.3875 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4203 - accuracy: 0.8230 - val_loss: 0.3844 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4241 - accuracy: 0.8174 - val_loss: 0.3851 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4196 - accuracy: 0.8202 - val_loss: 0.3850 - val_accuracy: 0.8045\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 129us/step - loss: 0.4211 - accuracy: 0.8228\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4209 - accuracy: 0.8263\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4207 - accuracy: 0.8175\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.4196 - accuracy: 0.8246\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4193 - accuracy: 0.8263\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4218 - accuracy: 0.8281\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4192 - accuracy: 0.8263\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4200 - accuracy: 0.8228\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4189 - accuracy: 0.8228\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4203 - accuracy: 0.8246\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4182 - accuracy: 0.8246\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4184 - accuracy: 0.8263\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4179 - accuracy: 0.8228\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4199 - accuracy: 0.8246\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4179 - accuracy: 0.8246\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4176 - accuracy: 0.8263\n",
      "Epoch 17/30\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4177 - accuracy: 0.8246\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4178 - accuracy: 0.8263\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4179 - accuracy: 0.8228\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4186 - accuracy: 0.8263\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4176 - accuracy: 0.8263\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4183 - accuracy: 0.8193\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4168 - accuracy: 0.8263\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4161 - accuracy: 0.8263\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4190 - accuracy: 0.8193\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4172 - accuracy: 0.8263\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4167 - accuracy: 0.8263\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4168 - accuracy: 0.8246\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4164 - accuracy: 0.8246\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4169 - accuracy: 0.8263\n",
      "142/142 [==============================] - 0s 55us/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_179 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 796us/step - loss: 0.6429 - accuracy: 0.6489 - val_loss: 0.6183 - val_accuracy: 0.6704\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6127 - accuracy: 0.6657 - val_loss: 0.5892 - val_accuracy: 0.7095\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.5871 - accuracy: 0.7247 - val_loss: 0.5599 - val_accuracy: 0.7598\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.5617 - accuracy: 0.7430 - val_loss: 0.5313 - val_accuracy: 0.7486\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.5405 - accuracy: 0.7683 - val_loss: 0.5064 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.5212 - accuracy: 0.7893 - val_loss: 0.4857 - val_accuracy: 0.7877\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 217us/step - loss: 0.5083 - accuracy: 0.7921 - val_loss: 0.4665 - val_accuracy: 0.7877\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4939 - accuracy: 0.7893 - val_loss: 0.4538 - val_accuracy: 0.7933\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4858 - accuracy: 0.7907 - val_loss: 0.4454 - val_accuracy: 0.7821\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4804 - accuracy: 0.7921 - val_loss: 0.4367 - val_accuracy: 0.7989\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4768 - accuracy: 0.7907 - val_loss: 0.4295 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4761 - accuracy: 0.7893 - val_loss: 0.4306 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4714 - accuracy: 0.7879 - val_loss: 0.4276 - val_accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4693 - accuracy: 0.7893 - val_loss: 0.4256 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.4240 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4683 - accuracy: 0.7893 - val_loss: 0.4215 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4662 - accuracy: 0.7879 - val_loss: 0.4228 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4691 - accuracy: 0.7907 - val_loss: 0.4210 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4676 - accuracy: 0.7893 - val_loss: 0.4197 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4631 - accuracy: 0.7851 - val_loss: 0.4163 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.79 - 0s 99us/step - loss: 0.4617 - accuracy: 0.7907 - val_loss: 0.4172 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4611 - accuracy: 0.7935 - val_loss: 0.4168 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4627 - accuracy: 0.7907 - val_loss: 0.4167 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4620 - accuracy: 0.7893 - val_loss: 0.4158 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4607 - accuracy: 0.7935 - val_loss: 0.4145 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4595 - accuracy: 0.7949 - val_loss: 0.4129 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4582 - accuracy: 0.7893 - val_loss: 0.4129 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4583 - accuracy: 0.7907 - val_loss: 0.4126 - val_accuracy: 0.7933\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4580 - accuracy: 0.7893 - val_loss: 0.4128 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4577 - accuracy: 0.7921 - val_loss: 0.4116 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4579 - accuracy: 0.7963 - val_loss: 0.4121 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4563 - accuracy: 0.7921 - val_loss: 0.4125 - val_accuracy: 0.8045\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4570 - accuracy: 0.7963 - val_loss: 0.4116 - val_accuracy: 0.8045\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4561 - accuracy: 0.7963 - val_loss: 0.4116 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4559 - accuracy: 0.7935 - val_loss: 0.4128 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4547 - accuracy: 0.7978 - val_loss: 0.4137 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4563 - accuracy: 0.7935 - val_loss: 0.4163 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4548 - accuracy: 0.8006 - val_loss: 0.4145 - val_accuracy: 0.7877\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4548 - accuracy: 0.7992 - val_loss: 0.4136 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4536 - accuracy: 0.8006 - val_loss: 0.4142 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4556 - accuracy: 0.7992 - val_loss: 0.4159 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4548 - accuracy: 0.7978 - val_loss: 0.4100 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 168us/step - loss: 0.4533 - accuracy: 0.7978 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 185us/step - loss: 0.4547 - accuracy: 0.8020 - val_loss: 0.4101 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4528 - accuracy: 0.7992 - val_loss: 0.4111 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4533 - accuracy: 0.7963 - val_loss: 0.4112 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4532 - accuracy: 0.8048 - val_loss: 0.4105 - val_accuracy: 0.7877\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4561 - accuracy: 0.7921 - val_loss: 0.4113 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4505 - accuracy: 0.8020 - val_loss: 0.4110 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4560 - accuracy: 0.7921 - val_loss: 0.4162 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4546 - accuracy: 0.8048 - val_loss: 0.4078 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4515 - accuracy: 0.8006 - val_loss: 0.4094 - val_accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4505 - accuracy: 0.8006 - val_loss: 0.4127 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4508 - accuracy: 0.8020 - val_loss: 0.4070 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4491 - accuracy: 0.7992 - val_loss: 0.4075 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 94us/step - loss: 0.4478 - accuracy: 0.8006 - val_loss: 0.4074 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4508 - accuracy: 0.8020 - val_loss: 0.4073 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4490 - accuracy: 0.7992 - val_loss: 0.4089 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4459 - accuracy: 0.7992 - val_loss: 0.4078 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4483 - accuracy: 0.8006 - val_loss: 0.4078 - val_accuracy: 0.7933\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4469 - accuracy: 0.7978 - val_loss: 0.4066 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4468 - accuracy: 0.8034 - val_loss: 0.4064 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4475 - accuracy: 0.7992 - val_loss: 0.4045 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4487 - accuracy: 0.8006 - val_loss: 0.4078 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4456 - accuracy: 0.7992 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4438 - accuracy: 0.8006 - val_loss: 0.4031 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4442 - accuracy: 0.8006 - val_loss: 0.4044 - val_accuracy: 0.8101\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4437 - accuracy: 0.8034 - val_loss: 0.4037 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4454 - accuracy: 0.8020 - val_loss: 0.4020 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4430 - accuracy: 0.8020 - val_loss: 0.4033 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4445 - accuracy: 0.8048 - val_loss: 0.4022 - val_accuracy: 0.7989\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4431 - accuracy: 0.8062 - val_loss: 0.4013 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4422 - accuracy: 0.8034 - val_loss: 0.4028 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4416 - accuracy: 0.8034 - val_loss: 0.4008 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4422 - accuracy: 0.8104 - val_loss: 0.4017 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4411 - accuracy: 0.8076 - val_loss: 0.3987 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4426 - accuracy: 0.8062 - val_loss: 0.3980 - val_accuracy: 0.8156\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4399 - accuracy: 0.8076 - val_loss: 0.3998 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4408 - accuracy: 0.8090 - val_loss: 0.3986 - val_accuracy: 0.8212\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4385 - accuracy: 0.8118 - val_loss: 0.3957 - val_accuracy: 0.8212\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4378 - accuracy: 0.8076 - val_loss: 0.3965 - val_accuracy: 0.8212\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4379 - accuracy: 0.8062 - val_loss: 0.3962 - val_accuracy: 0.8156\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4378 - accuracy: 0.8118 - val_loss: 0.3975 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4417 - accuracy: 0.8160 - val_loss: 0.3966 - val_accuracy: 0.8268\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4395 - accuracy: 0.8160 - val_loss: 0.3958 - val_accuracy: 0.8212\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4372 - accuracy: 0.8132 - val_loss: 0.3959 - val_accuracy: 0.8156\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4381 - accuracy: 0.8132 - val_loss: 0.3990 - val_accuracy: 0.8212\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4369 - accuracy: 0.8202 - val_loss: 0.3951 - val_accuracy: 0.8212\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4360 - accuracy: 0.8160 - val_loss: 0.3957 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4352 - accuracy: 0.8132 - val_loss: 0.3940 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4368 - accuracy: 0.8104 - val_loss: 0.3990 - val_accuracy: 0.8212\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4352 - accuracy: 0.8202 - val_loss: 0.3939 - val_accuracy: 0.8212\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4349 - accuracy: 0.8160 - val_loss: 0.3964 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4340 - accuracy: 0.8202 - val_loss: 0.3919 - val_accuracy: 0.8268\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4344 - accuracy: 0.8174 - val_loss: 0.3963 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4332 - accuracy: 0.8160 - val_loss: 0.3916 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4351 - accuracy: 0.8174 - val_loss: 0.3918 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4324 - accuracy: 0.8202 - val_loss: 0.3949 - val_accuracy: 0.8212\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4319 - accuracy: 0.8188 - val_loss: 0.3930 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4344 - accuracy: 0.8146 - val_loss: 0.3961 - val_accuracy: 0.8212\n",
      "Epoch 1/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4365 - accuracy: 0.8281\n",
      "Epoch 2/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4341 - accuracy: 0.8246\n",
      "Epoch 3/30\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4344 - accuracy: 0.8228\n",
      "Epoch 4/30\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4337 - accuracy: 0.8246\n",
      "Epoch 5/30\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4347 - accuracy: 0.8246\n",
      "Epoch 6/30\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4328 - accuracy: 0.8228\n",
      "Epoch 7/30\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4335 - accuracy: 0.8246\n",
      "Epoch 8/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4322 - accuracy: 0.8246\n",
      "Epoch 9/30\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4335 - accuracy: 0.8211\n",
      "Epoch 10/30\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4341 - accuracy: 0.8281\n",
      "Epoch 11/30\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4321 - accuracy: 0.8263\n",
      "Epoch 12/30\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4335 - accuracy: 0.8211\n",
      "Epoch 13/30\n",
      "570/570 [==============================] - 0s 136us/step - loss: 0.4315 - accuracy: 0.8211\n",
      "Epoch 14/30\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4309 - accuracy: 0.8228\n",
      "Epoch 15/30\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4334 - accuracy: 0.8246\n",
      "Epoch 16/30\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4349 - accuracy: 0.8228\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 52us/step - loss: 0.4308 - accuracy: 0.8228\n",
      "Epoch 18/30\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4327 - accuracy: 0.8246\n",
      "Epoch 19/30\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4297 - accuracy: 0.8228\n",
      "Epoch 20/30\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4300 - accuracy: 0.8228\n",
      "Epoch 21/30\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4306 - accuracy: 0.8246\n",
      "Epoch 22/30\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4299 - accuracy: 0.8228\n",
      "Epoch 23/30\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4289 - accuracy: 0.8228\n",
      "Epoch 24/30\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4291 - accuracy: 0.8246\n",
      "Epoch 25/30\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4300 - accuracy: 0.8246\n",
      "Epoch 26/30\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4285 - accuracy: 0.8246\n",
      "Epoch 27/30\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4295 - accuracy: 0.8246\n",
      "Epoch 28/30\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4276 - accuracy: 0.8211\n",
      "Epoch 29/30\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4291 - accuracy: 0.8246\n",
      "Epoch 30/30\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4288 - accuracy: 0.8246\n",
      "142/142 [==============================] - 0s 48us/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_183 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.7168 - accuracy: 0.3919 - val_loss: 0.6876 - val_accuracy: 0.4358\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6675 - accuracy: 0.6601 - val_loss: 0.6434 - val_accuracy: 0.6760\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.6289 - accuracy: 0.6952 - val_loss: 0.6078 - val_accuracy: 0.7263\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5990 - accuracy: 0.7121 - val_loss: 0.5725 - val_accuracy: 0.7654\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.5699 - accuracy: 0.7669 - val_loss: 0.5419 - val_accuracy: 0.7709\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5456 - accuracy: 0.7654 - val_loss: 0.5140 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5248 - accuracy: 0.7767 - val_loss: 0.4939 - val_accuracy: 0.7933\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.5089 - accuracy: 0.7781 - val_loss: 0.4716 - val_accuracy: 0.7877\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4952 - accuracy: 0.7809 - val_loss: 0.4610 - val_accuracy: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4913 - accuracy: 0.7823 - val_loss: 0.4500 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4837 - accuracy: 0.7851 - val_loss: 0.4432 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4798 - accuracy: 0.7837 - val_loss: 0.4399 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4765 - accuracy: 0.7851 - val_loss: 0.4370 - val_accuracy: 0.7989\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4741 - accuracy: 0.7823 - val_loss: 0.4334 - val_accuracy: 0.7989\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4706 - accuracy: 0.7809 - val_loss: 0.4303 - val_accuracy: 0.7989\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4694 - accuracy: 0.7865 - val_loss: 0.4323 - val_accuracy: 0.7989\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4692 - accuracy: 0.7837 - val_loss: 0.4300 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.4266 - val_accuracy: 0.7989\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4626 - accuracy: 0.7879 - val_loss: 0.4257 - val_accuracy: 0.7989\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4250 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4616 - accuracy: 0.7893 - val_loss: 0.4236 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4615 - accuracy: 0.7893 - val_loss: 0.4258 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4580 - accuracy: 0.7921 - val_loss: 0.4209 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 177us/step - loss: 0.4562 - accuracy: 0.7907 - val_loss: 0.4195 - val_accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 179us/step - loss: 0.4553 - accuracy: 0.7879 - val_loss: 0.4202 - val_accuracy: 0.7989\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4533 - accuracy: 0.7921 - val_loss: 0.4199 - val_accuracy: 0.8045\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4558 - accuracy: 0.7893 - val_loss: 0.4220 - val_accuracy: 0.7989\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 167us/step - loss: 0.4526 - accuracy: 0.7907 - val_loss: 0.4172 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4535 - accuracy: 0.7907 - val_loss: 0.4182 - val_accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4503 - accuracy: 0.7921 - val_loss: 0.4148 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.4489 - accuracy: 0.7921 - val_loss: 0.4152 - val_accuracy: 0.8045\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 172us/step - loss: 0.4486 - accuracy: 0.7935 - val_loss: 0.4149 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4489 - accuracy: 0.7935 - val_loss: 0.4149 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4488 - accuracy: 0.7935 - val_loss: 0.4138 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4485 - accuracy: 0.7935 - val_loss: 0.4124 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4466 - accuracy: 0.7949 - val_loss: 0.4114 - val_accuracy: 0.8045\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4461 - accuracy: 0.8006 - val_loss: 0.4141 - val_accuracy: 0.8156\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4471 - accuracy: 0.7921 - val_loss: 0.4159 - val_accuracy: 0.7989\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4464 - accuracy: 0.7963 - val_loss: 0.4122 - val_accuracy: 0.8101\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.78 - 0s 125us/step - loss: 0.4453 - accuracy: 0.7935 - val_loss: 0.4112 - val_accuracy: 0.8045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4443 - accuracy: 0.7935 - val_loss: 0.4114 - val_accuracy: 0.8045\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4451 - accuracy: 0.7963 - val_loss: 0.4109 - val_accuracy: 0.8045\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4447 - accuracy: 0.8006 - val_loss: 0.4111 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4435 - accuracy: 0.7949 - val_loss: 0.4090 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4417 - accuracy: 0.7935 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4413 - accuracy: 0.7949 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4432 - accuracy: 0.8006 - val_loss: 0.4088 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4409 - accuracy: 0.8006 - val_loss: 0.4087 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4409 - accuracy: 0.7963 - val_loss: 0.4089 - val_accuracy: 0.8045\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4423 - accuracy: 0.7963 - val_loss: 0.4080 - val_accuracy: 0.8101\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4400 - accuracy: 0.8006 - val_loss: 0.4076 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4403 - accuracy: 0.8006 - val_loss: 0.4080 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4410 - accuracy: 0.7963 - val_loss: 0.4091 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4421 - accuracy: 0.7992 - val_loss: 0.4106 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4420 - accuracy: 0.7992 - val_loss: 0.4082 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4392 - accuracy: 0.8020 - val_loss: 0.4076 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4382 - accuracy: 0.8048 - val_loss: 0.4069 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4392 - accuracy: 0.8048 - val_loss: 0.4059 - val_accuracy: 0.8156\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4397 - accuracy: 0.7963 - val_loss: 0.4067 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4381 - accuracy: 0.8076 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.79 - 0s 96us/step - loss: 0.4377 - accuracy: 0.8020 - val_loss: 0.4083 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4429 - accuracy: 0.8062 - val_loss: 0.4112 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4413 - accuracy: 0.8020 - val_loss: 0.4084 - val_accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4404 - accuracy: 0.8062 - val_loss: 0.4085 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4395 - accuracy: 0.8034 - val_loss: 0.4047 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4378 - accuracy: 0.8062 - val_loss: 0.4086 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4364 - accuracy: 0.8062 - val_loss: 0.4073 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4407 - accuracy: 0.8062 - val_loss: 0.4092 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4357 - accuracy: 0.8104 - val_loss: 0.4069 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4354 - accuracy: 0.8132 - val_loss: 0.4076 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4357 - accuracy: 0.8062 - val_loss: 0.4076 - val_accuracy: 0.7989\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4355 - accuracy: 0.8090 - val_loss: 0.4059 - val_accuracy: 0.7933\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4345 - accuracy: 0.8118 - val_loss: 0.4062 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 51us/step - loss: 0.4346 - accuracy: 0.8048 - val_loss: 0.4061 - val_accuracy: 0.7933\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4371 - accuracy: 0.8146 - val_loss: 0.4063 - val_accuracy: 0.7989\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4369 - accuracy: 0.8076 - val_loss: 0.4058 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4338 - accuracy: 0.8132 - val_loss: 0.4046 - val_accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4343 - accuracy: 0.8132 - val_loss: 0.4054 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4361 - accuracy: 0.8132 - val_loss: 0.4045 - val_accuracy: 0.8045\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4323 - accuracy: 0.8118 - val_loss: 0.4043 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4333 - accuracy: 0.8118 - val_loss: 0.4041 - val_accuracy: 0.7989\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4332 - accuracy: 0.8146 - val_loss: 0.4059 - val_accuracy: 0.7989\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4333 - accuracy: 0.8118 - val_loss: 0.4053 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4340 - accuracy: 0.8160 - val_loss: 0.4042 - val_accuracy: 0.7989\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4319 - accuracy: 0.8146 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4332 - accuracy: 0.8146 - val_loss: 0.4048 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4321 - accuracy: 0.8132 - val_loss: 0.4030 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4345 - accuracy: 0.8132 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4366 - accuracy: 0.8020 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4311 - accuracy: 0.8090 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4313 - accuracy: 0.8160 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4322 - accuracy: 0.8090 - val_loss: 0.4060 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4336 - accuracy: 0.8132 - val_loss: 0.4048 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4330 - accuracy: 0.8062 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4378 - accuracy: 0.8118 - val_loss: 0.4119 - val_accuracy: 0.8045\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4314 - accuracy: 0.8146 - val_loss: 0.4046 - val_accuracy: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4306 - accuracy: 0.8146 - val_loss: 0.4043 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4359 - accuracy: 0.8118 - val_loss: 0.4092 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4301 - accuracy: 0.8146 - val_loss: 0.4029 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4308 - accuracy: 0.8048 - val_loss: 0.4075 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4193 - accuracy: 0.8243\n",
      "Epoch 2/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4168 - accuracy: 0.8172\n",
      "Epoch 3/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4122 - accuracy: 0.8225\n",
      "Epoch 4/60\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4143 - accuracy: 0.8243\n",
      "Epoch 5/60\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.4127 - accuracy: 0.8225\n",
      "Epoch 6/60\n",
      "569/569 [==============================] - 0s 68us/step - loss: 0.4130 - accuracy: 0.8172\n",
      "Epoch 7/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4156 - accuracy: 0.8190\n",
      "Epoch 8/60\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.4133 - accuracy: 0.8120\n",
      "Epoch 9/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4200 - accuracy: 0.8172\n",
      "Epoch 10/60\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.4188 - accuracy: 0.8102\n",
      "Epoch 11/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4115 - accuracy: 0.8155\n",
      "Epoch 12/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4135 - accuracy: 0.8225\n",
      "Epoch 13/60\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4132 - accuracy: 0.8155\n",
      "Epoch 14/60\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.4116 - accuracy: 0.8190\n",
      "Epoch 15/60\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4126 - accuracy: 0.8207\n",
      "Epoch 16/60\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4125 - accuracy: 0.8172\n",
      "Epoch 17/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4112 - accuracy: 0.8172\n",
      "Epoch 18/60\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4120 - accuracy: 0.8155\n",
      "Epoch 19/60\n",
      "569/569 [==============================] - 0s 74us/step - loss: 0.4108 - accuracy: 0.8172\n",
      "Epoch 20/60\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4125 - accuracy: 0.8207\n",
      "Epoch 21/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4111 - accuracy: 0.8155\n",
      "Epoch 22/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4107 - accuracy: 0.8172\n",
      "Epoch 23/60\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4121 - accuracy: 0.8172\n",
      "Epoch 24/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4113 - accuracy: 0.8155\n",
      "Epoch 25/60\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.4112 - accuracy: 0.8172\n",
      "Epoch 26/60\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4115 - accuracy: 0.8190\n",
      "Epoch 27/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4103 - accuracy: 0.8155\n",
      "Epoch 28/60\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4104 - accuracy: 0.8172\n",
      "Epoch 29/60\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.4099 - accuracy: 0.8172\n",
      "Epoch 30/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4127 - accuracy: 0.8207\n",
      "Epoch 31/60\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4103 - accuracy: 0.8172\n",
      "Epoch 32/60\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4105 - accuracy: 0.8190\n",
      "Epoch 33/60\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.4105 - accuracy: 0.8190\n",
      "Epoch 34/60\n",
      "569/569 [==============================] - 0s 83us/step - loss: 0.4107 - accuracy: 0.8207\n",
      "Epoch 35/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4098 - accuracy: 0.8207\n",
      "Epoch 36/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4099 - accuracy: 0.8190\n",
      "Epoch 37/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4095 - accuracy: 0.8190\n",
      "Epoch 38/60\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4102 - accuracy: 0.8137\n",
      "Epoch 39/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4086 - accuracy: 0.8207\n",
      "Epoch 40/60\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.4101 - accuracy: 0.8190\n",
      "Epoch 41/60\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4089 - accuracy: 0.8190\n",
      "Epoch 42/60\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4089 - accuracy: 0.8207\n",
      "Epoch 43/60\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.79 - 0s 43us/step - loss: 0.4093 - accuracy: 0.8207\n",
      "Epoch 44/60\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4097 - accuracy: 0.8190\n",
      "Epoch 45/60\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.4094 - accuracy: 0.8190\n",
      "Epoch 46/60\n",
      "569/569 [==============================] - 0s 89us/step - loss: 0.4089 - accuracy: 0.8190\n",
      "Epoch 47/60\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.4087 - accuracy: 0.8207\n",
      "Epoch 48/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4087 - accuracy: 0.8207\n",
      "Epoch 49/60\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4098 - accuracy: 0.8207\n",
      "Epoch 50/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4116 - accuracy: 0.8190\n",
      "Epoch 51/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4094 - accuracy: 0.8225\n",
      "Epoch 52/60\n",
      "569/569 [==============================] - 0s 107us/step - loss: 0.4108 - accuracy: 0.8225\n",
      "Epoch 53/60\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4088 - accuracy: 0.8225\n",
      "Epoch 54/60\n",
      "569/569 [==============================] - 0s 76us/step - loss: 0.4095 - accuracy: 0.8207\n",
      "Epoch 55/60\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4088 - accuracy: 0.8225\n",
      "Epoch 56/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4097 - accuracy: 0.8225\n",
      "Epoch 57/60\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4085 - accuracy: 0.8260\n",
      "Epoch 58/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4075 - accuracy: 0.8225\n",
      "Epoch 59/60\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4087 - accuracy: 0.8243\n",
      "Epoch 60/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4068 - accuracy: 0.8207\n",
      "143/143 [==============================] - 0s 68us/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 584us/step - loss: 0.6798 - accuracy: 0.6166 - val_loss: 0.6731 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6637 - accuracy: 0.6166 - val_loss: 0.6561 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6497 - accuracy: 0.6166 - val_loss: 0.6395 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 98us/step - loss: 0.6359 - accuracy: 0.6166 - val_loss: 0.6232 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6215 - accuracy: 0.6166 - val_loss: 0.6052 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6054 - accuracy: 0.6447 - val_loss: 0.5839 - val_accuracy: 0.7486\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5878 - accuracy: 0.7051 - val_loss: 0.5613 - val_accuracy: 0.7542\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.5689 - accuracy: 0.7205 - val_loss: 0.5386 - val_accuracy: 0.7598\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.5506 - accuracy: 0.7654 - val_loss: 0.5163 - val_accuracy: 0.7542\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.5335 - accuracy: 0.7612 - val_loss: 0.4948 - val_accuracy: 0.7486\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5179 - accuracy: 0.7640 - val_loss: 0.4794 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5057 - accuracy: 0.7851 - val_loss: 0.4663 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4944 - accuracy: 0.7893 - val_loss: 0.4581 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4900 - accuracy: 0.7837 - val_loss: 0.4521 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4822 - accuracy: 0.7893 - val_loss: 0.4481 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4818 - accuracy: 0.7837 - val_loss: 0.4400 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4789 - accuracy: 0.7851 - val_loss: 0.4369 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4726 - accuracy: 0.7935 - val_loss: 0.4340 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4728 - accuracy: 0.7879 - val_loss: 0.4303 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4701 - accuracy: 0.7893 - val_loss: 0.4301 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4685 - accuracy: 0.7837 - val_loss: 0.4279 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4694 - accuracy: 0.7879 - val_loss: 0.4261 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.4264 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4645 - accuracy: 0.7907 - val_loss: 0.4255 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4697 - accuracy: 0.7837 - val_loss: 0.4237 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4638 - accuracy: 0.7865 - val_loss: 0.4223 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4225 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4626 - accuracy: 0.7879 - val_loss: 0.4219 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4608 - accuracy: 0.7921 - val_loss: 0.4215 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4621 - accuracy: 0.7837 - val_loss: 0.4213 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4591 - accuracy: 0.7921 - val_loss: 0.4218 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4590 - accuracy: 0.7879 - val_loss: 0.4194 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4579 - accuracy: 0.7865 - val_loss: 0.4188 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4572 - accuracy: 0.7935 - val_loss: 0.4169 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.4175 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4574 - accuracy: 0.7978 - val_loss: 0.4178 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4562 - accuracy: 0.7851 - val_loss: 0.4167 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4555 - accuracy: 0.7921 - val_loss: 0.4176 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4546 - accuracy: 0.7907 - val_loss: 0.4168 - val_accuracy: 0.7877\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4554 - accuracy: 0.7921 - val_loss: 0.4172 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4535 - accuracy: 0.7935 - val_loss: 0.4153 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4526 - accuracy: 0.7949 - val_loss: 0.4147 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.80 - 0s 104us/step - loss: 0.4542 - accuracy: 0.7963 - val_loss: 0.4140 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4497 - accuracy: 0.7935 - val_loss: 0.4136 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4528 - accuracy: 0.7935 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4510 - accuracy: 0.8006 - val_loss: 0.4135 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4507 - accuracy: 0.7963 - val_loss: 0.4126 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4508 - accuracy: 0.7963 - val_loss: 0.4119 - val_accuracy: 0.7821\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4508 - accuracy: 0.7992 - val_loss: 0.4119 - val_accuracy: 0.7821\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4475 - accuracy: 0.8006 - val_loss: 0.4108 - val_accuracy: 0.8045\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4496 - accuracy: 0.7949 - val_loss: 0.4103 - val_accuracy: 0.7765\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4493 - accuracy: 0.7992 - val_loss: 0.4093 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4465 - accuracy: 0.7978 - val_loss: 0.4084 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4458 - accuracy: 0.7978 - val_loss: 0.4093 - val_accuracy: 0.8101\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 221us/step - loss: 0.4459 - accuracy: 0.7992 - val_loss: 0.4084 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4448 - accuracy: 0.8006 - val_loss: 0.4079 - val_accuracy: 0.7877\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 316us/step - loss: 0.4453 - accuracy: 0.8076 - val_loss: 0.4084 - val_accuracy: 0.7821\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4460 - accuracy: 0.8034 - val_loss: 0.4066 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4445 - accuracy: 0.8034 - val_loss: 0.4072 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 137us/step - loss: 0.4418 - accuracy: 0.7992 - val_loss: 0.4059 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4427 - accuracy: 0.8076 - val_loss: 0.4074 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 196us/step - loss: 0.4442 - accuracy: 0.8090 - val_loss: 0.4058 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4434 - accuracy: 0.8076 - val_loss: 0.4047 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4427 - accuracy: 0.8076 - val_loss: 0.4060 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4440 - accuracy: 0.8090 - val_loss: 0.4051 - val_accuracy: 0.7989\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4469 - accuracy: 0.8034 - val_loss: 0.4059 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4419 - accuracy: 0.8104 - val_loss: 0.4044 - val_accuracy: 0.7933\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4401 - accuracy: 0.8062 - val_loss: 0.4040 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4404 - accuracy: 0.8090 - val_loss: 0.4042 - val_accuracy: 0.7877\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4418 - accuracy: 0.8090 - val_loss: 0.4066 - val_accuracy: 0.7933\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 182us/step - loss: 0.4402 - accuracy: 0.8118 - val_loss: 0.4028 - val_accuracy: 0.7933\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.4409 - accuracy: 0.8076 - val_loss: 0.4021 - val_accuracy: 0.7933\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4385 - accuracy: 0.8118 - val_loss: 0.4032 - val_accuracy: 0.7933\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4384 - accuracy: 0.8104 - val_loss: 0.4028 - val_accuracy: 0.7933\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4375 - accuracy: 0.8118 - val_loss: 0.4039 - val_accuracy: 0.7989\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4395 - accuracy: 0.8118 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4383 - accuracy: 0.8118 - val_loss: 0.4016 - val_accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4372 - accuracy: 0.8104 - val_loss: 0.4018 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 168us/step - loss: 0.4388 - accuracy: 0.8118 - val_loss: 0.4033 - val_accuracy: 0.7989\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4382 - accuracy: 0.8160 - val_loss: 0.4032 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4359 - accuracy: 0.8132 - val_loss: 0.4023 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4358 - accuracy: 0.8118 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4378 - accuracy: 0.8146 - val_loss: 0.4035 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4359 - accuracy: 0.8146 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4388 - accuracy: 0.8090 - val_loss: 0.4014 - val_accuracy: 0.7989\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4420 - accuracy: 0.8146 - val_loss: 0.4059 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4349 - accuracy: 0.8132 - val_loss: 0.4022 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4348 - accuracy: 0.8174 - val_loss: 0.4005 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4382 - accuracy: 0.8160 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4356 - accuracy: 0.8160 - val_loss: 0.4026 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4346 - accuracy: 0.8132 - val_loss: 0.4010 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4352 - accuracy: 0.8146 - val_loss: 0.4009 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4358 - accuracy: 0.8188 - val_loss: 0.4013 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4326 - accuracy: 0.8132 - val_loss: 0.4001 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4324 - accuracy: 0.8174 - val_loss: 0.4012 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4324 - accuracy: 0.8230 - val_loss: 0.4016 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4323 - accuracy: 0.8160 - val_loss: 0.4016 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4345 - accuracy: 0.8104 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4319 - accuracy: 0.8216 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4313 - accuracy: 0.8132 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.4431 - accuracy: 0.8102\n",
      "Epoch 2/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4429 - accuracy: 0.8137\n",
      "Epoch 3/60\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4446 - accuracy: 0.8120\n",
      "Epoch 4/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4416 - accuracy: 0.8137\n",
      "Epoch 5/60\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4414 - accuracy: 0.8120\n",
      "Epoch 6/60\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4406 - accuracy: 0.8120\n",
      "Epoch 7/60\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4409 - accuracy: 0.8120\n",
      "Epoch 8/60\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4401 - accuracy: 0.8084\n",
      "Epoch 9/60\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4413 - accuracy: 0.8137\n",
      "Epoch 10/60\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4405 - accuracy: 0.8102\n",
      "Epoch 11/60\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4399 - accuracy: 0.8120\n",
      "Epoch 12/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4392 - accuracy: 0.8120\n",
      "Epoch 13/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4402 - accuracy: 0.8155\n",
      "Epoch 14/60\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4386 - accuracy: 0.8137\n",
      "Epoch 15/60\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4389 - accuracy: 0.8155\n",
      "Epoch 16/60\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4385 - accuracy: 0.8172\n",
      "Epoch 17/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4412 - accuracy: 0.8067\n",
      "Epoch 18/60\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4387 - accuracy: 0.8120\n",
      "Epoch 19/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4392 - accuracy: 0.8120\n",
      "Epoch 20/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4383 - accuracy: 0.8120\n",
      "Epoch 21/60\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4391 - accuracy: 0.8137\n",
      "Epoch 22/60\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4380 - accuracy: 0.8137\n",
      "Epoch 23/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 53us/step - loss: 0.4377 - accuracy: 0.8155\n",
      "Epoch 24/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4382 - accuracy: 0.8155\n",
      "Epoch 25/60\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4377 - accuracy: 0.8137\n",
      "Epoch 26/60\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4380 - accuracy: 0.8155\n",
      "Epoch 27/60\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4383 - accuracy: 0.8155\n",
      "Epoch 28/60\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4374 - accuracy: 0.8137\n",
      "Epoch 29/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4366 - accuracy: 0.8172\n",
      "Epoch 30/60\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4372 - accuracy: 0.8155\n",
      "Epoch 31/60\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4374 - accuracy: 0.8155\n",
      "Epoch 32/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4378 - accuracy: 0.8155\n",
      "Epoch 33/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4374 - accuracy: 0.8137\n",
      "Epoch 34/60\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4367 - accuracy: 0.8155\n",
      "Epoch 35/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4370 - accuracy: 0.8120\n",
      "Epoch 36/60\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4364 - accuracy: 0.8155\n",
      "Epoch 37/60\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4371 - accuracy: 0.8155\n",
      "Epoch 38/60\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4367 - accuracy: 0.8172\n",
      "Epoch 39/60\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4366 - accuracy: 0.8137\n",
      "Epoch 40/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4373 - accuracy: 0.8137\n",
      "Epoch 41/60\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4351 - accuracy: 0.8172\n",
      "Epoch 42/60\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4357 - accuracy: 0.8155\n",
      "Epoch 43/60\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.4358 - accuracy: 0.8190\n",
      "Epoch 44/60\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.4351 - accuracy: 0.8172\n",
      "Epoch 45/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4357 - accuracy: 0.8137\n",
      "Epoch 46/60\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4363 - accuracy: 0.8207\n",
      "Epoch 47/60\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.4355 - accuracy: 0.8190\n",
      "Epoch 48/60\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4362 - accuracy: 0.8172\n",
      "Epoch 49/60\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.4352 - accuracy: 0.8137\n",
      "Epoch 50/60\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4348 - accuracy: 0.8155\n",
      "Epoch 51/60\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4349 - accuracy: 0.8190\n",
      "Epoch 52/60\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4350 - accuracy: 0.8190\n",
      "Epoch 53/60\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4352 - accuracy: 0.8155\n",
      "Epoch 54/60\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4358 - accuracy: 0.8155\n",
      "Epoch 55/60\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4345 - accuracy: 0.8207\n",
      "Epoch 56/60\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4349 - accuracy: 0.8120\n",
      "Epoch 57/60\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4347 - accuracy: 0.8172\n",
      "Epoch 58/60\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.4358 - accuracy: 0.8190\n",
      "Epoch 59/60\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4349 - accuracy: 0.8155\n",
      "Epoch 60/60\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4355 - accuracy: 0.8207\n",
      "143/143 [==============================] - 0s 38us/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_191 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 596us/step - loss: 0.6900 - accuracy: 0.6053 - val_loss: 0.6877 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6778 - accuracy: 0.6166 - val_loss: 0.6800 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6713 - accuracy: 0.6166 - val_loss: 0.6736 - val_accuracy: 0.6145\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.6641 - accuracy: 0.6166 - val_loss: 0.6664 - val_accuracy: 0.6145\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.6568 - accuracy: 0.6166 - val_loss: 0.6586 - val_accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.6487 - accuracy: 0.6166 - val_loss: 0.6485 - val_accuracy: 0.6145\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.6368 - accuracy: 0.6250 - val_loss: 0.6335 - val_accuracy: 0.6313\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6206 - accuracy: 0.6882 - val_loss: 0.6078 - val_accuracy: 0.7263\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.5893 - accuracy: 0.7149 - val_loss: 0.5597 - val_accuracy: 0.7709\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.5527 - accuracy: 0.7528 - val_loss: 0.5228 - val_accuracy: 0.7486\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5273 - accuracy: 0.7809 - val_loss: 0.4923 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.5110 - accuracy: 0.7865 - val_loss: 0.4711 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.5013 - accuracy: 0.7893 - val_loss: 0.4592 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4948 - accuracy: 0.7865 - val_loss: 0.4521 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4905 - accuracy: 0.7865 - val_loss: 0.4461 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4868 - accuracy: 0.7907 - val_loss: 0.4403 - val_accuracy: 0.7765\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4816 - accuracy: 0.7865 - val_loss: 0.4385 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4797 - accuracy: 0.7907 - val_loss: 0.4356 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4800 - accuracy: 0.7907 - val_loss: 0.4321 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4772 - accuracy: 0.7907 - val_loss: 0.4299 - val_accuracy: 0.7765\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4746 - accuracy: 0.7865 - val_loss: 0.4292 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4739 - accuracy: 0.7837 - val_loss: 0.4288 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4719 - accuracy: 0.7879 - val_loss: 0.4273 - val_accuracy: 0.7821\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 96us/step - loss: 0.4719 - accuracy: 0.7907 - val_loss: 0.4277 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4702 - accuracy: 0.7865 - val_loss: 0.4269 - val_accuracy: 0.7821\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4703 - accuracy: 0.7907 - val_loss: 0.4250 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4683 - accuracy: 0.7865 - val_loss: 0.4239 - val_accuracy: 0.7765\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4666 - accuracy: 0.7907 - val_loss: 0.4234 - val_accuracy: 0.7765\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4661 - accuracy: 0.7879 - val_loss: 0.4219 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.4206 - val_accuracy: 0.7765\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4642 - accuracy: 0.7851 - val_loss: 0.4205 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4638 - accuracy: 0.7865 - val_loss: 0.4215 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4647 - accuracy: 0.7879 - val_loss: 0.4190 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4627 - accuracy: 0.7851 - val_loss: 0.4186 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4186 - val_accuracy: 0.7877\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4183 - val_accuracy: 0.7877\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4632 - accuracy: 0.7851 - val_loss: 0.4214 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4630 - accuracy: 0.7893 - val_loss: 0.4191 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4174 - val_accuracy: 0.7877\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.78 - 0s 96us/step - loss: 0.4620 - accuracy: 0.7879 - val_loss: 0.4178 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4595 - accuracy: 0.7851 - val_loss: 0.4157 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4589 - accuracy: 0.7851 - val_loss: 0.4169 - val_accuracy: 0.7821\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4579 - accuracy: 0.7935 - val_loss: 0.4141 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4585 - accuracy: 0.7865 - val_loss: 0.4137 - val_accuracy: 0.7877\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4581 - accuracy: 0.7921 - val_loss: 0.4147 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4575 - accuracy: 0.7851 - val_loss: 0.4156 - val_accuracy: 0.7821\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4572 - accuracy: 0.7935 - val_loss: 0.4141 - val_accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4557 - accuracy: 0.7865 - val_loss: 0.4125 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4545 - accuracy: 0.7949 - val_loss: 0.4130 - val_accuracy: 0.7821\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4552 - accuracy: 0.7879 - val_loss: 0.4133 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4532 - accuracy: 0.7837 - val_loss: 0.4118 - val_accuracy: 0.7821\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4528 - accuracy: 0.7907 - val_loss: 0.4102 - val_accuracy: 0.7821\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4524 - accuracy: 0.7907 - val_loss: 0.4113 - val_accuracy: 0.7877\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4531 - accuracy: 0.7978 - val_loss: 0.4119 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 221us/step - loss: 0.4522 - accuracy: 0.7907 - val_loss: 0.4111 - val_accuracy: 0.7821\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4504 - accuracy: 0.7907 - val_loss: 0.4092 - val_accuracy: 0.7821\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 235us/step - loss: 0.4497 - accuracy: 0.7921 - val_loss: 0.4105 - val_accuracy: 0.7877\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4508 - accuracy: 0.7921 - val_loss: 0.4117 - val_accuracy: 0.7821\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 197us/step - loss: 0.4500 - accuracy: 0.7935 - val_loss: 0.4087 - val_accuracy: 0.7877\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4510 - accuracy: 0.7907 - val_loss: 0.4085 - val_accuracy: 0.7821\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4505 - accuracy: 0.7921 - val_loss: 0.4054 - val_accuracy: 0.7877\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4472 - accuracy: 0.7921 - val_loss: 0.4122 - val_accuracy: 0.7821\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4474 - accuracy: 0.7921 - val_loss: 0.4101 - val_accuracy: 0.7821\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4467 - accuracy: 0.7921 - val_loss: 0.4072 - val_accuracy: 0.7821\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4499 - accuracy: 0.7921 - val_loss: 0.4063 - val_accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4509 - accuracy: 0.7992 - val_loss: 0.4076 - val_accuracy: 0.7821\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4492 - accuracy: 0.7949 - val_loss: 0.4058 - val_accuracy: 0.7877\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4462 - accuracy: 0.7921 - val_loss: 0.4050 - val_accuracy: 0.7877\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4452 - accuracy: 0.8034 - val_loss: 0.4078 - val_accuracy: 0.7821\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4508 - accuracy: 0.7907 - val_loss: 0.4086 - val_accuracy: 0.8156\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4450 - accuracy: 0.7935 - val_loss: 0.4033 - val_accuracy: 0.7877\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4435 - accuracy: 0.7949 - val_loss: 0.4068 - val_accuracy: 0.7877\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4429 - accuracy: 0.7949 - val_loss: 0.4058 - val_accuracy: 0.7877\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4437 - accuracy: 0.7921 - val_loss: 0.4054 - val_accuracy: 0.7877\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4435 - accuracy: 0.7949 - val_loss: 0.4053 - val_accuracy: 0.7821\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4426 - accuracy: 0.7921 - val_loss: 0.4027 - val_accuracy: 0.7877\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4403 - accuracy: 0.7949 - val_loss: 0.4031 - val_accuracy: 0.7933\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4435 - accuracy: 0.7921 - val_loss: 0.4028 - val_accuracy: 0.7877\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4415 - accuracy: 0.7992 - val_loss: 0.4039 - val_accuracy: 0.7877\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 197us/step - loss: 0.4419 - accuracy: 0.8048 - val_loss: 0.4038 - val_accuracy: 0.7933\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4426 - accuracy: 0.7978 - val_loss: 0.3998 - val_accuracy: 0.7989\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.4401 - accuracy: 0.7978 - val_loss: 0.4020 - val_accuracy: 0.7933\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4400 - accuracy: 0.8020 - val_loss: 0.4028 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4398 - accuracy: 0.8020 - val_loss: 0.4024 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4404 - accuracy: 0.8048 - val_loss: 0.4029 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4404 - accuracy: 0.8076 - val_loss: 0.4047 - val_accuracy: 0.7933\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.4401 - accuracy: 0.8020 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4403 - accuracy: 0.8048 - val_loss: 0.4023 - val_accuracy: 0.7989\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4375 - accuracy: 0.8076 - val_loss: 0.4010 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4371 - accuracy: 0.8104 - val_loss: 0.4039 - val_accuracy: 0.8045\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.4368 - accuracy: 0.8104 - val_loss: 0.4014 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4390 - accuracy: 0.8048 - val_loss: 0.4028 - val_accuracy: 0.7933\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4362 - accuracy: 0.8048 - val_loss: 0.4015 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.4372 - accuracy: 0.8118 - val_loss: 0.4007 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4365 - accuracy: 0.8076 - val_loss: 0.3978 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4366 - accuracy: 0.8048 - val_loss: 0.3994 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4367 - accuracy: 0.8104 - val_loss: 0.4015 - val_accuracy: 0.8045\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.80 - 0s 116us/step - loss: 0.4348 - accuracy: 0.8062 - val_loss: 0.3993 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4360 - accuracy: 0.8076 - val_loss: 0.4025 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4362 - accuracy: 0.8090 - val_loss: 0.3993 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4431 - accuracy: 0.8053\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4369 - accuracy: 0.8035\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4350 - accuracy: 0.8088\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4354 - accuracy: 0.8018\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4368 - accuracy: 0.8105\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4325 - accuracy: 0.8105\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4335 - accuracy: 0.8018\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4324 - accuracy: 0.8105\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4321 - accuracy: 0.8088\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4333 - accuracy: 0.8088\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4320 - accuracy: 0.8070\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4321 - accuracy: 0.8105\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4329 - accuracy: 0.8070\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4316 - accuracy: 0.8175\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4319 - accuracy: 0.8088\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4309 - accuracy: 0.8088\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4312 - accuracy: 0.8105\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4306 - accuracy: 0.8105\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4300 - accuracy: 0.8123\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4299 - accuracy: 0.8088\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4295 - accuracy: 0.8123\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4293 - accuracy: 0.8088\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4298 - accuracy: 0.8123\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4287 - accuracy: 0.8123\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4293 - accuracy: 0.8123\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4296 - accuracy: 0.8123\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4290 - accuracy: 0.8088\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4289 - accuracy: 0.8105\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4290 - accuracy: 0.8193\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4278 - accuracy: 0.8035\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4282 - accuracy: 0.8105\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4272 - accuracy: 0.8123\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4286 - accuracy: 0.8088\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4279 - accuracy: 0.8140\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4273 - accuracy: 0.8105\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4265 - accuracy: 0.8123\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 40us/step - loss: 0.4267 - accuracy: 0.8123\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4264 - accuracy: 0.8158\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4258 - accuracy: 0.8105\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4276 - accuracy: 0.8123\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.85 - 0s 68us/step - loss: 0.4285 - accuracy: 0.8053\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4251 - accuracy: 0.8105\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4256 - accuracy: 0.8140\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4251 - accuracy: 0.8158\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4253 - accuracy: 0.8088\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 77us/step - loss: 0.4260 - accuracy: 0.8123\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4258 - accuracy: 0.8053\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4252 - accuracy: 0.8035\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4247 - accuracy: 0.8175\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 74us/step - loss: 0.4246 - accuracy: 0.8140\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4269 - accuracy: 0.8053\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4265 - accuracy: 0.8140\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4253 - accuracy: 0.8070\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4236 - accuracy: 0.8105\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4249 - accuracy: 0.8175\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4257 - accuracy: 0.8018\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4258 - accuracy: 0.8140\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4249 - accuracy: 0.8140\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4242 - accuracy: 0.8070\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4229 - accuracy: 0.8140\n",
      "142/142 [==============================] - 0s 66us/step\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_195 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 657us/step - loss: 0.7104 - accuracy: 0.6152 - val_loss: 0.6740 - val_accuracy: 0.6313\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.6392 - accuracy: 0.6306 - val_loss: 0.6354 - val_accuracy: 0.6369\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.6158 - accuracy: 0.7037 - val_loss: 0.6124 - val_accuracy: 0.6760\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.5955 - accuracy: 0.7247 - val_loss: 0.5869 - val_accuracy: 0.7207\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.5747 - accuracy: 0.7444 - val_loss: 0.5591 - val_accuracy: 0.7374\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.5541 - accuracy: 0.7584 - val_loss: 0.5345 - val_accuracy: 0.7542\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.5343 - accuracy: 0.7669 - val_loss: 0.5132 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5188 - accuracy: 0.7781 - val_loss: 0.4891 - val_accuracy: 0.7765\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.5046 - accuracy: 0.7753 - val_loss: 0.4749 - val_accuracy: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4978 - accuracy: 0.7865 - val_loss: 0.4679 - val_accuracy: 0.7821\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4926 - accuracy: 0.7851 - val_loss: 0.4572 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4864 - accuracy: 0.7893 - val_loss: 0.4520 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4853 - accuracy: 0.7907 - val_loss: 0.4495 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4804 - accuracy: 0.7893 - val_loss: 0.4480 - val_accuracy: 0.7765\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4809 - accuracy: 0.7879 - val_loss: 0.4453 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4776 - accuracy: 0.7879 - val_loss: 0.4427 - val_accuracy: 0.7989\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4759 - accuracy: 0.7893 - val_loss: 0.4408 - val_accuracy: 0.7933\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4740 - accuracy: 0.7893 - val_loss: 0.4390 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4721 - accuracy: 0.7907 - val_loss: 0.4363 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4713 - accuracy: 0.7907 - val_loss: 0.4373 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4705 - accuracy: 0.7893 - val_loss: 0.4378 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4702 - accuracy: 0.7907 - val_loss: 0.4360 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4699 - accuracy: 0.7907 - val_loss: 0.4366 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4678 - accuracy: 0.7893 - val_loss: 0.4389 - val_accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4690 - accuracy: 0.7893 - val_loss: 0.4351 - val_accuracy: 0.7765\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4663 - accuracy: 0.7893 - val_loss: 0.4330 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4647 - accuracy: 0.7893 - val_loss: 0.4317 - val_accuracy: 0.7877\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4638 - accuracy: 0.7907 - val_loss: 0.4310 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4640 - accuracy: 0.7893 - val_loss: 0.4294 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4632 - accuracy: 0.7907 - val_loss: 0.4315 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4637 - accuracy: 0.7893 - val_loss: 0.4279 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4616 - accuracy: 0.7907 - val_loss: 0.4284 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4601 - accuracy: 0.7921 - val_loss: 0.4248 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4595 - accuracy: 0.7893 - val_loss: 0.4278 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4592 - accuracy: 0.7907 - val_loss: 0.4257 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4655 - accuracy: 0.7935 - val_loss: 0.4286 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4233 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4579 - accuracy: 0.7921 - val_loss: 0.4224 - val_accuracy: 0.7821\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4569 - accuracy: 0.7907 - val_loss: 0.4192 - val_accuracy: 0.7821\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4558 - accuracy: 0.7949 - val_loss: 0.4202 - val_accuracy: 0.7989\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4566 - accuracy: 0.7879 - val_loss: 0.4192 - val_accuracy: 0.7877\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4544 - accuracy: 0.7921 - val_loss: 0.4208 - val_accuracy: 0.7989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4544 - accuracy: 0.7949 - val_loss: 0.4196 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4534 - accuracy: 0.7949 - val_loss: 0.4190 - val_accuracy: 0.7933\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4521 - accuracy: 0.7949 - val_loss: 0.4159 - val_accuracy: 0.7877\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4527 - accuracy: 0.7949 - val_loss: 0.4167 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4554 - accuracy: 0.7893 - val_loss: 0.4173 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4634 - accuracy: 0.8006 - val_loss: 0.4184 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4516 - accuracy: 0.7935 - val_loss: 0.4136 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4511 - accuracy: 0.7949 - val_loss: 0.4146 - val_accuracy: 0.7933\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4513 - accuracy: 0.7963 - val_loss: 0.4139 - val_accuracy: 0.7933\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4482 - accuracy: 0.7963 - val_loss: 0.4128 - val_accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4489 - accuracy: 0.7963 - val_loss: 0.4126 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4500 - accuracy: 0.7963 - val_loss: 0.4136 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4481 - accuracy: 0.7949 - val_loss: 0.4117 - val_accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4489 - accuracy: 0.7949 - val_loss: 0.4114 - val_accuracy: 0.7877\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4478 - accuracy: 0.7963 - val_loss: 0.4113 - val_accuracy: 0.7877\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4458 - accuracy: 0.7963 - val_loss: 0.4098 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4474 - accuracy: 0.7963 - val_loss: 0.4116 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4469 - accuracy: 0.8006 - val_loss: 0.4134 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4467 - accuracy: 0.7949 - val_loss: 0.4103 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4456 - accuracy: 0.7963 - val_loss: 0.4100 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4459 - accuracy: 0.7992 - val_loss: 0.4097 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4445 - accuracy: 0.7978 - val_loss: 0.4092 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4436 - accuracy: 0.7992 - val_loss: 0.4112 - val_accuracy: 0.8101\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4446 - accuracy: 0.8020 - val_loss: 0.4092 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4439 - accuracy: 0.8034 - val_loss: 0.4109 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4447 - accuracy: 0.8034 - val_loss: 0.4098 - val_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4426 - accuracy: 0.8034 - val_loss: 0.4103 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4415 - accuracy: 0.8076 - val_loss: 0.4108 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4491 - accuracy: 0.8048 - val_loss: 0.4101 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4423 - accuracy: 0.8076 - val_loss: 0.4081 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4418 - accuracy: 0.8048 - val_loss: 0.4083 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4413 - accuracy: 0.8034 - val_loss: 0.4071 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4442 - accuracy: 0.8090 - val_loss: 0.4057 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4417 - accuracy: 0.8034 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4403 - accuracy: 0.8090 - val_loss: 0.4064 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4426 - accuracy: 0.8062 - val_loss: 0.4091 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4396 - accuracy: 0.8076 - val_loss: 0.4077 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.90 - 0s 70us/step - loss: 0.4409 - accuracy: 0.8104 - val_loss: 0.4048 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4425 - accuracy: 0.8090 - val_loss: 0.4095 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4402 - accuracy: 0.8118 - val_loss: 0.4150 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4421 - accuracy: 0.8146 - val_loss: 0.4050 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4405 - accuracy: 0.8090 - val_loss: 0.4054 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4394 - accuracy: 0.8104 - val_loss: 0.4036 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4376 - accuracy: 0.8146 - val_loss: 0.4064 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4399 - accuracy: 0.8132 - val_loss: 0.4055 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4366 - accuracy: 0.8146 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4421 - accuracy: 0.8118 - val_loss: 0.4032 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4389 - accuracy: 0.8104 - val_loss: 0.4071 - val_accuracy: 0.7989\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 182us/step - loss: 0.4376 - accuracy: 0.8132 - val_loss: 0.4038 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 173us/step - loss: 0.4376 - accuracy: 0.8146 - val_loss: 0.4078 - val_accuracy: 0.8045\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4362 - accuracy: 0.8104 - val_loss: 0.4042 - val_accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4367 - accuracy: 0.8160 - val_loss: 0.4032 - val_accuracy: 0.8045\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4431 - accuracy: 0.8132 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4375 - accuracy: 0.8160 - val_loss: 0.4028 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4386 - accuracy: 0.8132 - val_loss: 0.4020 - val_accuracy: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4380 - accuracy: 0.8090 - val_loss: 0.4016 - val_accuracy: 0.8045\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4374 - accuracy: 0.8188 - val_loss: 0.4084 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4617 - accuracy: 0.7982\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4464 - accuracy: 0.8140\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4385 - accuracy: 0.8105\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.4344 - accuracy: 0.8105\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4342 - accuracy: 0.8123\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4329 - accuracy: 0.8088\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4342 - accuracy: 0.8193\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4325 - accuracy: 0.8193\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4333 - accuracy: 0.8123\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4322 - accuracy: 0.8140\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4328 - accuracy: 0.8193\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4330 - accuracy: 0.8123\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4316 - accuracy: 0.8158\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4315 - accuracy: 0.8175\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4312 - accuracy: 0.8193\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4314 - accuracy: 0.8158\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4308 - accuracy: 0.8175\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4308 - accuracy: 0.8158\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4308 - accuracy: 0.8158\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4320 - accuracy: 0.8175\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4304 - accuracy: 0.8193\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4301 - accuracy: 0.8228\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4303 - accuracy: 0.8228\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4302 - accuracy: 0.8211\n",
      "Epoch 25/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4303 - accuracy: 0.8228\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4307 - accuracy: 0.8140\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4304 - accuracy: 0.8193\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4299 - accuracy: 0.8193\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4296 - accuracy: 0.8246\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4295 - accuracy: 0.8211\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4299 - accuracy: 0.8228\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4300 - accuracy: 0.8175\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4292 - accuracy: 0.8228\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4298 - accuracy: 0.8193\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4288 - accuracy: 0.8211\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4311 - accuracy: 0.8140\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4311 - accuracy: 0.8193\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4285 - accuracy: 0.8193\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4314 - accuracy: 0.8158\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4287 - accuracy: 0.8228\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4281 - accuracy: 0.8211\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4284 - accuracy: 0.8193\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4282 - accuracy: 0.8193\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 84us/step - loss: 0.4288 - accuracy: 0.8246\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4280 - accuracy: 0.8228\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4283 - accuracy: 0.8211\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4278 - accuracy: 0.8228\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4289 - accuracy: 0.8228\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 78us/step - loss: 0.4274 - accuracy: 0.8246\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4278 - accuracy: 0.8228\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.4273 - accuracy: 0.8228\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4271 - accuracy: 0.8228\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4284 - accuracy: 0.8211\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4274 - accuracy: 0.8228\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4270 - accuracy: 0.8175\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4279 - accuracy: 0.8211\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4304 - accuracy: 0.8228\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4289 - accuracy: 0.8175\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4266 - accuracy: 0.8193\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4278 - accuracy: 0.8193\n",
      "142/142 [==============================] - 0s 47us/step\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_199 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 575us/step - loss: 0.6729 - accuracy: 0.6376 - val_loss: 0.6479 - val_accuracy: 0.6927\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.6365 - accuracy: 0.6756 - val_loss: 0.6062 - val_accuracy: 0.7095\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.6013 - accuracy: 0.6854 - val_loss: 0.5625 - val_accuracy: 0.7486\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.5665 - accuracy: 0.7079 - val_loss: 0.5201 - val_accuracy: 0.7877\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.5368 - accuracy: 0.7360 - val_loss: 0.4877 - val_accuracy: 0.8045\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 108us/step - loss: 0.5131 - accuracy: 0.7683 - val_loss: 0.4595 - val_accuracy: 0.8045\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4970 - accuracy: 0.7781 - val_loss: 0.4450 - val_accuracy: 0.8045\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4863 - accuracy: 0.7795 - val_loss: 0.4340 - val_accuracy: 0.8045\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4794 - accuracy: 0.7837 - val_loss: 0.4302 - val_accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4742 - accuracy: 0.7893 - val_loss: 0.4270 - val_accuracy: 0.7989\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4695 - accuracy: 0.7921 - val_loss: 0.4239 - val_accuracy: 0.7989\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4661 - accuracy: 0.7921 - val_loss: 0.4219 - val_accuracy: 0.7989\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4624 - accuracy: 0.7963 - val_loss: 0.4208 - val_accuracy: 0.7989\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4601 - accuracy: 0.8048 - val_loss: 0.4206 - val_accuracy: 0.7989\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4569 - accuracy: 0.7978 - val_loss: 0.4157 - val_accuracy: 0.7989\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4548 - accuracy: 0.8048 - val_loss: 0.4148 - val_accuracy: 0.7989\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4534 - accuracy: 0.8020 - val_loss: 0.4142 - val_accuracy: 0.7989\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4509 - accuracy: 0.8020 - val_loss: 0.4102 - val_accuracy: 0.8045\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4490 - accuracy: 0.8048 - val_loss: 0.4099 - val_accuracy: 0.8101\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4467 - accuracy: 0.8048 - val_loss: 0.4062 - val_accuracy: 0.8045\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4466 - accuracy: 0.8006 - val_loss: 0.4085 - val_accuracy: 0.8045\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4435 - accuracy: 0.8034 - val_loss: 0.4046 - val_accuracy: 0.8156\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4414 - accuracy: 0.8048 - val_loss: 0.4051 - val_accuracy: 0.8156\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4418 - accuracy: 0.8062 - val_loss: 0.4037 - val_accuracy: 0.8156\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4394 - accuracy: 0.8090 - val_loss: 0.3988 - val_accuracy: 0.8156\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4387 - accuracy: 0.8048 - val_loss: 0.3996 - val_accuracy: 0.8156\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4370 - accuracy: 0.8062 - val_loss: 0.3987 - val_accuracy: 0.8156\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4384 - accuracy: 0.8020 - val_loss: 0.3994 - val_accuracy: 0.8156\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4388 - accuracy: 0.8216 - val_loss: 0.4025 - val_accuracy: 0.8156\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4356 - accuracy: 0.8062 - val_loss: 0.3944 - val_accuracy: 0.8156\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4338 - accuracy: 0.8090 - val_loss: 0.3953 - val_accuracy: 0.8156\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4347 - accuracy: 0.8146 - val_loss: 0.3956 - val_accuracy: 0.8101\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4360 - accuracy: 0.8118 - val_loss: 0.3956 - val_accuracy: 0.8156\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4330 - accuracy: 0.8118 - val_loss: 0.3940 - val_accuracy: 0.8156\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4347 - accuracy: 0.8258 - val_loss: 0.3948 - val_accuracy: 0.8156\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4312 - accuracy: 0.8090 - val_loss: 0.3943 - val_accuracy: 0.8156\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4298 - accuracy: 0.8188 - val_loss: 0.3938 - val_accuracy: 0.8156\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4328 - accuracy: 0.8132 - val_loss: 0.3957 - val_accuracy: 0.8156\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4279 - accuracy: 0.8258 - val_loss: 0.3945 - val_accuracy: 0.8156\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.83 - 0s 143us/step - loss: 0.4268 - accuracy: 0.8216 - val_loss: 0.3929 - val_accuracy: 0.8156\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4272 - accuracy: 0.8216 - val_loss: 0.3928 - val_accuracy: 0.8101\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4254 - accuracy: 0.8202 - val_loss: 0.3910 - val_accuracy: 0.8101\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4251 - accuracy: 0.8272 - val_loss: 0.3908 - val_accuracy: 0.8101\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4250 - accuracy: 0.8216 - val_loss: 0.3909 - val_accuracy: 0.8156\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4236 - accuracy: 0.8301 - val_loss: 0.3920 - val_accuracy: 0.8101\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4227 - accuracy: 0.8202 - val_loss: 0.3909 - val_accuracy: 0.8101\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4237 - accuracy: 0.8216 - val_loss: 0.3886 - val_accuracy: 0.8212\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4210 - accuracy: 0.8244 - val_loss: 0.3941 - val_accuracy: 0.8156\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4226 - accuracy: 0.8343 - val_loss: 0.3933 - val_accuracy: 0.8156\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4207 - accuracy: 0.8258 - val_loss: 0.3898 - val_accuracy: 0.8156\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.4194 - accuracy: 0.8230 - val_loss: 0.3907 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4212 - accuracy: 0.8258 - val_loss: 0.3888 - val_accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4183 - accuracy: 0.8272 - val_loss: 0.3905 - val_accuracy: 0.8156\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4186 - accuracy: 0.8272 - val_loss: 0.3906 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.90 - 0s 95us/step - loss: 0.4246 - accuracy: 0.8188 - val_loss: 0.3899 - val_accuracy: 0.8212\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4183 - accuracy: 0.8315 - val_loss: 0.3855 - val_accuracy: 0.8156\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4184 - accuracy: 0.8258 - val_loss: 0.3876 - val_accuracy: 0.8212\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4170 - accuracy: 0.8287 - val_loss: 0.3859 - val_accuracy: 0.8212\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4180 - accuracy: 0.8371 - val_loss: 0.3884 - val_accuracy: 0.8212\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4172 - accuracy: 0.8272 - val_loss: 0.3894 - val_accuracy: 0.8212\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4147 - accuracy: 0.8287 - val_loss: 0.3840 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4166 - accuracy: 0.8315 - val_loss: 0.3850 - val_accuracy: 0.8212\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4148 - accuracy: 0.8343 - val_loss: 0.3869 - val_accuracy: 0.8212\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4142 - accuracy: 0.8329 - val_loss: 0.3889 - val_accuracy: 0.8212\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4137 - accuracy: 0.8315 - val_loss: 0.3875 - val_accuracy: 0.8212\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4167 - accuracy: 0.8258 - val_loss: 0.3879 - val_accuracy: 0.8212\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4143 - accuracy: 0.8357 - val_loss: 0.3835 - val_accuracy: 0.8212\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4161 - accuracy: 0.8230 - val_loss: 0.3884 - val_accuracy: 0.8212\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4128 - accuracy: 0.8329 - val_loss: 0.3829 - val_accuracy: 0.8212\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4120 - accuracy: 0.8371 - val_loss: 0.3883 - val_accuracy: 0.8212\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4122 - accuracy: 0.8287 - val_loss: 0.3850 - val_accuracy: 0.8212\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4107 - accuracy: 0.8315 - val_loss: 0.3841 - val_accuracy: 0.8156\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4120 - accuracy: 0.8301 - val_loss: 0.3877 - val_accuracy: 0.8212\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.4106 - accuracy: 0.8301 - val_loss: 0.3870 - val_accuracy: 0.8212\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 173us/step - loss: 0.4121 - accuracy: 0.8329 - val_loss: 0.3887 - val_accuracy: 0.8212\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4114 - accuracy: 0.8343 - val_loss: 0.3880 - val_accuracy: 0.8212\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4095 - accuracy: 0.8343 - val_loss: 0.3871 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4099 - accuracy: 0.8287 - val_loss: 0.3854 - val_accuracy: 0.8212\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.75 - 0s 91us/step - loss: 0.4089 - accuracy: 0.8343 - val_loss: 0.3856 - val_accuracy: 0.8212\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4106 - accuracy: 0.8343 - val_loss: 0.3857 - val_accuracy: 0.8156\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4098 - accuracy: 0.8287 - val_loss: 0.3849 - val_accuracy: 0.8212\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4081 - accuracy: 0.8272 - val_loss: 0.3852 - val_accuracy: 0.8212\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4071 - accuracy: 0.8343 - val_loss: 0.3878 - val_accuracy: 0.8212\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4087 - accuracy: 0.8329 - val_loss: 0.3890 - val_accuracy: 0.8212\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4088 - accuracy: 0.8329 - val_loss: 0.3815 - val_accuracy: 0.8268\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4113 - accuracy: 0.8315 - val_loss: 0.3852 - val_accuracy: 0.8212\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4080 - accuracy: 0.8301 - val_loss: 0.3886 - val_accuracy: 0.8212\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4068 - accuracy: 0.8315 - val_loss: 0.3852 - val_accuracy: 0.8268\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4083 - accuracy: 0.8329 - val_loss: 0.3901 - val_accuracy: 0.8212\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4083 - accuracy: 0.8343 - val_loss: 0.3872 - val_accuracy: 0.8268\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4051 - accuracy: 0.8315 - val_loss: 0.3868 - val_accuracy: 0.8212\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4061 - accuracy: 0.8315 - val_loss: 0.3858 - val_accuracy: 0.8212\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4071 - accuracy: 0.8343 - val_loss: 0.3832 - val_accuracy: 0.8268\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4091 - accuracy: 0.8272 - val_loss: 0.3865 - val_accuracy: 0.8212\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4069 - accuracy: 0.8343 - val_loss: 0.3838 - val_accuracy: 0.8268\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4051 - accuracy: 0.8315 - val_loss: 0.3838 - val_accuracy: 0.8268\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4058 - accuracy: 0.8343 - val_loss: 0.3916 - val_accuracy: 0.8212\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4049 - accuracy: 0.8343 - val_loss: 0.3864 - val_accuracy: 0.8324\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4051 - accuracy: 0.8329 - val_loss: 0.3856 - val_accuracy: 0.8212\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4035 - accuracy: 0.8343 - val_loss: 0.3877 - val_accuracy: 0.8212\n",
      "Epoch 1/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4066 - accuracy: 0.8281\n",
      "Epoch 2/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4030 - accuracy: 0.8333\n",
      "Epoch 3/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4030 - accuracy: 0.8351\n",
      "Epoch 4/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4026 - accuracy: 0.8351\n",
      "Epoch 5/60\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4016 - accuracy: 0.8333\n",
      "Epoch 6/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4023 - accuracy: 0.8333\n",
      "Epoch 7/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4030 - accuracy: 0.8368\n",
      "Epoch 8/60\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4010 - accuracy: 0.8368\n",
      "Epoch 9/60\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4008 - accuracy: 0.8333\n",
      "Epoch 10/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4005 - accuracy: 0.8333\n",
      "Epoch 11/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4012 - accuracy: 0.8368\n",
      "Epoch 12/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4004 - accuracy: 0.8333\n",
      "Epoch 13/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4012 - accuracy: 0.8351\n",
      "Epoch 14/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4002 - accuracy: 0.8333\n",
      "Epoch 15/60\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.3991 - accuracy: 0.8351\n",
      "Epoch 16/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.3991 - accuracy: 0.8386\n",
      "Epoch 17/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.3991 - accuracy: 0.8368\n",
      "Epoch 18/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.3993 - accuracy: 0.8316\n",
      "Epoch 19/60\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.3983 - accuracy: 0.8316\n",
      "Epoch 20/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.3995 - accuracy: 0.8386\n",
      "Epoch 21/60\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.3992 - accuracy: 0.8333\n",
      "Epoch 22/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.3980 - accuracy: 0.8333\n",
      "Epoch 23/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.3978 - accuracy: 0.8351\n",
      "Epoch 24/60\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.3979 - accuracy: 0.8386\n",
      "Epoch 25/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 50us/step - loss: 0.3977 - accuracy: 0.8351\n",
      "Epoch 26/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.3981 - accuracy: 0.8333\n",
      "Epoch 27/60\n",
      "570/570 [==============================] - 0s 74us/step - loss: 0.3965 - accuracy: 0.8386\n",
      "Epoch 28/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.3969 - accuracy: 0.8386\n",
      "Epoch 29/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.3964 - accuracy: 0.8316\n",
      "Epoch 30/60\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.3960 - accuracy: 0.8333\n",
      "Epoch 31/60\n",
      "570/570 [==============================] - 0s 40us/step - loss: 0.3962 - accuracy: 0.8404\n",
      "Epoch 32/60\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.3960 - accuracy: 0.8404\n",
      "Epoch 33/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.3950 - accuracy: 0.8333\n",
      "Epoch 34/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.3961 - accuracy: 0.8351\n",
      "Epoch 35/60\n",
      "570/570 [==============================] - 0s 125us/step - loss: 0.3958 - accuracy: 0.8404\n",
      "Epoch 36/60\n",
      "570/570 [==============================] - 0s 105us/step - loss: 0.3966 - accuracy: 0.8351\n",
      "Epoch 37/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.3950 - accuracy: 0.8351\n",
      "Epoch 38/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.3953 - accuracy: 0.8439\n",
      "Epoch 39/60\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.3951 - accuracy: 0.8368\n",
      "Epoch 40/60\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.3947 - accuracy: 0.8368\n",
      "Epoch 41/60\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.3947 - accuracy: 0.8368\n",
      "Epoch 42/60\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.3944 - accuracy: 0.8386\n",
      "Epoch 43/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.3943 - accuracy: 0.8404\n",
      "Epoch 44/60\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.3941 - accuracy: 0.8316\n",
      "Epoch 45/60\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.3936 - accuracy: 0.8386\n",
      "Epoch 46/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.3949 - accuracy: 0.8316\n",
      "Epoch 47/60\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.3936 - accuracy: 0.8351\n",
      "Epoch 48/60\n",
      "570/570 [==============================] - 0s 82us/step - loss: 0.3941 - accuracy: 0.8351\n",
      "Epoch 49/60\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.3930 - accuracy: 0.8333\n",
      "Epoch 50/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.3936 - accuracy: 0.8456\n",
      "Epoch 51/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.3926 - accuracy: 0.8421\n",
      "Epoch 52/60\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.3934 - accuracy: 0.8333\n",
      "Epoch 53/60\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.3924 - accuracy: 0.8421\n",
      "Epoch 54/60\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.3940 - accuracy: 0.8474\n",
      "Epoch 55/60\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.3930 - accuracy: 0.8351\n",
      "Epoch 56/60\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.3915 - accuracy: 0.8368\n",
      "Epoch 57/60\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.3920 - accuracy: 0.8456\n",
      "Epoch 58/60\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.3917 - accuracy: 0.8404\n",
      "Epoch 59/60\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.3928 - accuracy: 0.8421\n",
      "Epoch 60/60\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.3918 - accuracy: 0.8351\n",
      "142/142 [==============================] - 0s 48us/step\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_203 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 497us/step - loss: 0.6583 - accuracy: 0.6489 - val_loss: 0.6370 - val_accuracy: 0.7151\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.6353 - accuracy: 0.6657 - val_loss: 0.6146 - val_accuracy: 0.7151\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.6173 - accuracy: 0.6756 - val_loss: 0.5937 - val_accuracy: 0.7318\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.5996 - accuracy: 0.6882 - val_loss: 0.5730 - val_accuracy: 0.7430\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.5816 - accuracy: 0.7626 - val_loss: 0.5512 - val_accuracy: 0.7542\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.5618 - accuracy: 0.7767 - val_loss: 0.5283 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.5417 - accuracy: 0.7837 - val_loss: 0.5052 - val_accuracy: 0.8045\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.5232 - accuracy: 0.7949 - val_loss: 0.4850 - val_accuracy: 0.7877\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5116 - accuracy: 0.7907 - val_loss: 0.4716 - val_accuracy: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.75 - 0s 64us/step - loss: 0.5002 - accuracy: 0.7921 - val_loss: 0.4598 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4918 - accuracy: 0.7935 - val_loss: 0.4523 - val_accuracy: 0.7877\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4880 - accuracy: 0.7907 - val_loss: 0.4468 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4831 - accuracy: 0.7893 - val_loss: 0.4444 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4803 - accuracy: 0.7893 - val_loss: 0.4409 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4771 - accuracy: 0.7907 - val_loss: 0.4406 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.87 - 0s 70us/step - loss: 0.4772 - accuracy: 0.7893 - val_loss: 0.4363 - val_accuracy: 0.7821\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4748 - accuracy: 0.7907 - val_loss: 0.4362 - val_accuracy: 0.7765\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4751 - accuracy: 0.7893 - val_loss: 0.4347 - val_accuracy: 0.7709\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4716 - accuracy: 0.7907 - val_loss: 0.4367 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4726 - accuracy: 0.7907 - val_loss: 0.4325 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4701 - accuracy: 0.7907 - val_loss: 0.4321 - val_accuracy: 0.7765\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4679 - accuracy: 0.7893 - val_loss: 0.4334 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4677 - accuracy: 0.7879 - val_loss: 0.4314 - val_accuracy: 0.7765\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4686 - accuracy: 0.7935 - val_loss: 0.4302 - val_accuracy: 0.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4656 - accuracy: 0.7851 - val_loss: 0.4307 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4647 - accuracy: 0.7893 - val_loss: 0.4283 - val_accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4645 - accuracy: 0.7907 - val_loss: 0.4284 - val_accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4672 - accuracy: 0.7893 - val_loss: 0.4285 - val_accuracy: 0.7877\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4638 - accuracy: 0.7935 - val_loss: 0.4272 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4658 - accuracy: 0.7851 - val_loss: 0.4271 - val_accuracy: 0.7821\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4689 - accuracy: 0.7935 - val_loss: 0.4304 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4621 - accuracy: 0.7893 - val_loss: 0.4265 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4636 - accuracy: 0.7865 - val_loss: 0.4249 - val_accuracy: 0.7765\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4628 - accuracy: 0.7963 - val_loss: 0.4245 - val_accuracy: 0.7821\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4243 - val_accuracy: 0.7765\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4628 - accuracy: 0.7949 - val_loss: 0.4259 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4632 - accuracy: 0.7865 - val_loss: 0.4249 - val_accuracy: 0.7821\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4597 - accuracy: 0.7893 - val_loss: 0.4228 - val_accuracy: 0.7765\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4601 - accuracy: 0.7907 - val_loss: 0.4209 - val_accuracy: 0.7877\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4588 - accuracy: 0.7893 - val_loss: 0.4244 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4603 - accuracy: 0.7879 - val_loss: 0.4210 - val_accuracy: 0.7821\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4640 - accuracy: 0.7949 - val_loss: 0.4238 - val_accuracy: 0.7877\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4585 - accuracy: 0.7921 - val_loss: 0.4220 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4572 - accuracy: 0.7907 - val_loss: 0.4242 - val_accuracy: 0.7821\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4591 - accuracy: 0.7907 - val_loss: 0.4243 - val_accuracy: 0.7877\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4573 - accuracy: 0.7921 - val_loss: 0.4230 - val_accuracy: 0.7877\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4565 - accuracy: 0.7921 - val_loss: 0.4236 - val_accuracy: 0.7877\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4566 - accuracy: 0.7907 - val_loss: 0.4222 - val_accuracy: 0.7877\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4577 - accuracy: 0.7893 - val_loss: 0.4208 - val_accuracy: 0.7933\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4565 - accuracy: 0.7921 - val_loss: 0.4202 - val_accuracy: 0.7877\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4585 - accuracy: 0.7921 - val_loss: 0.4190 - val_accuracy: 0.7877\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4588 - accuracy: 0.7935 - val_loss: 0.4251 - val_accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4573 - accuracy: 0.7992 - val_loss: 0.4210 - val_accuracy: 0.7933\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4559 - accuracy: 0.7921 - val_loss: 0.4220 - val_accuracy: 0.7933\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4559 - accuracy: 0.7921 - val_loss: 0.4218 - val_accuracy: 0.7877\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4560 - accuracy: 0.7949 - val_loss: 0.4200 - val_accuracy: 0.7933\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4572 - accuracy: 0.7893 - val_loss: 0.4179 - val_accuracy: 0.8045\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4554 - accuracy: 0.7907 - val_loss: 0.4178 - val_accuracy: 0.7933\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4564 - accuracy: 0.7935 - val_loss: 0.4171 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4576 - accuracy: 0.7879 - val_loss: 0.4151 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4565 - accuracy: 0.7978 - val_loss: 0.4171 - val_accuracy: 0.7933\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4546 - accuracy: 0.7963 - val_loss: 0.4196 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4545 - accuracy: 0.7921 - val_loss: 0.4194 - val_accuracy: 0.7877\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4545 - accuracy: 0.7949 - val_loss: 0.4188 - val_accuracy: 0.7933\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4538 - accuracy: 0.7949 - val_loss: 0.4157 - val_accuracy: 0.7933\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4539 - accuracy: 0.7921 - val_loss: 0.4157 - val_accuracy: 0.7933\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4532 - accuracy: 0.7949 - val_loss: 0.4155 - val_accuracy: 0.7933\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4556 - accuracy: 0.7935 - val_loss: 0.4148 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4527 - accuracy: 0.7949 - val_loss: 0.4167 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4537 - accuracy: 0.7907 - val_loss: 0.4151 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.4526 - accuracy: 0.7935 - val_loss: 0.4178 - val_accuracy: 0.7933\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4530 - accuracy: 0.7935 - val_loss: 0.4171 - val_accuracy: 0.7933\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4516 - accuracy: 0.7978 - val_loss: 0.4164 - val_accuracy: 0.8045\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4512 - accuracy: 0.7935 - val_loss: 0.4147 - val_accuracy: 0.7989\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4532 - accuracy: 0.7949 - val_loss: 0.4137 - val_accuracy: 0.8045\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4530 - accuracy: 0.7963 - val_loss: 0.4195 - val_accuracy: 0.7933\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4520 - accuracy: 0.7935 - val_loss: 0.4135 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4496 - accuracy: 0.7963 - val_loss: 0.4157 - val_accuracy: 0.7933\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4511 - accuracy: 0.7949 - val_loss: 0.4145 - val_accuracy: 0.7933\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4546 - accuracy: 0.7935 - val_loss: 0.4146 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 103us/step - loss: 0.4495 - accuracy: 0.7963 - val_loss: 0.4151 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4500 - accuracy: 0.7949 - val_loss: 0.4120 - val_accuracy: 0.7989\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4477 - accuracy: 0.7978 - val_loss: 0.4121 - val_accuracy: 0.7989\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4474 - accuracy: 0.7949 - val_loss: 0.4133 - val_accuracy: 0.7989\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4477 - accuracy: 0.7963 - val_loss: 0.4134 - val_accuracy: 0.7989\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4479 - accuracy: 0.7978 - val_loss: 0.4115 - val_accuracy: 0.7989\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.80 - 0s 112us/step - loss: 0.4470 - accuracy: 0.7949 - val_loss: 0.4151 - val_accuracy: 0.7933\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4475 - accuracy: 0.7921 - val_loss: 0.4126 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4470 - accuracy: 0.8006 - val_loss: 0.4124 - val_accuracy: 0.7933\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4460 - accuracy: 0.7949 - val_loss: 0.4163 - val_accuracy: 0.7989\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4491 - accuracy: 0.7935 - val_loss: 0.4109 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4469 - accuracy: 0.7992 - val_loss: 0.4125 - val_accuracy: 0.7933\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4439 - accuracy: 0.7963 - val_loss: 0.4138 - val_accuracy: 0.7877\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 54us/step - loss: 0.4439 - accuracy: 0.7978 - val_loss: 0.4126 - val_accuracy: 0.7933\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4429 - accuracy: 0.8020 - val_loss: 0.4108 - val_accuracy: 0.7933\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4434 - accuracy: 0.7978 - val_loss: 0.4095 - val_accuracy: 0.8045\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4419 - accuracy: 0.7949 - val_loss: 0.4099 - val_accuracy: 0.7933\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4423 - accuracy: 0.7992 - val_loss: 0.4094 - val_accuracy: 0.7933\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4406 - accuracy: 0.7992 - val_loss: 0.4088 - val_accuracy: 0.7933\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4392 - accuracy: 0.8006 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 1/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4245 - accuracy: 0.8032\n",
      "Epoch 2/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4239 - accuracy: 0.8049\n",
      "Epoch 3/90\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4227 - accuracy: 0.8049\n",
      "Epoch 4/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4224 - accuracy: 0.8049\n",
      "Epoch 5/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4222 - accuracy: 0.8049\n",
      "Epoch 6/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4220 - accuracy: 0.8049\n",
      "Epoch 7/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4212 - accuracy: 0.8049\n",
      "Epoch 8/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4220 - accuracy: 0.8032\n",
      "Epoch 9/90\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4209 - accuracy: 0.8067\n",
      "Epoch 10/90\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4209 - accuracy: 0.8049\n",
      "Epoch 11/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4231 - accuracy: 0.8067\n",
      "Epoch 12/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4212 - accuracy: 0.8067\n",
      "Epoch 13/90\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4212 - accuracy: 0.8049\n",
      "Epoch 14/90\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4201 - accuracy: 0.8049\n",
      "Epoch 15/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4200 - accuracy: 0.8084\n",
      "Epoch 16/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4194 - accuracy: 0.8084\n",
      "Epoch 17/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4192 - accuracy: 0.8084\n",
      "Epoch 18/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4191 - accuracy: 0.8049\n",
      "Epoch 19/90\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4177 - accuracy: 0.8067\n",
      "Epoch 20/90\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4175 - accuracy: 0.8084\n",
      "Epoch 21/90\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4173 - accuracy: 0.8084\n",
      "Epoch 22/90\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4177 - accuracy: 0.8102\n",
      "Epoch 23/90\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4182 - accuracy: 0.8102\n",
      "Epoch 24/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4168 - accuracy: 0.8102\n",
      "Epoch 25/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4162 - accuracy: 0.8102\n",
      "Epoch 26/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4160 - accuracy: 0.8084\n",
      "Epoch 27/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4158 - accuracy: 0.8084\n",
      "Epoch 28/90\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4173 - accuracy: 0.8049\n",
      "Epoch 29/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4153 - accuracy: 0.8137\n",
      "Epoch 30/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4161 - accuracy: 0.8102\n",
      "Epoch 31/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4152 - accuracy: 0.8049\n",
      "Epoch 32/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4149 - accuracy: 0.8084\n",
      "Epoch 33/90\n",
      "569/569 [==============================] - 0s 67us/step - loss: 0.4146 - accuracy: 0.8120\n",
      "Epoch 34/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4144 - accuracy: 0.8120\n",
      "Epoch 35/90\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4139 - accuracy: 0.8084\n",
      "Epoch 36/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4141 - accuracy: 0.8084\n",
      "Epoch 37/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4144 - accuracy: 0.8084\n",
      "Epoch 38/90\n",
      "569/569 [==============================] - 0s 74us/step - loss: 0.4185 - accuracy: 0.8102\n",
      "Epoch 39/90\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4119 - accuracy: 0.8084\n",
      "Epoch 40/90\n",
      "569/569 [==============================] - 0s 69us/step - loss: 0.4148 - accuracy: 0.8137\n",
      "Epoch 41/90\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4127 - accuracy: 0.8120\n",
      "Epoch 42/90\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4127 - accuracy: 0.8084\n",
      "Epoch 43/90\n",
      "569/569 [==============================] - 0s 43us/step - loss: 0.4129 - accuracy: 0.8120\n",
      "Epoch 44/90\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4136 - accuracy: 0.8120\n",
      "Epoch 45/90\n",
      "569/569 [==============================] - 0s 68us/step - loss: 0.4122 - accuracy: 0.8102\n",
      "Epoch 46/90\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4126 - accuracy: 0.8137\n",
      "Epoch 47/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4115 - accuracy: 0.8102\n",
      "Epoch 48/90\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.4109 - accuracy: 0.8120\n",
      "Epoch 49/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4114 - accuracy: 0.8102\n",
      "Epoch 50/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4112 - accuracy: 0.8137\n",
      "Epoch 51/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4110 - accuracy: 0.8137\n",
      "Epoch 52/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 57us/step - loss: 0.4111 - accuracy: 0.8137\n",
      "Epoch 53/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4108 - accuracy: 0.8120\n",
      "Epoch 54/90\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4112 - accuracy: 0.8172\n",
      "Epoch 55/90\n",
      "569/569 [==============================] - 0s 43us/step - loss: 0.4107 - accuracy: 0.8155\n",
      "Epoch 56/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4102 - accuracy: 0.8137\n",
      "Epoch 57/90\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4105 - accuracy: 0.8102\n",
      "Epoch 58/90\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4104 - accuracy: 0.8137\n",
      "Epoch 59/90\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.4089 - accuracy: 0.8190\n",
      "Epoch 60/90\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.4113 - accuracy: 0.8137\n",
      "Epoch 61/90\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4080 - accuracy: 0.8172\n",
      "Epoch 62/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4101 - accuracy: 0.8190\n",
      "Epoch 63/90\n",
      "569/569 [==============================] - 0s 44us/step - loss: 0.4077 - accuracy: 0.8155\n",
      "Epoch 64/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4079 - accuracy: 0.8137\n",
      "Epoch 65/90\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4078 - accuracy: 0.8190\n",
      "Epoch 66/90\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.4102 - accuracy: 0.8225\n",
      "Epoch 67/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4074 - accuracy: 0.8190\n",
      "Epoch 68/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4069 - accuracy: 0.8172\n",
      "Epoch 69/90\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4075 - accuracy: 0.8207\n",
      "Epoch 70/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4078 - accuracy: 0.8243\n",
      "Epoch 71/90\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4092 - accuracy: 0.8190\n",
      "Epoch 72/90\n",
      "569/569 [==============================] - 0s 103us/step - loss: 0.4062 - accuracy: 0.8225\n",
      "Epoch 73/90\n",
      "569/569 [==============================] - 0s 192us/step - loss: 0.4070 - accuracy: 0.8243\n",
      "Epoch 74/90\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4070 - accuracy: 0.8207\n",
      "Epoch 75/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4080 - accuracy: 0.8243\n",
      "Epoch 76/90\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4058 - accuracy: 0.8243\n",
      "Epoch 77/90\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4054 - accuracy: 0.8207\n",
      "Epoch 78/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4058 - accuracy: 0.8260\n",
      "Epoch 79/90\n",
      "569/569 [==============================] - 0s 77us/step - loss: 0.4054 - accuracy: 0.8243\n",
      "Epoch 80/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4048 - accuracy: 0.8207\n",
      "Epoch 81/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4056 - accuracy: 0.8243\n",
      "Epoch 82/90\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4053 - accuracy: 0.8225\n",
      "Epoch 83/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4049 - accuracy: 0.8243\n",
      "Epoch 84/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4050 - accuracy: 0.8260\n",
      "Epoch 85/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4036 - accuracy: 0.8243\n",
      "Epoch 86/90\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4040 - accuracy: 0.8243\n",
      "Epoch 87/90\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4036 - accuracy: 0.8260\n",
      "Epoch 88/90\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4036 - accuracy: 0.8243\n",
      "Epoch 89/90\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4041 - accuracy: 0.8278\n",
      "Epoch 90/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4039 - accuracy: 0.8278\n",
      "143/143 [==============================] - 0s 52us/step\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_207 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 507us/step - loss: 0.7138 - accuracy: 0.5801 - val_loss: 0.7123 - val_accuracy: 0.5698\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.6799 - accuracy: 0.5787 - val_loss: 0.6657 - val_accuracy: 0.6257\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6470 - accuracy: 0.6348 - val_loss: 0.6136 - val_accuracy: 0.6536\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.6082 - accuracy: 0.6615 - val_loss: 0.5605 - val_accuracy: 0.7486\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.5721 - accuracy: 0.7275 - val_loss: 0.5157 - val_accuracy: 0.7989\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.5453 - accuracy: 0.7584 - val_loss: 0.4851 - val_accuracy: 0.7765\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.5247 - accuracy: 0.7669 - val_loss: 0.4661 - val_accuracy: 0.8101\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.5069 - accuracy: 0.7753 - val_loss: 0.4493 - val_accuracy: 0.8045\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4968 - accuracy: 0.7725 - val_loss: 0.4417 - val_accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4867 - accuracy: 0.7795 - val_loss: 0.4368 - val_accuracy: 0.7877\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4820 - accuracy: 0.7823 - val_loss: 0.4319 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4799 - accuracy: 0.7837 - val_loss: 0.4293 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.4780 - accuracy: 0.7823 - val_loss: 0.4269 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4734 - accuracy: 0.7837 - val_loss: 0.4226 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4716 - accuracy: 0.7823 - val_loss: 0.4222 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4693 - accuracy: 0.7837 - val_loss: 0.4206 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4682 - accuracy: 0.7809 - val_loss: 0.4194 - val_accuracy: 0.7821\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4186 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4643 - accuracy: 0.7879 - val_loss: 0.4184 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4620 - accuracy: 0.7879 - val_loss: 0.4166 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4609 - accuracy: 0.7851 - val_loss: 0.4156 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.80 - 0s 121us/step - loss: 0.4593 - accuracy: 0.7921 - val_loss: 0.4149 - val_accuracy: 0.7989\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 96us/step - loss: 0.4620 - accuracy: 0.7893 - val_loss: 0.4145 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4570 - accuracy: 0.7921 - val_loss: 0.4152 - val_accuracy: 0.7877\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4557 - accuracy: 0.7907 - val_loss: 0.4120 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4565 - accuracy: 0.7851 - val_loss: 0.4141 - val_accuracy: 0.7821\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.4548 - accuracy: 0.7921 - val_loss: 0.4122 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4533 - accuracy: 0.7963 - val_loss: 0.4110 - val_accuracy: 0.7933\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4523 - accuracy: 0.7921 - val_loss: 0.4119 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4507 - accuracy: 0.7879 - val_loss: 0.4081 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4499 - accuracy: 0.7921 - val_loss: 0.4112 - val_accuracy: 0.7877\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4505 - accuracy: 0.7935 - val_loss: 0.4087 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4511 - accuracy: 0.7935 - val_loss: 0.4081 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4477 - accuracy: 0.7935 - val_loss: 0.4068 - val_accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4480 - accuracy: 0.7949 - val_loss: 0.4078 - val_accuracy: 0.7989\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4486 - accuracy: 0.7978 - val_loss: 0.4038 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4454 - accuracy: 0.7949 - val_loss: 0.4058 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4453 - accuracy: 0.7963 - val_loss: 0.4079 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4464 - accuracy: 0.7978 - val_loss: 0.4103 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4432 - accuracy: 0.8048 - val_loss: 0.4050 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4465 - accuracy: 0.8048 - val_loss: 0.4079 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4416 - accuracy: 0.8006 - val_loss: 0.4038 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4444 - accuracy: 0.7949 - val_loss: 0.4034 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4409 - accuracy: 0.8006 - val_loss: 0.4056 - val_accuracy: 0.7989\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4402 - accuracy: 0.8048 - val_loss: 0.4040 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4426 - accuracy: 0.8006 - val_loss: 0.4040 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4410 - accuracy: 0.8048 - val_loss: 0.4017 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4380 - accuracy: 0.8076 - val_loss: 0.4013 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4377 - accuracy: 0.8076 - val_loss: 0.4031 - val_accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4391 - accuracy: 0.8118 - val_loss: 0.4001 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4368 - accuracy: 0.8034 - val_loss: 0.3998 - val_accuracy: 0.8045\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4374 - accuracy: 0.8090 - val_loss: 0.3999 - val_accuracy: 0.8045\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4365 - accuracy: 0.8020 - val_loss: 0.4007 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4338 - accuracy: 0.8118 - val_loss: 0.3964 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4338 - accuracy: 0.8104 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4337 - accuracy: 0.8132 - val_loss: 0.3984 - val_accuracy: 0.8101\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4335 - accuracy: 0.8104 - val_loss: 0.3964 - val_accuracy: 0.8156\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4338 - accuracy: 0.8090 - val_loss: 0.3968 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4322 - accuracy: 0.8090 - val_loss: 0.4036 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4323 - accuracy: 0.8174 - val_loss: 0.3984 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4306 - accuracy: 0.8118 - val_loss: 0.4005 - val_accuracy: 0.8156\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4308 - accuracy: 0.8132 - val_loss: 0.3951 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4316 - accuracy: 0.8118 - val_loss: 0.3971 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4292 - accuracy: 0.8090 - val_loss: 0.3955 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4296 - accuracy: 0.8146 - val_loss: 0.3992 - val_accuracy: 0.7989\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4288 - accuracy: 0.8118 - val_loss: 0.3970 - val_accuracy: 0.8045\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4288 - accuracy: 0.8160 - val_loss: 0.3963 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4280 - accuracy: 0.8104 - val_loss: 0.3962 - val_accuracy: 0.7989\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4270 - accuracy: 0.8104 - val_loss: 0.3996 - val_accuracy: 0.8045\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4294 - accuracy: 0.8202 - val_loss: 0.3964 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4280 - accuracy: 0.8132 - val_loss: 0.3967 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4264 - accuracy: 0.8118 - val_loss: 0.4010 - val_accuracy: 0.7933\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4265 - accuracy: 0.8160 - val_loss: 0.3963 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.4305 - accuracy: 0.8146 - val_loss: 0.3992 - val_accuracy: 0.7989\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4283 - accuracy: 0.8118 - val_loss: 0.3952 - val_accuracy: 0.7989\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.4251 - accuracy: 0.8104 - val_loss: 0.3937 - val_accuracy: 0.7989\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4284 - accuracy: 0.8202 - val_loss: 0.4007 - val_accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4244 - accuracy: 0.8174 - val_loss: 0.3983 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 108us/step - loss: 0.4242 - accuracy: 0.8146 - val_loss: 0.3980 - val_accuracy: 0.7989\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4230 - accuracy: 0.8188 - val_loss: 0.4025 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4252 - accuracy: 0.8244 - val_loss: 0.3988 - val_accuracy: 0.7933\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4251 - accuracy: 0.8104 - val_loss: 0.4016 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4258 - accuracy: 0.8160 - val_loss: 0.3963 - val_accuracy: 0.7989\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4212 - accuracy: 0.8202 - val_loss: 0.3998 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4206 - accuracy: 0.8230 - val_loss: 0.3965 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4268 - accuracy: 0.8132 - val_loss: 0.4006 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4233 - accuracy: 0.8146 - val_loss: 0.4020 - val_accuracy: 0.8045\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4205 - accuracy: 0.8216 - val_loss: 0.3961 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4204 - accuracy: 0.8160 - val_loss: 0.3966 - val_accuracy: 0.8045\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4184 - accuracy: 0.8188 - val_loss: 0.3963 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4205 - accuracy: 0.8216 - val_loss: 0.3996 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4192 - accuracy: 0.8174 - val_loss: 0.3975 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4184 - accuracy: 0.8230 - val_loss: 0.4030 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4182 - accuracy: 0.8202 - val_loss: 0.3961 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4173 - accuracy: 0.8202 - val_loss: 0.3948 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4209 - accuracy: 0.8202 - val_loss: 0.3964 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4169 - accuracy: 0.8216 - val_loss: 0.4048 - val_accuracy: 0.8045\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4172 - accuracy: 0.8202 - val_loss: 0.3958 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4210 - accuracy: 0.8216 - val_loss: 0.3953 - val_accuracy: 0.8268\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4186 - accuracy: 0.8244 - val_loss: 0.4016 - val_accuracy: 0.8045\n",
      "Epoch 1/90\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4313 - accuracy: 0.8067\n",
      "Epoch 2/90\n",
      "569/569 [==============================] - 0s 68us/step - loss: 0.4262 - accuracy: 0.8137\n",
      "Epoch 3/90\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4265 - accuracy: 0.8137\n",
      "Epoch 4/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4262 - accuracy: 0.8207\n",
      "Epoch 5/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4255 - accuracy: 0.8190\n",
      "Epoch 6/90\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4254 - accuracy: 0.8172\n",
      "Epoch 7/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4252 - accuracy: 0.8207\n",
      "Epoch 8/90\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4252 - accuracy: 0.8137\n",
      "Epoch 9/90\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4242 - accuracy: 0.8207\n",
      "Epoch 10/90\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4254 - accuracy: 0.8172\n",
      "Epoch 11/90\n",
      "569/569 [==============================] - 0s 78us/step - loss: 0.4246 - accuracy: 0.8172\n",
      "Epoch 12/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4247 - accuracy: 0.8155\n",
      "Epoch 13/90\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.4272 - accuracy: 0.8067\n",
      "Epoch 14/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4288 - accuracy: 0.8190\n",
      "Epoch 15/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4255 - accuracy: 0.8137\n",
      "Epoch 16/90\n",
      "569/569 [==============================] - 0s 63us/step - loss: 0.4234 - accuracy: 0.8155\n",
      "Epoch 17/90\n",
      "569/569 [==============================] - 0s 30us/step - loss: 0.4231 - accuracy: 0.8190\n",
      "Epoch 18/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4236 - accuracy: 0.8190\n",
      "Epoch 19/90\n",
      "569/569 [==============================] - 0s 86us/step - loss: 0.4225 - accuracy: 0.8172\n",
      "Epoch 20/90\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4239 - accuracy: 0.8155\n",
      "Epoch 21/90\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4229 - accuracy: 0.8172\n",
      "Epoch 22/90\n",
      "569/569 [==============================] - 0s 84us/step - loss: 0.4224 - accuracy: 0.8207\n",
      "Epoch 23/90\n",
      "569/569 [==============================] - 0s 62us/step - loss: 0.4226 - accuracy: 0.8137\n",
      "Epoch 24/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4224 - accuracy: 0.8172\n",
      "Epoch 25/90\n",
      "569/569 [==============================] - 0s 79us/step - loss: 0.4224 - accuracy: 0.8190\n",
      "Epoch 26/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4257 - accuracy: 0.8190\n",
      "Epoch 27/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4224 - accuracy: 0.8137\n",
      "Epoch 28/90\n",
      "569/569 [==============================] - 0s 65us/step - loss: 0.4221 - accuracy: 0.8137\n",
      "Epoch 29/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4223 - accuracy: 0.8172\n",
      "Epoch 30/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4213 - accuracy: 0.8155\n",
      "Epoch 31/90\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4219 - accuracy: 0.8190\n",
      "Epoch 32/90\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4233 - accuracy: 0.8120\n",
      "Epoch 33/90\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4212 - accuracy: 0.8172\n",
      "Epoch 34/90\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4212 - accuracy: 0.8190\n",
      "Epoch 35/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4219 - accuracy: 0.8190\n",
      "Epoch 36/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4212 - accuracy: 0.8172\n",
      "Epoch 37/90\n",
      "569/569 [==============================] - 0s 75us/step - loss: 0.4207 - accuracy: 0.8120\n",
      "Epoch 38/90\n",
      "569/569 [==============================] - 0s 66us/step - loss: 0.4196 - accuracy: 0.8137\n",
      "Epoch 39/90\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4221 - accuracy: 0.8190\n",
      "Epoch 40/90\n",
      "569/569 [==============================] - 0s 73us/step - loss: 0.4190 - accuracy: 0.8172\n",
      "Epoch 41/90\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4219 - accuracy: 0.8067\n",
      "Epoch 42/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4199 - accuracy: 0.8155\n",
      "Epoch 43/90\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4198 - accuracy: 0.8155\n",
      "Epoch 44/90\n",
      "569/569 [==============================] - 0s 68us/step - loss: 0.4195 - accuracy: 0.8172\n",
      "Epoch 45/90\n",
      "569/569 [==============================] - 0s 54us/step - loss: 0.4199 - accuracy: 0.8172\n",
      "Epoch 46/90\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4190 - accuracy: 0.8172\n",
      "Epoch 47/90\n",
      "569/569 [==============================] - 0s 71us/step - loss: 0.4197 - accuracy: 0.8155\n",
      "Epoch 48/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4195 - accuracy: 0.8190\n",
      "Epoch 49/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4199 - accuracy: 0.8084\n",
      "Epoch 50/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 54us/step - loss: 0.4204 - accuracy: 0.8207\n",
      "Epoch 51/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4187 - accuracy: 0.8137\n",
      "Epoch 52/90\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4191 - accuracy: 0.8190\n",
      "Epoch 53/90\n",
      "569/569 [==============================] - 0s 56us/step - loss: 0.4183 - accuracy: 0.8172\n",
      "Epoch 54/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4207 - accuracy: 0.8243\n",
      "Epoch 55/90\n",
      "569/569 [==============================] - 0s 46us/step - loss: 0.4170 - accuracy: 0.8207\n",
      "Epoch 56/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4193 - accuracy: 0.8155\n",
      "Epoch 57/90\n",
      "569/569 [==============================] - 0s 80us/step - loss: 0.4176 - accuracy: 0.8155\n",
      "Epoch 58/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4173 - accuracy: 0.8190\n",
      "Epoch 59/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4188 - accuracy: 0.8137\n",
      "Epoch 60/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4180 - accuracy: 0.8155\n",
      "Epoch 61/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4178 - accuracy: 0.8120\n",
      "Epoch 62/90\n",
      "569/569 [==============================] - 0s 91us/step - loss: 0.4173 - accuracy: 0.8190\n",
      "Epoch 63/90\n",
      "569/569 [==============================] - 0s 49us/step - loss: 0.4164 - accuracy: 0.8155\n",
      "Epoch 64/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4197 - accuracy: 0.8067\n",
      "Epoch 65/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4191 - accuracy: 0.8225\n",
      "Epoch 66/90\n",
      "569/569 [==============================] - 0s 55us/step - loss: 0.4160 - accuracy: 0.8190\n",
      "Epoch 67/90\n",
      "569/569 [==============================] - 0s 51us/step - loss: 0.4166 - accuracy: 0.8120\n",
      "Epoch 68/90\n",
      "569/569 [==============================] - 0s 58us/step - loss: 0.4164 - accuracy: 0.8207\n",
      "Epoch 69/90\n",
      "569/569 [==============================] - 0s 50us/step - loss: 0.4162 - accuracy: 0.8190\n",
      "Epoch 70/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4171 - accuracy: 0.8102\n",
      "Epoch 71/90\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.4173 - accuracy: 0.8225\n",
      "Epoch 72/90\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.83 - 0s 60us/step - loss: 0.4162 - accuracy: 0.8172\n",
      "Epoch 73/90\n",
      "569/569 [==============================] - 0s 52us/step - loss: 0.4157 - accuracy: 0.8172\n",
      "Epoch 74/90\n",
      "569/569 [==============================] - 0s 61us/step - loss: 0.4154 - accuracy: 0.8190\n",
      "Epoch 75/90\n",
      "569/569 [==============================] - 0s 64us/step - loss: 0.4157 - accuracy: 0.8155\n",
      "Epoch 76/90\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.4171 - accuracy: 0.8225\n",
      "Epoch 77/90\n",
      "569/569 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.8155\n",
      "Epoch 78/90\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.4152 - accuracy: 0.8155\n",
      "Epoch 79/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4144 - accuracy: 0.8207\n",
      "Epoch 80/90\n",
      "569/569 [==============================] - 0s 48us/step - loss: 0.4164 - accuracy: 0.8207\n",
      "Epoch 81/90\n",
      "569/569 [==============================] - 0s 72us/step - loss: 0.4159 - accuracy: 0.8207\n",
      "Epoch 82/90\n",
      "569/569 [==============================] - 0s 96us/step - loss: 0.4154 - accuracy: 0.8243\n",
      "Epoch 83/90\n",
      "569/569 [==============================] - 0s 115us/step - loss: 0.4144 - accuracy: 0.8190\n",
      "Epoch 84/90\n",
      "569/569 [==============================] - 0s 81us/step - loss: 0.4143 - accuracy: 0.8190\n",
      "Epoch 85/90\n",
      "569/569 [==============================] - 0s 59us/step - loss: 0.4142 - accuracy: 0.8225\n",
      "Epoch 86/90\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.8172\n",
      "Epoch 87/90\n",
      "569/569 [==============================] - 0s 57us/step - loss: 0.4175 - accuracy: 0.8225\n",
      "Epoch 88/90\n",
      "569/569 [==============================] - 0s 47us/step - loss: 0.4172 - accuracy: 0.8137\n",
      "Epoch 89/90\n",
      "569/569 [==============================] - 0s 60us/step - loss: 0.4143 - accuracy: 0.8172\n",
      "Epoch 90/90\n",
      "569/569 [==============================] - 0s 53us/step - loss: 0.4143 - accuracy: 0.8260\n",
      "143/143 [==============================] - 0s 43us/step\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_211 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 746us/step - loss: 0.7316 - accuracy: 0.6166 - val_loss: 0.6884 - val_accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6591 - accuracy: 0.6166 - val_loss: 0.6528 - val_accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6478 - accuracy: 0.6180 - val_loss: 0.6433 - val_accuracy: 0.6201\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.6400 - accuracy: 0.6180 - val_loss: 0.6331 - val_accuracy: 0.6201\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6298 - accuracy: 0.6306 - val_loss: 0.6199 - val_accuracy: 0.6480\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6171 - accuracy: 0.6475 - val_loss: 0.6060 - val_accuracy: 0.6816\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.6027 - accuracy: 0.6728 - val_loss: 0.5870 - val_accuracy: 0.7095\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5862 - accuracy: 0.6756 - val_loss: 0.5676 - val_accuracy: 0.7095\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5694 - accuracy: 0.7626 - val_loss: 0.5480 - val_accuracy: 0.7318\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.5515 - accuracy: 0.7612 - val_loss: 0.5282 - val_accuracy: 0.7765\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.5336 - accuracy: 0.7893 - val_loss: 0.5104 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.5232 - accuracy: 0.7893 - val_loss: 0.4984 - val_accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5084 - accuracy: 0.7893 - val_loss: 0.4813 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.5029 - accuracy: 0.7893 - val_loss: 0.4765 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4938 - accuracy: 0.7851 - val_loss: 0.4665 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4878 - accuracy: 0.7879 - val_loss: 0.4596 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 186us/step - loss: 0.4824 - accuracy: 0.7879 - val_loss: 0.4541 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.4501 - val_accuracy: 0.7877\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4742 - accuracy: 0.7865 - val_loss: 0.4467 - val_accuracy: 0.7877\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4730 - accuracy: 0.7921 - val_loss: 0.4435 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4727 - accuracy: 0.7907 - val_loss: 0.4406 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4690 - accuracy: 0.7907 - val_loss: 0.4384 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4625 - accuracy: 0.7907 - val_loss: 0.4350 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4585 - accuracy: 0.7935 - val_loss: 0.4310 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4584 - accuracy: 0.7907 - val_loss: 0.4261 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4537 - accuracy: 0.7963 - val_loss: 0.4280 - val_accuracy: 0.7877\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4552 - accuracy: 0.7921 - val_loss: 0.4229 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4495 - accuracy: 0.7963 - val_loss: 0.4237 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4559 - accuracy: 0.7992 - val_loss: 0.4173 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4463 - accuracy: 0.7949 - val_loss: 0.4256 - val_accuracy: 0.7989\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4522 - accuracy: 0.8076 - val_loss: 0.4162 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4444 - accuracy: 0.7992 - val_loss: 0.4121 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4433 - accuracy: 0.8034 - val_loss: 0.4252 - val_accuracy: 0.8101\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4456 - accuracy: 0.7992 - val_loss: 0.4108 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4444 - accuracy: 0.8062 - val_loss: 0.4123 - val_accuracy: 0.8101\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4440 - accuracy: 0.7992 - val_loss: 0.4072 - val_accuracy: 0.8045\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4437 - accuracy: 0.8048 - val_loss: 0.4107 - val_accuracy: 0.8045\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4382 - accuracy: 0.8090 - val_loss: 0.4042 - val_accuracy: 0.8045\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4351 - accuracy: 0.8090 - val_loss: 0.4049 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4324 - accuracy: 0.8090 - val_loss: 0.4026 - val_accuracy: 0.8101\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4323 - accuracy: 0.8118 - val_loss: 0.4038 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.4314 - accuracy: 0.8118 - val_loss: 0.4025 - val_accuracy: 0.8101\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4311 - accuracy: 0.8090 - val_loss: 0.4024 - val_accuracy: 0.7989\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4293 - accuracy: 0.8118 - val_loss: 0.3992 - val_accuracy: 0.8156\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4293 - accuracy: 0.8174 - val_loss: 0.4002 - val_accuracy: 0.8101\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4308 - accuracy: 0.8118 - val_loss: 0.3974 - val_accuracy: 0.8101\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4310 - accuracy: 0.8160 - val_loss: 0.3995 - val_accuracy: 0.8045\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4315 - accuracy: 0.8160 - val_loss: 0.4009 - val_accuracy: 0.7933\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4266 - accuracy: 0.8174 - val_loss: 0.3942 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4283 - accuracy: 0.8188 - val_loss: 0.3966 - val_accuracy: 0.8156\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4241 - accuracy: 0.8188 - val_loss: 0.3952 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4248 - accuracy: 0.8146 - val_loss: 0.3971 - val_accuracy: 0.8101\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4232 - accuracy: 0.8202 - val_loss: 0.3968 - val_accuracy: 0.8101\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4224 - accuracy: 0.8188 - val_loss: 0.3953 - val_accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4245 - accuracy: 0.8258 - val_loss: 0.3928 - val_accuracy: 0.8268\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4257 - accuracy: 0.8202 - val_loss: 0.3932 - val_accuracy: 0.8268\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4224 - accuracy: 0.8188 - val_loss: 0.3961 - val_accuracy: 0.8156\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4195 - accuracy: 0.8216 - val_loss: 0.3923 - val_accuracy: 0.8212\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4224 - accuracy: 0.8216 - val_loss: 0.3944 - val_accuracy: 0.8212\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4184 - accuracy: 0.8287 - val_loss: 0.3980 - val_accuracy: 0.8101\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4208 - accuracy: 0.8230 - val_loss: 0.3963 - val_accuracy: 0.8212\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4184 - accuracy: 0.8216 - val_loss: 0.3951 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4209 - accuracy: 0.8230 - val_loss: 0.3939 - val_accuracy: 0.8212\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4192 - accuracy: 0.8244 - val_loss: 0.3927 - val_accuracy: 0.8156\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4199 - accuracy: 0.8272 - val_loss: 0.3954 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4208 - accuracy: 0.8118 - val_loss: 0.3957 - val_accuracy: 0.8268\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4200 - accuracy: 0.8244 - val_loss: 0.3935 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4221 - accuracy: 0.8244 - val_loss: 0.3930 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4212 - accuracy: 0.8343 - val_loss: 0.3947 - val_accuracy: 0.8212\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4164 - accuracy: 0.8329 - val_loss: 0.3978 - val_accuracy: 0.7989\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4278 - accuracy: 0.8076 - val_loss: 0.4006 - val_accuracy: 0.8268\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4172 - accuracy: 0.8258 - val_loss: 0.3941 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4188 - accuracy: 0.8244 - val_loss: 0.3968 - val_accuracy: 0.7989\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4238 - accuracy: 0.8244 - val_loss: 0.3944 - val_accuracy: 0.8212\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4187 - accuracy: 0.8230 - val_loss: 0.3913 - val_accuracy: 0.8212\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4146 - accuracy: 0.8287 - val_loss: 0.3996 - val_accuracy: 0.7933\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4222 - accuracy: 0.8244 - val_loss: 0.3958 - val_accuracy: 0.8212\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 90us/step - loss: 0.4170 - accuracy: 0.8287 - val_loss: 0.3904 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4141 - accuracy: 0.8258 - val_loss: 0.3916 - val_accuracy: 0.8268\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4166 - accuracy: 0.8287 - val_loss: 0.3945 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4129 - accuracy: 0.8287 - val_loss: 0.3918 - val_accuracy: 0.8156\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4141 - accuracy: 0.8301 - val_loss: 0.3958 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4165 - accuracy: 0.8216 - val_loss: 0.3906 - val_accuracy: 0.8268\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4140 - accuracy: 0.8287 - val_loss: 0.3912 - val_accuracy: 0.8045\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4146 - accuracy: 0.8287 - val_loss: 0.3962 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4129 - accuracy: 0.8272 - val_loss: 0.3909 - val_accuracy: 0.8268\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4135 - accuracy: 0.8343 - val_loss: 0.3899 - val_accuracy: 0.8212\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4155 - accuracy: 0.8244 - val_loss: 0.3922 - val_accuracy: 0.8212\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4130 - accuracy: 0.8244 - val_loss: 0.3957 - val_accuracy: 0.8268\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4137 - accuracy: 0.8329 - val_loss: 0.3939 - val_accuracy: 0.8156\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4128 - accuracy: 0.8315 - val_loss: 0.3951 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4116 - accuracy: 0.8315 - val_loss: 0.3950 - val_accuracy: 0.8101\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4119 - accuracy: 0.8230 - val_loss: 0.3922 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4162 - accuracy: 0.8315 - val_loss: 0.3962 - val_accuracy: 0.8212\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4095 - accuracy: 0.8343 - val_loss: 0.4017 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4165 - accuracy: 0.8272 - val_loss: 0.3953 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4119 - accuracy: 0.8244 - val_loss: 0.3964 - val_accuracy: 0.8268\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4116 - accuracy: 0.8343 - val_loss: 0.3944 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4132 - accuracy: 0.8315 - val_loss: 0.4016 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4106 - accuracy: 0.8315 - val_loss: 0.3937 - val_accuracy: 0.8045\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 108us/step - loss: 0.4062 - accuracy: 0.8281\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4048 - accuracy: 0.8263\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4078 - accuracy: 0.8316\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4078 - accuracy: 0.8211\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4036 - accuracy: 0.8316\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4043 - accuracy: 0.8333\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4053 - accuracy: 0.8298\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4028 - accuracy: 0.8351\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4030 - accuracy: 0.8351\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4037 - accuracy: 0.8281\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4035 - accuracy: 0.8298\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.81 - 0s 61us/step - loss: 0.4026 - accuracy: 0.8351\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4025 - accuracy: 0.8386\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4036 - accuracy: 0.8298\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4024 - accuracy: 0.8351\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4018 - accuracy: 0.8333\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4019 - accuracy: 0.8298\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4012 - accuracy: 0.8333\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4016 - accuracy: 0.8316\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4017 - accuracy: 0.8351\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4018 - accuracy: 0.8298\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 38us/step - loss: 0.4028 - accuracy: 0.8281\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4018 - accuracy: 0.8246\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4006 - accuracy: 0.8351\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4012 - accuracy: 0.8333\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4015 - accuracy: 0.8333\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4017 - accuracy: 0.8316\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4040 - accuracy: 0.8316\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.3999 - accuracy: 0.8333\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4010 - accuracy: 0.8281\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4005 - accuracy: 0.8368\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4049 - accuracy: 0.8088\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4031 - accuracy: 0.8316\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.81 - 0s 50us/step - loss: 0.4001 - accuracy: 0.8404\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4007 - accuracy: 0.8211\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4029 - accuracy: 0.8263\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4029 - accuracy: 0.8281\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4014 - accuracy: 0.8263\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4017 - accuracy: 0.8298\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4021 - accuracy: 0.8246\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.3998 - accuracy: 0.8351\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.3994 - accuracy: 0.8333\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4028 - accuracy: 0.8246\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.3999 - accuracy: 0.8316\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.3986 - accuracy: 0.8351\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.3996 - accuracy: 0.8281\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.3990 - accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.3983 - accuracy: 0.8333\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4005 - accuracy: 0.8281\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.3986 - accuracy: 0.8333\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.3982 - accuracy: 0.8316\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.3989 - accuracy: 0.8316\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4007 - accuracy: 0.8281\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 81us/step - loss: 0.4039 - accuracy: 0.8281\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.3993 - accuracy: 0.8263\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.3998 - accuracy: 0.8351\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4027 - accuracy: 0.8263\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.3981 - accuracy: 0.8316\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.3988 - accuracy: 0.8316\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4004 - accuracy: 0.8333\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4005 - accuracy: 0.8246\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.3990 - accuracy: 0.8316\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.3975 - accuracy: 0.8281\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.83 - 0s 66us/step - loss: 0.3974 - accuracy: 0.8333\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.3987 - accuracy: 0.8316\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.3975 - accuracy: 0.8351\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.3982 - accuracy: 0.8333\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.3968 - accuracy: 0.8333\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.3992 - accuracy: 0.8333\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4058 - accuracy: 0.8263\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4079 - accuracy: 0.8263\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 83us/step - loss: 0.4002 - accuracy: 0.8281\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4003 - accuracy: 0.8281\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.3969 - accuracy: 0.8351\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.3999 - accuracy: 0.8351\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.3964 - accuracy: 0.8368\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.3977 - accuracy: 0.8298\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.3957 - accuracy: 0.8333\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.3963 - accuracy: 0.8351\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.3964 - accuracy: 0.8351\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.3965 - accuracy: 0.8246\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 38us/step - loss: 0.3967 - accuracy: 0.8316\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.3980 - accuracy: 0.8281\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.3974 - accuracy: 0.8298\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 41us/step - loss: 0.3957 - accuracy: 0.8368\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.3972 - accuracy: 0.8316\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.3948 - accuracy: 0.8333\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.3958 - accuracy: 0.8316\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.3961 - accuracy: 0.8333\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.3969 - accuracy: 0.8316\n",
      "142/142 [==============================] - 0s 55us/step\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_215 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 590us/step - loss: 0.6842 - accuracy: 0.5253 - val_loss: 0.6665 - val_accuracy: 0.5922\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.6662 - accuracy: 0.5857 - val_loss: 0.6470 - val_accuracy: 0.6480\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.6465 - accuracy: 0.6292 - val_loss: 0.6243 - val_accuracy: 0.6983\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6239 - accuracy: 0.6531 - val_loss: 0.6009 - val_accuracy: 0.7207\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.6027 - accuracy: 0.6994 - val_loss: 0.5763 - val_accuracy: 0.7430\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.5817 - accuracy: 0.7261 - val_loss: 0.5529 - val_accuracy: 0.7486\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.5636 - accuracy: 0.7317 - val_loss: 0.5308 - val_accuracy: 0.7486\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.5436 - accuracy: 0.7430 - val_loss: 0.5079 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.5265 - accuracy: 0.7472 - val_loss: 0.4870 - val_accuracy: 0.7542\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.5086 - accuracy: 0.7612 - val_loss: 0.4612 - val_accuracy: 0.7877\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4923 - accuracy: 0.7795 - val_loss: 0.4494 - val_accuracy: 0.7709\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4842 - accuracy: 0.7767 - val_loss: 0.4388 - val_accuracy: 0.7709\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4779 - accuracy: 0.7781 - val_loss: 0.4366 - val_accuracy: 0.7821\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4742 - accuracy: 0.7781 - val_loss: 0.4280 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4713 - accuracy: 0.7823 - val_loss: 0.4257 - val_accuracy: 0.7821\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4681 - accuracy: 0.7809 - val_loss: 0.4264 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4660 - accuracy: 0.7851 - val_loss: 0.4278 - val_accuracy: 0.7877\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4652 - accuracy: 0.7837 - val_loss: 0.4210 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4628 - accuracy: 0.7837 - val_loss: 0.4192 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 118us/step - loss: 0.4630 - accuracy: 0.7893 - val_loss: 0.4196 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4193 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4581 - accuracy: 0.7851 - val_loss: 0.4169 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4565 - accuracy: 0.7851 - val_loss: 0.4176 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.4203 - val_accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4583 - accuracy: 0.7893 - val_loss: 0.4146 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4525 - accuracy: 0.7879 - val_loss: 0.4144 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4519 - accuracy: 0.7893 - val_loss: 0.4133 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4518 - accuracy: 0.7879 - val_loss: 0.4138 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4497 - accuracy: 0.7921 - val_loss: 0.4143 - val_accuracy: 0.7989\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4506 - accuracy: 0.7893 - val_loss: 0.4111 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4484 - accuracy: 0.7949 - val_loss: 0.4118 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4486 - accuracy: 0.7992 - val_loss: 0.4113 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4459 - accuracy: 0.7907 - val_loss: 0.4098 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4464 - accuracy: 0.7879 - val_loss: 0.4082 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.4455 - accuracy: 0.7893 - val_loss: 0.4102 - val_accuracy: 0.7989\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4439 - accuracy: 0.7921 - val_loss: 0.4102 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4437 - accuracy: 0.7992 - val_loss: 0.4088 - val_accuracy: 0.7933\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4430 - accuracy: 0.7935 - val_loss: 0.4089 - val_accuracy: 0.7933\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4429 - accuracy: 0.8034 - val_loss: 0.4110 - val_accuracy: 0.7933\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4458 - accuracy: 0.7949 - val_loss: 0.4100 - val_accuracy: 0.7933\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4425 - accuracy: 0.8048 - val_loss: 0.4094 - val_accuracy: 0.7933\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4408 - accuracy: 0.7963 - val_loss: 0.4077 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4408 - accuracy: 0.7992 - val_loss: 0.4095 - val_accuracy: 0.7933\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4402 - accuracy: 0.8034 - val_loss: 0.4065 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.4390 - accuracy: 0.8020 - val_loss: 0.4080 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4386 - accuracy: 0.8020 - val_loss: 0.4056 - val_accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4380 - accuracy: 0.8020 - val_loss: 0.4074 - val_accuracy: 0.7877\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4374 - accuracy: 0.8062 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4374 - accuracy: 0.8020 - val_loss: 0.4067 - val_accuracy: 0.7877\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4385 - accuracy: 0.8076 - val_loss: 0.4050 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4372 - accuracy: 0.8048 - val_loss: 0.4065 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4375 - accuracy: 0.8090 - val_loss: 0.4092 - val_accuracy: 0.7933\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4377 - accuracy: 0.8104 - val_loss: 0.4081 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4360 - accuracy: 0.8132 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4348 - accuracy: 0.8118 - val_loss: 0.4057 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4336 - accuracy: 0.8104 - val_loss: 0.4056 - val_accuracy: 0.7989\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4343 - accuracy: 0.8118 - val_loss: 0.4041 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4383 - accuracy: 0.8076 - val_loss: 0.4088 - val_accuracy: 0.7989\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4326 - accuracy: 0.8118 - val_loss: 0.4019 - val_accuracy: 0.7989\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4330 - accuracy: 0.8076 - val_loss: 0.4031 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4334 - accuracy: 0.8104 - val_loss: 0.4035 - val_accuracy: 0.7989\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4330 - accuracy: 0.8104 - val_loss: 0.4032 - val_accuracy: 0.7989\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4314 - accuracy: 0.8118 - val_loss: 0.4027 - val_accuracy: 0.7989\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4335 - accuracy: 0.8104 - val_loss: 0.4023 - val_accuracy: 0.7989\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4339 - accuracy: 0.8118 - val_loss: 0.4050 - val_accuracy: 0.7989\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4312 - accuracy: 0.8118 - val_loss: 0.4038 - val_accuracy: 0.7989\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4316 - accuracy: 0.8118 - val_loss: 0.4045 - val_accuracy: 0.7989\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4337 - accuracy: 0.8076 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4374 - accuracy: 0.8104 - val_loss: 0.4088 - val_accuracy: 0.7989\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4306 - accuracy: 0.8118 - val_loss: 0.4032 - val_accuracy: 0.8045\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4318 - accuracy: 0.8132 - val_loss: 0.4033 - val_accuracy: 0.8101\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4292 - accuracy: 0.8132 - val_loss: 0.4049 - val_accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4298 - accuracy: 0.8132 - val_loss: 0.4024 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4297 - accuracy: 0.8160 - val_loss: 0.4051 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4298 - accuracy: 0.8076 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 91us/step - loss: 0.4293 - accuracy: 0.8174 - val_loss: 0.4019 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4285 - accuracy: 0.8146 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4273 - accuracy: 0.8174 - val_loss: 0.4024 - val_accuracy: 0.8045\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4285 - accuracy: 0.8146 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4292 - accuracy: 0.8146 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.4284 - accuracy: 0.8146 - val_loss: 0.4024 - val_accuracy: 0.8045\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4261 - accuracy: 0.8174 - val_loss: 0.4022 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4268 - accuracy: 0.8174 - val_loss: 0.4027 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4256 - accuracy: 0.8188 - val_loss: 0.4019 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4263 - accuracy: 0.8160 - val_loss: 0.4050 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4260 - accuracy: 0.8174 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4277 - accuracy: 0.8174 - val_loss: 0.3987 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4262 - accuracy: 0.8188 - val_loss: 0.4036 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4249 - accuracy: 0.8202 - val_loss: 0.4008 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4255 - accuracy: 0.8160 - val_loss: 0.4021 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4244 - accuracy: 0.8188 - val_loss: 0.4005 - val_accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4250 - accuracy: 0.8174 - val_loss: 0.3990 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4240 - accuracy: 0.8188 - val_loss: 0.4011 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.4237 - accuracy: 0.8216 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4249 - accuracy: 0.8216 - val_loss: 0.4034 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4237 - accuracy: 0.8230 - val_loss: 0.4012 - val_accuracy: 0.8101\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4225 - accuracy: 0.8216 - val_loss: 0.4013 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4243 - accuracy: 0.8188 - val_loss: 0.4009 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4254 - accuracy: 0.8230 - val_loss: 0.4039 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4249 - accuracy: 0.8216 - val_loss: 0.4003 - val_accuracy: 0.8045\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4192 - accuracy: 0.8193\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4196 - accuracy: 0.8158\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 73us/step - loss: 0.4183 - accuracy: 0.8211\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4180 - accuracy: 0.8211\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4182 - accuracy: 0.8175\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4178 - accuracy: 0.8193\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4172 - accuracy: 0.8211\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4171 - accuracy: 0.8228\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4171 - accuracy: 0.8211\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4166 - accuracy: 0.8228\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4176 - accuracy: 0.8228\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.8211\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4161 - accuracy: 0.8228\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4174 - accuracy: 0.8228\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.8228\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4161 - accuracy: 0.8211\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4153 - accuracy: 0.8211\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4155 - accuracy: 0.8211\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4144 - accuracy: 0.8246\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4151 - accuracy: 0.8228\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4152 - accuracy: 0.8263\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 99us/step - loss: 0.4145 - accuracy: 0.8228\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4145 - accuracy: 0.8228\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4142 - accuracy: 0.8263\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.83 - 0s 58us/step - loss: 0.4144 - accuracy: 0.8246\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4138 - accuracy: 0.8228\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4138 - accuracy: 0.8246\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4130 - accuracy: 0.8246\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4138 - accuracy: 0.8263\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4130 - accuracy: 0.8211\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4132 - accuracy: 0.8263\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4129 - accuracy: 0.8263\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4128 - accuracy: 0.8263\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4121 - accuracy: 0.8246\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4121 - accuracy: 0.8246\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4127 - accuracy: 0.8263\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4124 - accuracy: 0.8298\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4142 - accuracy: 0.8263\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4106 - accuracy: 0.8298\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4119 - accuracy: 0.8298\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4113 - accuracy: 0.8246\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4108 - accuracy: 0.8281\n",
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4109 - accuracy: 0.8281\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4114 - accuracy: 0.8246\n",
      "Epoch 45/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 56us/step - loss: 0.4105 - accuracy: 0.8246\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4104 - accuracy: 0.8281\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4101 - accuracy: 0.8281\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4105 - accuracy: 0.8263\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4100 - accuracy: 0.8263\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4100 - accuracy: 0.8263\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4102 - accuracy: 0.8263\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4084 - accuracy: 0.8298\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4094 - accuracy: 0.8263\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4091 - accuracy: 0.8263\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4090 - accuracy: 0.8281\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4085 - accuracy: 0.8281\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4086 - accuracy: 0.8263\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4093 - accuracy: 0.8263\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4098 - accuracy: 0.8298\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4090 - accuracy: 0.8281\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4095 - accuracy: 0.8351\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4098 - accuracy: 0.8316\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4078 - accuracy: 0.8316\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4074 - accuracy: 0.8281\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4071 - accuracy: 0.8298\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4077 - accuracy: 0.8246\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4071 - accuracy: 0.8316\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 76us/step - loss: 0.4070 - accuracy: 0.8298\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4072 - accuracy: 0.8298\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4064 - accuracy: 0.8368\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4069 - accuracy: 0.8263\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4061 - accuracy: 0.8316\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4060 - accuracy: 0.8316\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4065 - accuracy: 0.8316\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4064 - accuracy: 0.8316\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4051 - accuracy: 0.8316\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 71us/step - loss: 0.4059 - accuracy: 0.8281\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4062 - accuracy: 0.8298\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4052 - accuracy: 0.8298\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4052 - accuracy: 0.8333\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4048 - accuracy: 0.8316\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4067 - accuracy: 0.8316\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4049 - accuracy: 0.8316\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 70us/step - loss: 0.4059 - accuracy: 0.8298\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4051 - accuracy: 0.8351\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 52us/step - loss: 0.4052 - accuracy: 0.8281\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4060 - accuracy: 0.8298\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 65us/step - loss: 0.4065 - accuracy: 0.8333\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4054 - accuracy: 0.8298\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4046 - accuracy: 0.8316\n",
      "142/142 [==============================] - 0s 53us/step\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_219 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 0s 474us/step - loss: 0.7124 - accuracy: 0.3834 - val_loss: 0.6880 - val_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.6876 - accuracy: 0.4298 - val_loss: 0.6689 - val_accuracy: 0.6257\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.6744 - accuracy: 0.6629 - val_loss: 0.6579 - val_accuracy: 0.6927\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.6637 - accuracy: 0.6840 - val_loss: 0.6485 - val_accuracy: 0.7486\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.6538 - accuracy: 0.7163 - val_loss: 0.6399 - val_accuracy: 0.7263\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.6440 - accuracy: 0.7430 - val_loss: 0.6293 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.6351 - accuracy: 0.7500 - val_loss: 0.6194 - val_accuracy: 0.7709\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.6269 - accuracy: 0.7640 - val_loss: 0.6105 - val_accuracy: 0.8045\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.6180 - accuracy: 0.7781 - val_loss: 0.6015 - val_accuracy: 0.8045\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.6099 - accuracy: 0.7711 - val_loss: 0.5938 - val_accuracy: 0.8045\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6025 - accuracy: 0.7809 - val_loss: 0.5871 - val_accuracy: 0.8045\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.5946 - accuracy: 0.7992 - val_loss: 0.5808 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5873 - accuracy: 0.7992 - val_loss: 0.5778 - val_accuracy: 0.7989\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.5785 - accuracy: 0.7992 - val_loss: 0.5612 - val_accuracy: 0.7877\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.5482 - accuracy: 0.7992 - val_loss: 0.5211 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.5186 - accuracy: 0.7935 - val_loss: 0.4900 - val_accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4964 - accuracy: 0.7907 - val_loss: 0.4680 - val_accuracy: 0.7989\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 90us/step - loss: 0.4834 - accuracy: 0.7893 - val_loss: 0.4573 - val_accuracy: 0.7933\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4752 - accuracy: 0.7907 - val_loss: 0.4471 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4708 - accuracy: 0.7921 - val_loss: 0.4383 - val_accuracy: 0.7877\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4682 - accuracy: 0.7949 - val_loss: 0.4346 - val_accuracy: 0.7877\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4640 - accuracy: 0.7935 - val_loss: 0.4272 - val_accuracy: 0.7821\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4713 - accuracy: 0.7907 - val_loss: 0.4323 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4570 - accuracy: 0.7963 - val_loss: 0.4244 - val_accuracy: 0.7821\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4567 - accuracy: 0.7992 - val_loss: 0.4210 - val_accuracy: 0.7877\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.4534 - accuracy: 0.7907 - val_loss: 0.4207 - val_accuracy: 0.7989\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4522 - accuracy: 0.7978 - val_loss: 0.4179 - val_accuracy: 0.7989\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4502 - accuracy: 0.7963 - val_loss: 0.4205 - val_accuracy: 0.7989\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4506 - accuracy: 0.7978 - val_loss: 0.4145 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4480 - accuracy: 0.8034 - val_loss: 0.4118 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4462 - accuracy: 0.8006 - val_loss: 0.4131 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4460 - accuracy: 0.8020 - val_loss: 0.4103 - val_accuracy: 0.7821\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4446 - accuracy: 0.8034 - val_loss: 0.4104 - val_accuracy: 0.8045\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4451 - accuracy: 0.8006 - val_loss: 0.4077 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.4435 - accuracy: 0.8020 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.4418 - accuracy: 0.7992 - val_loss: 0.4078 - val_accuracy: 0.7989\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4418 - accuracy: 0.8048 - val_loss: 0.4059 - val_accuracy: 0.8045\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4427 - accuracy: 0.8020 - val_loss: 0.4075 - val_accuracy: 0.8045\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4413 - accuracy: 0.8020 - val_loss: 0.4027 - val_accuracy: 0.7989\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4397 - accuracy: 0.8048 - val_loss: 0.4052 - val_accuracy: 0.8156\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4402 - accuracy: 0.8090 - val_loss: 0.4055 - val_accuracy: 0.8156\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4388 - accuracy: 0.8048 - val_loss: 0.4015 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4384 - accuracy: 0.8090 - val_loss: 0.4039 - val_accuracy: 0.8156\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4386 - accuracy: 0.8048 - val_loss: 0.4055 - val_accuracy: 0.8156\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4379 - accuracy: 0.8090 - val_loss: 0.4022 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4366 - accuracy: 0.8090 - val_loss: 0.4013 - val_accuracy: 0.8156\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4365 - accuracy: 0.8104 - val_loss: 0.4001 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4372 - accuracy: 0.8104 - val_loss: 0.4004 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4346 - accuracy: 0.8076 - val_loss: 0.4037 - val_accuracy: 0.8101\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4366 - accuracy: 0.8118 - val_loss: 0.3991 - val_accuracy: 0.8212\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4354 - accuracy: 0.8090 - val_loss: 0.3973 - val_accuracy: 0.8101\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4353 - accuracy: 0.8118 - val_loss: 0.4023 - val_accuracy: 0.8212\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4367 - accuracy: 0.8090 - val_loss: 0.4043 - val_accuracy: 0.8045\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4346 - accuracy: 0.8118 - val_loss: 0.3981 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4371 - accuracy: 0.8104 - val_loss: 0.3975 - val_accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4376 - accuracy: 0.8132 - val_loss: 0.4029 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4332 - accuracy: 0.8118 - val_loss: 0.3944 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4323 - accuracy: 0.8104 - val_loss: 0.3974 - val_accuracy: 0.8156\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4321 - accuracy: 0.8146 - val_loss: 0.4001 - val_accuracy: 0.8156\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4324 - accuracy: 0.8160 - val_loss: 0.3959 - val_accuracy: 0.7989\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4348 - accuracy: 0.8104 - val_loss: 0.4000 - val_accuracy: 0.8156\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4319 - accuracy: 0.8146 - val_loss: 0.3955 - val_accuracy: 0.8156\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4317 - accuracy: 0.8132 - val_loss: 0.3949 - val_accuracy: 0.8101\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4318 - accuracy: 0.8118 - val_loss: 0.3962 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4331 - accuracy: 0.8048 - val_loss: 0.4010 - val_accuracy: 0.8156\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 179us/step - loss: 0.4329 - accuracy: 0.8202 - val_loss: 0.3951 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4352 - accuracy: 0.8132 - val_loss: 0.4031 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4297 - accuracy: 0.8118 - val_loss: 0.3940 - val_accuracy: 0.8156\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4290 - accuracy: 0.8160 - val_loss: 0.3972 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4296 - accuracy: 0.8202 - val_loss: 0.3951 - val_accuracy: 0.8212\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4279 - accuracy: 0.8160 - val_loss: 0.3969 - val_accuracy: 0.8156\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.4297 - accuracy: 0.8146 - val_loss: 0.3998 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4288 - accuracy: 0.8160 - val_loss: 0.3938 - val_accuracy: 0.8156\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 112us/step - loss: 0.4282 - accuracy: 0.8174 - val_loss: 0.3963 - val_accuracy: 0.8156\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4283 - accuracy: 0.8118 - val_loss: 0.3977 - val_accuracy: 0.8156\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 174us/step - loss: 0.4307 - accuracy: 0.8174 - val_loss: 0.3962 - val_accuracy: 0.8101\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4266 - accuracy: 0.8146 - val_loss: 0.4054 - val_accuracy: 0.8101\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4337 - accuracy: 0.8160 - val_loss: 0.3979 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4283 - accuracy: 0.8244 - val_loss: 0.3986 - val_accuracy: 0.8156\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4269 - accuracy: 0.8160 - val_loss: 0.3933 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4283 - accuracy: 0.8174 - val_loss: 0.3959 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.4276 - accuracy: 0.8216 - val_loss: 0.3934 - val_accuracy: 0.8101\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4313 - accuracy: 0.8118 - val_loss: 0.4063 - val_accuracy: 0.8045\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4308 - accuracy: 0.8188 - val_loss: 0.3980 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4271 - accuracy: 0.8244 - val_loss: 0.3965 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4271 - accuracy: 0.8216 - val_loss: 0.3928 - val_accuracy: 0.8101\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4239 - accuracy: 0.8160 - val_loss: 0.3991 - val_accuracy: 0.8156\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4266 - accuracy: 0.8329 - val_loss: 0.3962 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4232 - accuracy: 0.8216 - val_loss: 0.3954 - val_accuracy: 0.8156\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4252 - accuracy: 0.8230 - val_loss: 0.3976 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.4283 - accuracy: 0.8230 - val_loss: 0.3983 - val_accuracy: 0.8045\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4266 - accuracy: 0.8174 - val_loss: 0.3995 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4240 - accuracy: 0.8301 - val_loss: 0.3951 - val_accuracy: 0.8156\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4260 - accuracy: 0.8174 - val_loss: 0.3983 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4291 - accuracy: 0.8258 - val_loss: 0.3919 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4245 - accuracy: 0.8202 - val_loss: 0.3971 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.4225 - accuracy: 0.8343 - val_loss: 0.3943 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4235 - accuracy: 0.8132 - val_loss: 0.3989 - val_accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4221 - accuracy: 0.8202 - val_loss: 0.3948 - val_accuracy: 0.8101\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.4236 - accuracy: 0.8174 - val_loss: 0.3970 - val_accuracy: 0.8101\n",
      "Epoch 1/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4190 - accuracy: 0.8316\n",
      "Epoch 2/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4196 - accuracy: 0.8351\n",
      "Epoch 3/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4183 - accuracy: 0.8333\n",
      "Epoch 4/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4183 - accuracy: 0.8351\n",
      "Epoch 5/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4210 - accuracy: 0.8316\n",
      "Epoch 6/90\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4179 - accuracy: 0.8281\n",
      "Epoch 7/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4168 - accuracy: 0.8316\n",
      "Epoch 8/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4188 - accuracy: 0.8386\n",
      "Epoch 9/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4168 - accuracy: 0.8333\n",
      "Epoch 10/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4181 - accuracy: 0.8333\n",
      "Epoch 11/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4162 - accuracy: 0.8386\n",
      "Epoch 12/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4160 - accuracy: 0.8333\n",
      "Epoch 13/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.8368\n",
      "Epoch 14/90\n",
      "570/570 [==============================] - 0s 45us/step - loss: 0.4154 - accuracy: 0.8386\n",
      "Epoch 15/90\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4161 - accuracy: 0.8404\n",
      "Epoch 16/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4155 - accuracy: 0.8316\n",
      "Epoch 17/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4152 - accuracy: 0.8386\n",
      "Epoch 18/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4156 - accuracy: 0.8404\n",
      "Epoch 19/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4152 - accuracy: 0.8386\n",
      "Epoch 20/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4147 - accuracy: 0.8404\n",
      "Epoch 21/90\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4156 - accuracy: 0.8351\n",
      "Epoch 22/90\n",
      "570/570 [==============================] - 0s 36us/step - loss: 0.4144 - accuracy: 0.8439\n",
      "Epoch 23/90\n",
      "570/570 [==============================] - 0s 66us/step - loss: 0.4142 - accuracy: 0.8386\n",
      "Epoch 24/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4158 - accuracy: 0.8368\n",
      "Epoch 25/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4145 - accuracy: 0.8351\n",
      "Epoch 26/90\n",
      "570/570 [==============================] - 0s 91us/step - loss: 0.4140 - accuracy: 0.8404\n",
      "Epoch 27/90\n",
      "570/570 [==============================] - 0s 86us/step - loss: 0.4144 - accuracy: 0.8333\n",
      "Epoch 28/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4130 - accuracy: 0.8386\n",
      "Epoch 29/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4141 - accuracy: 0.8351\n",
      "Epoch 30/90\n",
      "570/570 [==============================] - 0s 42us/step - loss: 0.4142 - accuracy: 0.8351\n",
      "Epoch 31/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4131 - accuracy: 0.8404\n",
      "Epoch 32/90\n",
      "570/570 [==============================] - 0s 40us/step - loss: 0.4133 - accuracy: 0.8421\n",
      "Epoch 33/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4140 - accuracy: 0.8333\n",
      "Epoch 34/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4140 - accuracy: 0.8404\n",
      "Epoch 35/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4138 - accuracy: 0.8368\n",
      "Epoch 36/90\n",
      "570/570 [==============================] - 0s 72us/step - loss: 0.4132 - accuracy: 0.8298\n",
      "Epoch 37/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4127 - accuracy: 0.8421\n",
      "Epoch 38/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4154 - accuracy: 0.8386\n",
      "Epoch 39/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4115 - accuracy: 0.8386\n",
      "Epoch 40/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4123 - accuracy: 0.8298\n",
      "Epoch 41/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4115 - accuracy: 0.8386\n",
      "Epoch 42/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4124 - accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/90\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4117 - accuracy: 0.8404\n",
      "Epoch 44/90\n",
      "570/570 [==============================] - 0s 50us/step - loss: 0.4110 - accuracy: 0.8368\n",
      "Epoch 45/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4116 - accuracy: 0.8386\n",
      "Epoch 46/90\n",
      "570/570 [==============================] - 0s 85us/step - loss: 0.4112 - accuracy: 0.8333\n",
      "Epoch 47/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4117 - accuracy: 0.8404\n",
      "Epoch 48/90\n",
      "570/570 [==============================] - 0s 57us/step - loss: 0.4127 - accuracy: 0.8368\n",
      "Epoch 49/90\n",
      "570/570 [==============================] - 0s 37us/step - loss: 0.4099 - accuracy: 0.8386\n",
      "Epoch 50/90\n",
      "570/570 [==============================] - 0s 44us/step - loss: 0.4111 - accuracy: 0.8368\n",
      "Epoch 51/90\n",
      "570/570 [==============================] - 0s 88us/step - loss: 0.4112 - accuracy: 0.8386\n",
      "Epoch 52/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4100 - accuracy: 0.8386\n",
      "Epoch 53/90\n",
      "570/570 [==============================] - 0s 48us/step - loss: 0.4107 - accuracy: 0.8386\n",
      "Epoch 54/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4108 - accuracy: 0.8386\n",
      "Epoch 55/90\n",
      "570/570 [==============================] - 0s 64us/step - loss: 0.4117 - accuracy: 0.8333\n",
      "Epoch 56/90\n",
      "570/570 [==============================] - 0s 61us/step - loss: 0.4100 - accuracy: 0.8404\n",
      "Epoch 57/90\n",
      "570/570 [==============================] - 0s 68us/step - loss: 0.4092 - accuracy: 0.8421\n",
      "Epoch 58/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4104 - accuracy: 0.8404\n",
      "Epoch 59/90\n",
      "570/570 [==============================] - 0s 113us/step - loss: 0.4100 - accuracy: 0.8404\n",
      "Epoch 60/90\n",
      "570/570 [==============================] - 0s 80us/step - loss: 0.4104 - accuracy: 0.8333\n",
      "Epoch 61/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4095 - accuracy: 0.8404\n",
      "Epoch 62/90\n",
      "570/570 [==============================] - 0s 63us/step - loss: 0.4098 - accuracy: 0.8368\n",
      "Epoch 63/90\n",
      "570/570 [==============================] - 0s 62us/step - loss: 0.4097 - accuracy: 0.8386\n",
      "Epoch 64/90\n",
      "570/570 [==============================] - 0s 69us/step - loss: 0.4090 - accuracy: 0.8351\n",
      "Epoch 65/90\n",
      "570/570 [==============================] - 0s 75us/step - loss: 0.4106 - accuracy: 0.8421\n",
      "Epoch 66/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4078 - accuracy: 0.8439\n",
      "Epoch 67/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4086 - accuracy: 0.8368\n",
      "Epoch 68/90\n",
      "570/570 [==============================] - 0s 67us/step - loss: 0.4085 - accuracy: 0.8386\n",
      "Epoch 69/90\n",
      "570/570 [==============================] - 0s 79us/step - loss: 0.4082 - accuracy: 0.8421\n",
      "Epoch 70/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4086 - accuracy: 0.8404\n",
      "Epoch 71/90\n",
      "570/570 [==============================] - 0s 46us/step - loss: 0.4078 - accuracy: 0.8386\n",
      "Epoch 72/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4091 - accuracy: 0.8351\n",
      "Epoch 73/90\n",
      "570/570 [==============================] - 0s 56us/step - loss: 0.4073 - accuracy: 0.8333\n",
      "Epoch 74/90\n",
      "570/570 [==============================] - 0s 54us/step - loss: 0.4086 - accuracy: 0.8386\n",
      "Epoch 75/90\n",
      "570/570 [==============================] - 0s 58us/step - loss: 0.4076 - accuracy: 0.8404\n",
      "Epoch 76/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4073 - accuracy: 0.8404\n",
      "Epoch 77/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4073 - accuracy: 0.8386\n",
      "Epoch 78/90\n",
      "570/570 [==============================] - 0s 60us/step - loss: 0.4071 - accuracy: 0.8386\n",
      "Epoch 79/90\n",
      "570/570 [==============================] - 0s 49us/step - loss: 0.4071 - accuracy: 0.8404\n",
      "Epoch 80/90\n",
      "570/570 [==============================] - 0s 36us/step - loss: 0.4072 - accuracy: 0.8386\n",
      "Epoch 81/90\n",
      "570/570 [==============================] - 0s 51us/step - loss: 0.4085 - accuracy: 0.8333\n",
      "Epoch 82/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4075 - accuracy: 0.8421\n",
      "Epoch 83/90\n",
      "570/570 [==============================] - 0s 53us/step - loss: 0.4070 - accuracy: 0.8386\n",
      "Epoch 84/90\n",
      "570/570 [==============================] - 0s 36us/step - loss: 0.4072 - accuracy: 0.8386\n",
      "Epoch 85/90\n",
      "570/570 [==============================] - 0s 35us/step - loss: 0.4100 - accuracy: 0.8386\n",
      "Epoch 86/90\n",
      "570/570 [==============================] - 0s 40us/step - loss: 0.4069 - accuracy: 0.8333\n",
      "Epoch 87/90\n",
      "570/570 [==============================] - 0s 47us/step - loss: 0.4061 - accuracy: 0.8421\n",
      "Epoch 88/90\n",
      "570/570 [==============================] - 0s 43us/step - loss: 0.4071 - accuracy: 0.8368\n",
      "Epoch 89/90\n",
      "570/570 [==============================] - 0s 59us/step - loss: 0.4078 - accuracy: 0.8386\n",
      "Epoch 90/90\n",
      "570/570 [==============================] - 0s 55us/step - loss: 0.4058 - accuracy: 0.8386\n",
      "142/142 [==============================] - 0s 58us/step\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_223 (Dense)            (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 335\n",
      "Trainable params: 335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6278 - val_loss: 0.6121 - val_accuracy: 0.6480\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.6063 - accuracy: 0.6348 - val_loss: 0.5854 - val_accuracy: 0.6536\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.5880 - accuracy: 0.6531 - val_loss: 0.5614 - val_accuracy: 0.7039\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5620 - accuracy: 0.7261 - val_loss: 0.5282 - val_accuracy: 0.7151\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.5408 - accuracy: 0.7374 - val_loss: 0.5047 - val_accuracy: 0.7263\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.5278 - accuracy: 0.7444 - val_loss: 0.4893 - val_accuracy: 0.7430\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.5218 - accuracy: 0.7556 - val_loss: 0.4733 - val_accuracy: 0.7654\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.5164 - accuracy: 0.7514 - val_loss: 0.4633 - val_accuracy: 0.7933\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.5051 - accuracy: 0.7711 - val_loss: 0.4569 - val_accuracy: 0.7877\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4997 - accuracy: 0.7725 - val_loss: 0.4497 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4959 - accuracy: 0.7725 - val_loss: 0.4477 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4919 - accuracy: 0.7739 - val_loss: 0.4430 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4885 - accuracy: 0.7823 - val_loss: 0.4403 - val_accuracy: 0.7877\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4876 - accuracy: 0.7767 - val_loss: 0.4356 - val_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4839 - accuracy: 0.7893 - val_loss: 0.4353 - val_accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4816 - accuracy: 0.7725 - val_loss: 0.4344 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4801 - accuracy: 0.7907 - val_loss: 0.4338 - val_accuracy: 0.7709\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.4770 - accuracy: 0.7935 - val_loss: 0.4328 - val_accuracy: 0.7821\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4750 - accuracy: 0.7907 - val_loss: 0.4305 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4735 - accuracy: 0.7935 - val_loss: 0.4290 - val_accuracy: 0.7821\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4717 - accuracy: 0.7921 - val_loss: 0.4272 - val_accuracy: 0.7989\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.4702 - accuracy: 0.7907 - val_loss: 0.4267 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4713 - accuracy: 0.7893 - val_loss: 0.4244 - val_accuracy: 0.7877\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4715 - accuracy: 0.7809 - val_loss: 0.4236 - val_accuracy: 0.7989\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4682 - accuracy: 0.7921 - val_loss: 0.4234 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4671 - accuracy: 0.7865 - val_loss: 0.4227 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4660 - accuracy: 0.7907 - val_loss: 0.4220 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4666 - accuracy: 0.7879 - val_loss: 0.4198 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4654 - accuracy: 0.7837 - val_loss: 0.4192 - val_accuracy: 0.8045\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4647 - accuracy: 0.7907 - val_loss: 0.4179 - val_accuracy: 0.8045\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4632 - accuracy: 0.7907 - val_loss: 0.4187 - val_accuracy: 0.8045\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4628 - accuracy: 0.7837 - val_loss: 0.4193 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4649 - accuracy: 0.7978 - val_loss: 0.4181 - val_accuracy: 0.8045\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4627 - accuracy: 0.7907 - val_loss: 0.4178 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4627 - accuracy: 0.7851 - val_loss: 0.4175 - val_accuracy: 0.8045\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4607 - accuracy: 0.7879 - val_loss: 0.4177 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.4624 - accuracy: 0.7935 - val_loss: 0.4178 - val_accuracy: 0.8045\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4592 - accuracy: 0.7879 - val_loss: 0.4171 - val_accuracy: 0.8045\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4600 - accuracy: 0.8006 - val_loss: 0.4166 - val_accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4623 - accuracy: 0.7837 - val_loss: 0.4156 - val_accuracy: 0.8045\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4579 - accuracy: 0.7907 - val_loss: 0.4163 - val_accuracy: 0.8045\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.4161 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4579 - accuracy: 0.7907 - val_loss: 0.4160 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4574 - accuracy: 0.7921 - val_loss: 0.4153 - val_accuracy: 0.8045\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.4566 - accuracy: 0.7992 - val_loss: 0.4154 - val_accuracy: 0.8045\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4565 - accuracy: 0.7907 - val_loss: 0.4136 - val_accuracy: 0.8045\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.4145 - val_accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4559 - accuracy: 0.7978 - val_loss: 0.4136 - val_accuracy: 0.7989\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.4131 - val_accuracy: 0.7989\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4561 - accuracy: 0.7935 - val_loss: 0.4111 - val_accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4559 - accuracy: 0.7949 - val_loss: 0.4106 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4555 - accuracy: 0.7949 - val_loss: 0.4111 - val_accuracy: 0.7989\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4548 - accuracy: 0.7907 - val_loss: 0.4113 - val_accuracy: 0.7989\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4547 - accuracy: 0.7935 - val_loss: 0.4111 - val_accuracy: 0.7989\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4545 - accuracy: 0.7907 - val_loss: 0.4114 - val_accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4540 - accuracy: 0.7949 - val_loss: 0.4098 - val_accuracy: 0.8045\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4535 - accuracy: 0.7949 - val_loss: 0.4090 - val_accuracy: 0.7989\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4532 - accuracy: 0.7978 - val_loss: 0.4086 - val_accuracy: 0.8045\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4550 - accuracy: 0.7921 - val_loss: 0.4091 - val_accuracy: 0.8101\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4532 - accuracy: 0.7963 - val_loss: 0.4081 - val_accuracy: 0.8045\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.4527 - accuracy: 0.7963 - val_loss: 0.4092 - val_accuracy: 0.7933\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4540 - accuracy: 0.7921 - val_loss: 0.4087 - val_accuracy: 0.8045\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.4524 - accuracy: 0.7963 - val_loss: 0.4078 - val_accuracy: 0.8045\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4515 - accuracy: 0.7963 - val_loss: 0.4069 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4539 - accuracy: 0.7978 - val_loss: 0.4082 - val_accuracy: 0.8045\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.4529 - accuracy: 0.7963 - val_loss: 0.4078 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4521 - accuracy: 0.7978 - val_loss: 0.4071 - val_accuracy: 0.8045\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 93us/step - loss: 0.4529 - accuracy: 0.7879 - val_loss: 0.4066 - val_accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.4506 - accuracy: 0.7949 - val_loss: 0.4077 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4521 - accuracy: 0.8006 - val_loss: 0.4061 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4507 - accuracy: 0.7907 - val_loss: 0.4064 - val_accuracy: 0.8045\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.4506 - accuracy: 0.7963 - val_loss: 0.4060 - val_accuracy: 0.8045\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 107us/step - loss: 0.4494 - accuracy: 0.7921 - val_loss: 0.4050 - val_accuracy: 0.8101\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4497 - accuracy: 0.7963 - val_loss: 0.4044 - val_accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4485 - accuracy: 0.7949 - val_loss: 0.4042 - val_accuracy: 0.7989\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4482 - accuracy: 0.7992 - val_loss: 0.4050 - val_accuracy: 0.8045\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.4500 - accuracy: 0.7992 - val_loss: 0.4046 - val_accuracy: 0.8045\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.4473 - accuracy: 0.7935 - val_loss: 0.4039 - val_accuracy: 0.8101\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4491 - accuracy: 0.7935 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4481 - accuracy: 0.8020 - val_loss: 0.4041 - val_accuracy: 0.7989\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.4494 - accuracy: 0.7921 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4464 - accuracy: 0.7978 - val_loss: 0.4041 - val_accuracy: 0.8045\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4466 - accuracy: 0.7963 - val_loss: 0.4045 - val_accuracy: 0.8101\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4460 - accuracy: 0.7992 - val_loss: 0.4042 - val_accuracy: 0.8101\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4458 - accuracy: 0.7992 - val_loss: 0.4039 - val_accuracy: 0.8156\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4453 - accuracy: 0.7963 - val_loss: 0.4022 - val_accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4454 - accuracy: 0.7949 - val_loss: 0.4027 - val_accuracy: 0.8101\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.4452 - accuracy: 0.7978 - val_loss: 0.4022 - val_accuracy: 0.8101\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4452 - accuracy: 0.7963 - val_loss: 0.4027 - val_accuracy: 0.8101\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4457 - accuracy: 0.7949 - val_loss: 0.4015 - val_accuracy: 0.8101\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4447 - accuracy: 0.8006 - val_loss: 0.4026 - val_accuracy: 0.8156\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4443 - accuracy: 0.7963 - val_loss: 0.4020 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4444 - accuracy: 0.7978 - val_loss: 0.4006 - val_accuracy: 0.8101\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4443 - accuracy: 0.7978 - val_loss: 0.4015 - val_accuracy: 0.8101\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4438 - accuracy: 0.7978 - val_loss: 0.4018 - val_accuracy: 0.8101\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.4428 - accuracy: 0.7978 - val_loss: 0.4016 - val_accuracy: 0.8156\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4436 - accuracy: 0.8006 - val_loss: 0.4008 - val_accuracy: 0.8156\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4427 - accuracy: 0.8006 - val_loss: 0.4012 - val_accuracy: 0.8156\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.4436 - accuracy: 0.7978 - val_loss: 0.4009 - val_accuracy: 0.8156\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.4460 - accuracy: 0.7963 - val_loss: 0.4008 - val_accuracy: 0.8101\n",
      "Epoch 1/60\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4436 - accuracy: 0.8034\n",
      "Epoch 2/60\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4430 - accuracy: 0.7992\n",
      "Epoch 3/60\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4408 - accuracy: 0.8020\n",
      "Epoch 4/60\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4414 - accuracy: 0.8020\n",
      "Epoch 5/60\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4412 - accuracy: 0.8020\n",
      "Epoch 6/60\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4407 - accuracy: 0.8020\n",
      "Epoch 7/60\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.4408 - accuracy: 0.8020\n",
      "Epoch 8/60\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4404 - accuracy: 0.8020\n",
      "Epoch 9/60\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4401 - accuracy: 0.8034\n",
      "Epoch 10/60\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.4399 - accuracy: 0.8020\n",
      "Epoch 11/60\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.66 - 0s 57us/step - loss: 0.4397 - accuracy: 0.8020\n",
      "Epoch 12/60\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4401 - accuracy: 0.8020\n",
      "Epoch 13/60\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4394 - accuracy: 0.8020\n",
      "Epoch 14/60\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4399 - accuracy: 0.8034\n",
      "Epoch 15/60\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.4400 - accuracy: 0.8006\n",
      "Epoch 16/60\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4391 - accuracy: 0.8006\n",
      "Epoch 17/60\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4393 - accuracy: 0.8006\n",
      "Epoch 18/60\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4391 - accuracy: 0.8006\n",
      "Epoch 19/60\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4397 - accuracy: 0.8006\n",
      "Epoch 20/60\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4389 - accuracy: 0.7992\n",
      "Epoch 21/60\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4386 - accuracy: 0.8020\n",
      "Epoch 22/60\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4413 - accuracy: 0.8020\n",
      "Epoch 23/60\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4401 - accuracy: 0.7978\n",
      "Epoch 24/60\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.85 - 0s 65us/step - loss: 0.4382 - accuracy: 0.8020\n",
      "Epoch 25/60\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4382 - accuracy: 0.8006\n",
      "Epoch 26/60\n",
      "712/712 [==============================] - 0s 55us/step - loss: 0.4388 - accuracy: 0.7992\n",
      "Epoch 27/60\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4378 - accuracy: 0.8006\n",
      "Epoch 28/60\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4381 - accuracy: 0.8006\n",
      "Epoch 29/60\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4380 - accuracy: 0.7992\n",
      "Epoch 30/60\n",
      "712/712 [==============================] - 0s 55us/step - loss: 0.4374 - accuracy: 0.8006\n",
      "Epoch 31/60\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4375 - accuracy: 0.8006\n",
      "Epoch 32/60\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4378 - accuracy: 0.8020\n",
      "Epoch 33/60\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4375 - accuracy: 0.8006\n",
      "Epoch 34/60\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4391 - accuracy: 0.7992\n",
      "Epoch 35/60\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4376 - accuracy: 0.7992\n",
      "Epoch 36/60\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4370 - accuracy: 0.7978\n",
      "Epoch 37/60\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4369 - accuracy: 0.7992\n",
      "Epoch 38/60\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4373 - accuracy: 0.7992\n",
      "Epoch 39/60\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4367 - accuracy: 0.8020\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 62us/step - loss: 0.4369 - accuracy: 0.8006\n",
      "Epoch 41/60\n",
      "712/712 [==============================] - 0s 55us/step - loss: 0.4383 - accuracy: 0.7992\n",
      "Epoch 42/60\n",
      "712/712 [==============================] - 0s 61us/step - loss: 0.4382 - accuracy: 0.7992\n",
      "Epoch 43/60\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4360 - accuracy: 0.8034\n",
      "Epoch 44/60\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4363 - accuracy: 0.8048\n",
      "Epoch 45/60\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4366 - accuracy: 0.7992\n",
      "Epoch 46/60\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4360 - accuracy: 0.8006\n",
      "Epoch 47/60\n",
      "712/712 [==============================] - 0s 51us/step - loss: 0.4356 - accuracy: 0.8006\n",
      "Epoch 48/60\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4357 - accuracy: 0.8006\n",
      "Epoch 49/60\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4359 - accuracy: 0.7992\n",
      "Epoch 50/60\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4354 - accuracy: 0.8048\n",
      "Epoch 51/60\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4349 - accuracy: 0.8006\n",
      "Epoch 52/60\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4358 - accuracy: 0.8034\n",
      "Epoch 53/60\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4353 - accuracy: 0.8006\n",
      "Epoch 54/60\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4350 - accuracy: 0.8034\n",
      "Epoch 55/60\n",
      "712/712 [==============================] - 0s 89us/step - loss: 0.4353 - accuracy: 0.8006\n",
      "Epoch 56/60\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4345 - accuracy: 0.8020\n",
      "Epoch 57/60\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4347 - accuracy: 0.8034\n",
      "Epoch 58/60\n",
      "712/712 [==============================] - 0s 47us/step - loss: 0.4351 - accuracy: 0.8020\n",
      "Epoch 59/60\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4366 - accuracy: 0.8020\n",
      "Epoch 60/60\n",
      "712/712 [==============================] - 0s 65us/step - loss: 0.4346 - accuracy: 0.8048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000018803A8EFC8>,\n",
       "             param_grid={'batch_size': [16, 32, 48], 'epochs': [30, 60, 90]})"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8061797618865967"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 63us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8156424760818481"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report train:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       439\n",
      "           1       0.78      0.68      0.73       273\n",
      "\n",
      "    accuracy                           0.81       712\n",
      "   macro avg       0.80      0.78      0.79       712\n",
      "weighted avg       0.80      0.81      0.80       712\n",
      "\n",
      "Classification report val:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       110\n",
      "           1       0.77      0.74      0.76        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "confusion matrix train:  [[387  52]\n",
      " [ 86 187]]\n",
      "confusion  matrix val:  [[95 15]\n",
      " [18 51]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification report train: ', metrics.classification_report(y_train, gs.predict(X_train)))\n",
    "print('Classification report val: ', metrics.classification_report(y_val, gs.predict(X_val)))\n",
    "print('confusion matrix train: ', metrics.confusion_matrix(y_train, gs.predict(X_train)))\n",
    "print('confusion  matrix val: ', metrics.confusion_matrix(y_val, gs.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
